{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding exercise for Wang Lab\n",
    "### Implementation of nnU-net for the segmentation of pancreas and pancreatic lesions on CT scan, with classication of the pancreatic lesions\n",
    "### by Leo Chen\n",
    "### August/September 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "import os\n",
    "import glob\n",
    "#import util\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import SimpleITK as sitk\n",
    "#import nibabel as nib\n",
    "\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if cuda is working\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBAL VARIABLES\n",
    "\n",
    "# using GPU?\n",
    "gpu = False\n",
    "\n",
    "# first time running? need to generate csv and npy files\n",
    "firstrun = True\n",
    "\n",
    "# use resampled (1x1x3 mm voxel size) or original data?\n",
    "useResampledData = True\n",
    "\n",
    "# directories where the files are\n",
    "traindir = r'C:\\Users\\Leo\\Documents\\UHN-MedImg3D-ML-quiz\\train'\n",
    "valdir = r'C:\\Users\\Leo\\Documents\\UHN-MedImg3D-ML-quiz\\validation'\n",
    "testdir = r'C:\\Users\\Leo\\Documents\\UHN-MedImg3D-ML-quiz\\test'\n",
    "\n",
    "csvpath = r'C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\csv files\\trainval_metadata.csv'   # csv with the image dimensions, image and mask file paths\n",
    "\n",
    "nnUNet_raw_dir = r'C:\\Users\\Leo\\OneDrive\\Documents\\UHN-MedImg3D-ML-quiz\\nnUnet_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\OneDrive\\Documents\\UHN-MedImg3D-ML-quiz\\nnUnet_raw\n"
     ]
    }
   ],
   "source": [
    "print(nnUNet_raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS FOR SITK and IMAGE AUGMENTATION\n",
    "\n",
    "def rotateImage(original, anglex, angley, anglez, interpolate='linear'):\n",
    "    \"\"\" Returns the 'rotated' 3d image about the physical center that is resampled based on the 'original' image\n",
    "    1. original - original image \n",
    "    2. angle x is roll / twisting the body like a rolling pin, turning in dance\n",
    "    3. angle y is yaw / rotating the body like a propeller blade, like break dancing\n",
    "    4. angle z - pitch / tilt along the superior/inferior axis (i.e trendelenburg)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if interpolate == 'linear':\n",
    "        interpolator = sitk.sitkLinear\n",
    "    elif interpolate == 'NN':\n",
    "        interpolator = sitk.sitkNearestNeighbor\n",
    "\n",
    "    radx = anglex * math.pi / 180\n",
    "    rady = angley * math.pi / 180\n",
    "    radz = anglez * math.pi / 180\n",
    "\n",
    "    origin = np.array(original.GetOrigin())\n",
    "    pixelcenter = np.array(sitk.GetSize(original)) / 2.\n",
    "    physicalcenter = sitk.TransformContinuousIndexToPhysicalPoint(pixelcenter)\n",
    "\n",
    "    transform = sitk.Euler3DTransform()\n",
    "    transform.SetCenter(physicalcenter)\n",
    "    transform.SetRotation(radz, rady, radx)    # note the order is z, y, x\n",
    "\n",
    "    unitvecs = np.transpose(np.reshape(original.GetDirection(), (-1, 3)))\n",
    "    #print(unitvecs)\n",
    "    matrix = np.reshape(transform.GetMatrix(), (-1, 3))\n",
    "    inverse = np.linalg.inv(matrix)\n",
    "\n",
    "\n",
    "    # the transform matrix is actually mapping backwards: post to pre\n",
    "    # therefore the forward transformation is the inverse matrix\n",
    "    transformedunitvecs = inverse @ unitvecs   # new i, j, k are columns\n",
    "    #print(transformedunitvecs)\n",
    "    newdirection = transformedunitvecs.flatten('F')    # flatten by column\n",
    "\n",
    "    print(newdirection)\n",
    "    neworigin = (matrix @ (origin - physicalcenter)) + physicalcenter\n",
    "\n",
    "    rotatedImage = sitk.Resample(original, original, transform, interpolator)\n",
    "    rotatedImage.SetDirection(newdirection)\n",
    "    rotatedImage.SetOrigin(neworigin)\n",
    "\n",
    "    return rotatedImage\n",
    "\n",
    "def flipImage(original):\n",
    "    \"\"\"Flips an SimpleITK over left/right axis\"\"\"\n",
    "    flipped = sitk.Flip(original, [True, False, False])\n",
    "    return flipped\n",
    "\n",
    "def flipslice(original):\n",
    "    \"\"\"Flips a numpy slice (2d image) \"\"\"\n",
    "    # flips 2D slice (reverses x indices)\n",
    "    flipped = np.flipud(original)  #np.fliplr(original)\n",
    "    return flipped\n",
    "\n",
    "def bbox_3D(img):\n",
    "    \"\"\"Finds the bounding box around a 3D image (numpy)\n",
    "    returns rmin, rmax, cmin, cmax, zmin, zmax (r = row, c = column)\"\"\"\n",
    "    try:    \n",
    "        z = np.any(img, axis=(1, 2))    #z\n",
    "        c = np.any(img, axis=(0, 1))    #x , (c = column)\n",
    "        r = np.any(img, axis=(0, 2))    #y , (r = row)\n",
    "\n",
    "        rmin, rmax = np.where(r)[0][[0, -1]]\n",
    "        cmin, cmax = np.where(c)[0][[0, -1]]\n",
    "        zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "        #x min max, y min max, z min max\n",
    "        return [rmin, rmax, cmin, cmax, zmin, zmax]\n",
    "    except:\n",
    "        return -1, -1, -1, -1, -1, -1\n",
    "\n",
    "\n",
    "def bbox_2D(img):\n",
    "    \"\"\"Finds the bounding box around a 2D image (numpy)\n",
    "    returns rmin, rmax, cmin, cmax (r = row, c = column)\n",
    "    If no elements exist, then returns (-1, -1, -1, -1)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        c = np.any(img, axis=0)    #y , (c = column)\n",
    "        r = np.any(img, axis=1)    #x , (r = row)\n",
    "\n",
    "        rmin, rmax = np.where(r)[0][[0, -1]]\n",
    "        cmin, cmax = np.where(c)[0][[0, -1]]\n",
    "    \n",
    "        return rmin, rmax, cmin, cmax\n",
    "    except:\n",
    "        return -1, -1, -1, -1\n",
    "\n",
    "\n",
    "def cropImage(image, threshold, xshift, yshift):\n",
    "    \"\"\"Crops SimpleITK image to remove pixels below a threshold (e.g. black space)\n",
    "    Can also shift by *xshift and *yshift (random shifts in pixels) for augmentation\"\"\"\n",
    "    # load image\n",
    "    npy = sitk.GetArrayFromImage(image)\n",
    "\n",
    "    # GET METADATA\n",
    "    direction = image.GetDirection()\n",
    "    spacing = image.GetSpacing()\n",
    "\n",
    "    # CALCULATE BOUNDING BOX OF BODY (removes black space)\n",
    "    mask = npy > threshold\n",
    "    [xmin, xmax, ymin, ymax, zmin, zmax] = bbox_3D(mask)\n",
    "\n",
    "    # check to make sure shifts do not extend outside boundaries of image\n",
    "    if xmin + xshift < 0 or xmax + xshift > npy.shape[2]:\n",
    "        xshift = 0\n",
    "\n",
    "    if ymin + yshift < 0 or ymax + yshift > npy.shape[1]:\n",
    "        yshift = 0\n",
    "\n",
    "    # CROP IMAGE\n",
    "    newnpy = npy[zmin:zmax, (ymin+yshift):(ymax+yshift), (xmin+xshift):(xmax+xshift)]\n",
    "\n",
    "    newimage = sitk.GetImageFromArray(newnpy)\n",
    "    topleft = [int(xmin+xshift), int(ymin+yshift), zmin]\n",
    "    neworigin = image.TransformIndexToPhysicalPoint(topleft)\n",
    "\n",
    "    newimage.SetOrigin(neworigin)\n",
    "    newimage.SetDirection(direction)\n",
    "    newimage.SetSpacing(spacing)\n",
    "\n",
    "    return newimage\n",
    "\n",
    "\n",
    "def squareImage(image):\n",
    "    \"\"\"Makes an SimpleITK image square by padding with zeros\n",
    "    (square meaning width = height)\"\"\"\n",
    "    [numcols, numrows, numslices] = image.GetSize()\n",
    "    npy = sitk.GetArrayFromImage(image)\n",
    "\n",
    "    if numcols < numrows:    #pad columns\n",
    "        numzerostopad = numrows - numcols\n",
    "        leftpad = int(numzerostopad / 2)\n",
    "        rightpad = numzerostopad - leftpad\n",
    "\n",
    "        newnpy = np.concatenate((np.zeros([numslices, numrows, leftpad]), npy, np.zeros([numslices, numrows, rightpad])), axis=2)\n",
    "\n",
    "        topleft = [-leftpad, 0, 0]\n",
    "        neworigin = image.TransformIndexToPhysicalPoint(topleft)\n",
    "\n",
    "    elif numrows <= numcols:  #pad rows\n",
    "        numzerostopad = numcols - numrows\n",
    "        toppad = int(numzerostopad / 2)\n",
    "        botpad = numzerostopad - toppad\n",
    "\n",
    "        newnpy = np.concatenate((np.zeros([numslices, toppad, numcols]), npy, np.zeros([numslices, botpad, numcols])), axis=1)\n",
    "\n",
    "        topleft = [0, -toppad, 0]\n",
    "        neworigin = image.TransformIndexToPhysicalPoint(topleft)\n",
    "\n",
    "    paddedimg = sitk.GetImageFromArray(newnpy)\n",
    "    paddedimg.SetOrigin(neworigin)\n",
    "    paddedimg.SetDirection(image.GetDirection())\n",
    "    paddedimg.SetSpacing(image.GetSpacing())\n",
    "\n",
    "    return paddedimg\n",
    "\n",
    "def resampleImage(image, finalsize, interpolation='linear'):\n",
    "    \"\"\"Resamples SimpleITK image to finalsize x finalsize (width and height in pixels)\n",
    "    Preserves the original physical size of the image and number of slices\n",
    "    Changes the resolution so that the new image has numslices x *finalsize x *finalsize dimensions\"\"\"\n",
    "    \n",
    "    size = image.GetSize()\n",
    "    numslices = size[2]\n",
    "    squaresize = size[1]\n",
    "\n",
    "    # RESAMPLE TO finalsize x finalsize\n",
    "    finalnpy = np.zeros([numslices, finalsize, finalsize])\n",
    "    reference = sitk.GetImageFromArray(finalnpy)\n",
    "    reference.SetOrigin(image.GetOrigin())\n",
    "    reference.SetDirection(image.GetDirection())\n",
    "\n",
    "    spacing = image.GetSpacing()\n",
    "    newspacing = np.zeros(3)\n",
    "    newspacing[0:2] = (squaresize - 1) * np.array(spacing[0:2]) / (finalsize - 1)\n",
    "    newspacing[2] = spacing[2]\n",
    "    reference.SetSpacing(newspacing)\n",
    "\n",
    "\n",
    "    # MAKING RESAMPLING FILTER\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetReferenceImage(reference)\n",
    "    if interpolation == 'linear':\n",
    "        resample.SetInterpolator(sitk.sitkLinear)\n",
    "    elif interpolation == 'NN':\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "\n",
    "    # RESAMPLE TO finalsize x finalsize x n\n",
    "    resampledimg = resample.Execute(image)\n",
    "\n",
    "    return resampledimg\n",
    "\n",
    "\n",
    "def projectImage(reference, moving, interpolate = 'linear'):\n",
    "    \"\"\"Projects an SimpleITK image (*moving onto *reference)\n",
    "    interpolate* = linear or NN (nearest neighbor)\"\"\"\n",
    "    \n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetReferenceImage(reference)\n",
    "    if interpolate == 'linear':\n",
    "        resample.SetInterpolator(sitk.sitkLinear)\n",
    "    elif interpolate == 'NN':\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "\n",
    "    resampledimg = resample.Execute(moving)\n",
    "\n",
    "    return resampledimg\n",
    "\n",
    "\n",
    "def resampleImageToVoxelSize(image, voxelx, voxely, voxelz, interpolation='linear'):\n",
    "    \"\"\"Resamples SimpleITK *image* to spacing *[voxelx, voxely, voxelz] in mm\n",
    "    Preserves the original physical size of the image\n",
    "    *voxelz is slice thickness (usually)\n",
    "    *voxelx and *voxely are voxel width and height, respectively\n",
    "    \"\"\"\n",
    "    \n",
    "    original_spacing = image.GetSpacing()\n",
    "    original_size = image.GetSize()\n",
    "    \n",
    "    new_spacing = [voxelx, voxely, voxelz]\n",
    "    new_size = [int(round(osz*ospc/nspc)) for osz,ospc,nspc in zip(original_size, original_spacing, new_spacing)]\n",
    "    # new dimension will be original size * original spacing / new spacing\n",
    "    # based on physical distance formula: \n",
    "    #    original size (pixel) * original spacing (mm / pixel) = new size (pixel) * new spacing (mm / pixel)\n",
    "    \n",
    "    if interpolation == 'linear':\n",
    "        interpolator = sitk.sitkLinear\n",
    "    elif interpolation == 'NN':\n",
    "        interpolator = sitk.sitkNearestNeighbor\n",
    "    \n",
    "    # creates new image\n",
    "    new_image = sitk.Resample(image, new_size, sitk.Transform(), interpolator,\n",
    "                         image.GetOrigin(), new_spacing, image.GetDirection(), 0,\n",
    "                         image.GetPixelID())\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "\n",
    "def windowImage(image, window_width, window_center, output_min=0, output_max=255):\n",
    "    \"\"\"Normalizes SimpleITK *image* (CT scan) based on window specification\n",
    "    (example, abdominal soft tissue window is W = 400, C = 50, or -350 to 450)\n",
    "    Clips values above 0 and 1\n",
    "    \"\"\"\n",
    "    \n",
    "    window_min = window_center - window_width / 2\n",
    "    window_max = window_center + window_width / 2\n",
    "    \n",
    "    output_min = 0\n",
    "    output_max = 255\n",
    "    \n",
    "    windowed_image = sitk.IntensityWindowing(image, window_min, window_max, output_min, output_max)\n",
    "    \n",
    "    return windowed_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS FOR READING/LOADING THE DATA\n",
    "\n",
    "def getImageAndMaskFilePaths(train_or_val, subtype):\n",
    "    '''\n",
    "    returns a list of file paths, sorted alphabetically\n",
    "    [image_niftis_gz, mask_niftis_gz, image_niftis_panorama, mask_niftis_panorama]\n",
    "    input: training or validation images ('train' or 'val', and the subtype {0, 1, or 2}\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if train_or_val == 'train':\n",
    "        rootdir = traindir        \n",
    "    elif train_or_val == 'val':\n",
    "        rootdir = valdir\n",
    "        \n",
    "    subtypedir = os.path.join(rootdir, 'subtype' + str(subtype))\n",
    "    \n",
    "    \n",
    "    ## this gets all of the file paths in the subtype folder for the image and mask files\n",
    "    \n",
    "    # example file path for a training image of subtype 0:\n",
    "    #   '/kaggle/input/pancreas/train/subtype0/quiz_0_041_0000.nii'\n",
    "        \n",
    "    image_niftis_gz = [os.path.join(subtypedir, file_name) for file_name in os.listdir(subtypedir) if '0000' in file_name]\n",
    "    image_niftis_gz.sort()\n",
    "    \n",
    "    mask_niftis_gz = [file_name.partition(\"_0000\")[0] + '.nii' for file_name in image_niftis_gz]\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## however the actual CT / segmentation is within the zipped files:\n",
    "    #   '/kaggle/input/pancreas/train/subtype0/quiz_0_041_0000.nii/PANORAMA_101960_00001_0000.nii'\n",
    "    \n",
    "    \n",
    "    return [image_niftis_gz, mask_niftis_gz]\n",
    "   \n",
    "    \n",
    "    \n",
    "def getImageFileDetails(imageniftis, maskniftis, train_or_val):\n",
    "    '''Creates a dataframe with the following:\n",
    "        study ID // subtype // CT width/height/depth // pancreas width/height/depth // lesion width/height/depth  // pancreas xmin/xmax / ymin/ymax / zmin/zmax \n",
    "          // CT spacing x/y/z \n",
    "       \n",
    "       Input is a list of image nifti file paths, mask nifti file paths (panorama), and {'train' or 'val'}\n",
    "    '''\n",
    "    \n",
    "    ### THIS IS NOT USED TO SPEED UP TRAINING ###\n",
    "    ### (WAS INITIALLY USED IN 2D and 3D MODELS FROM SCRATCH)\n",
    "    \n",
    "    maindf = pd.DataFrame({'ID': pd.Series(dtype='string'),\n",
    "                   'train/val': pd.Series(dtype='string'),\n",
    "                   'subtype': pd.Series(dtype='int'),\n",
    "                   'CT width': pd.Series(dtype='int'),\n",
    "                   'CT height': pd.Series(dtype='int'),\n",
    "                   'CT depth': pd.Series(dtype='int'),\n",
    "                   'panc width': pd.Series(dtype='int'),\n",
    "                   'panc height': pd.Series(dtype='int'),\n",
    "                   'panc depth': pd.Series(dtype='int'),\n",
    "                   'lesion width': pd.Series(dtype='int'),\n",
    "                   'lesion height': pd.Series(dtype='int'),\n",
    "                   'lesion depth': pd.Series(dtype='int'),\n",
    "                   'panc xmin': pd.Series(dtype='int'),\n",
    "                   'panc xmax': pd.Series(dtype='int'),\n",
    "                   'panc ymin': pd.Series(dtype='int'),\n",
    "                   'panc ymax': pd.Series(dtype='int'),\n",
    "                   'panc zmin': pd.Series(dtype='int'),\n",
    "                   'panc zmax': pd.Series(dtype='int'),\n",
    "                   'CT spacing x': pd.Series(dtype='float'),\n",
    "                   'CT spacing y': pd.Series(dtype='float'),\n",
    "                   'CT spacing z': pd.Series(dtype='float'),\n",
    "                   'CT direction x': pd.Series(dtype='float'),\n",
    "                   'CT direction y': pd.Series(dtype='float'),\n",
    "                   'CT direction z': pd.Series(dtype='float'),        \n",
    "                   'image path': pd.Series(dtype='string'),\n",
    "                   'mask path': pd.Series(dtype='string')\n",
    "                  })\n",
    "\n",
    "    for i, imagepath in enumerate(imageniftis):\n",
    "        maskpath = maskniftis[i]\n",
    "        \n",
    "        ## gets the subtype, ID for the current image\n",
    "        # (format of the file name is: /kaggle/input/pancreas/train/subtype0/quiz_0_041_0000.nii/PANORAMA_101960_00001_0000.nii)\n",
    "        subfolder = [folder for folder in imagepath.split('/') if 'quiz' in folder][0]   #gets the subdirectory with \"quiz\"\n",
    "        \n",
    "        subtype = subfolder.split('_')[1]\n",
    "        ID = int(subfolder.split('_')[2])\n",
    "        \n",
    "        \n",
    "        ## gets the dimensions of CT image in pixels\n",
    "        img = sitk.ReadImage(imagepath)\n",
    "        \n",
    "        CTwidth = img.GetWidth()\n",
    "        CTheight = img.GetHeight()\n",
    "        CTdepth = img.GetDepth()\n",
    "                \n",
    "        ## gets the dimensions of the pancreas and lesion segmentations\n",
    "        mask = sitk.ReadImage(maskpath)\n",
    "        mask_vol = sitk.GetArrayFromImage(mask)\n",
    "    \n",
    "        [xmin1, xmax1, ymin1, ymax1, zmin1, zmax1] = bbox_3D(np.int64(mask_vol) == 1)   # 1 = pancreas\n",
    "        [xmin2, xmax2, ymin2, ymax2, zmin2, zmax2] = bbox_3D(np.int64(mask_vol) == 2)   # 2 = lesion\n",
    " \n",
    "        width1 = xmax1 - xmin1\n",
    "        height1 = ymax1 - ymin1\n",
    "        depth1 = zmax1 - zmin1\n",
    "        \n",
    "        width2 = xmax2 - xmin2\n",
    "        height2 = ymax2 - ymin2\n",
    "        depth2 = zmax2 - zmin2\n",
    "\n",
    "        ## gets the spacing (mm) and 'direction' vectors of x/y/z axis\n",
    "        spacing = img.GetSpacing()\n",
    "        direction = img.GetDirection()\n",
    "        directionx = str(direction[0:2])\n",
    "        directiony = str(direction[3:5])\n",
    "        directionz = str(direction[6:8])\n",
    "        \n",
    "        ## eventual numpy file names\n",
    "        image_filename =  os.path.join(numpydir, str(train_or_val) + '_' + \"{:03d}\".format(ID) + '_image.npy')\n",
    "        mask_filename = os.path.join(numpydir, str(train_or_val) + '_' + \"{:03d}\".format(ID) + '_mask.npy')\n",
    "\n",
    "        \n",
    "        # study ID // subtype // CT width/height/depth // pancreas width/height/depth // lesion width/height/depth  // pancreas xmin/xmax / ymin/ymax / zmin/zmax \n",
    "          #   // CT spacing x/y/z \n",
    "        df = pd.DataFrame({'train/val':train_or_val, 'ID':ID, 'subtype':subtype, 'CT width':CTwidth, 'CT height':CTheight, 'CT depth':CTdepth, \n",
    "                           'panc width':width1, 'panc height':height1, 'panc depth':depth1, \n",
    "                           'lesion width':width2, 'lesion height':height2, 'lesion depth':depth2,\n",
    "                           'panc xmin':xmin1, 'panc xmax':xmax1, 'panc ymin': ymin1, 'panc ymax':ymax1, 'panc zmin': zmin1, 'panc zmax':zmax1,\n",
    "                           'CT spacing x':spacing[0], 'CT spacing y':spacing[1], 'CT spacing z':spacing[2], \n",
    "                           'CT direction x':directionx, 'CT direction y':directiony, 'CT direction z':directionz, \n",
    "                           'image path': imagepath, 'mask path': maskpath, 'image npy': image_filename, 'mask npy':mask_filename}, index = [0])\n",
    "                           \n",
    "        \n",
    "        maindf = pd.concat([maindf, df])\n",
    "                 \n",
    "            \n",
    "    return maindf\n",
    "\n",
    "def getImageFileDataFrame(imageniftis_gz, maskniftis_gz, train_or_val):\n",
    "    '''Creates a dataframe with the following:\n",
    "        study ID // train/val // subtype // image gz path // mask gz path // image pano path // mask pano path\n",
    "       \n",
    "       Input is a list of image nifti file paths, mask nifti file paths (panorama), and {'train' or 'val'}\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    maindf = pd.DataFrame({'ID': pd.Series(dtype='string'),\n",
    "                           'train/val': pd.Series(dtype='string'),\n",
    "                           'subtype': pd.Series(dtype='string'),\n",
    "                           'image gz path': pd.Series(dtype='string'),\n",
    "                           'mask gz path': pd.Series(dtype='string'),\n",
    "                          })\n",
    "\n",
    "    for i, imagepath_gz in enumerate(imageniftis_gz):\n",
    "        maskpath_gz = maskniftis_gz[i]\n",
    "        \n",
    "        ## gets the subtype, ID for the current image\n",
    "        # (format of the file name is: /kaggle/input/pancreas/train/subtype0/quiz_0_041_0000.nii/PANORAMA_101960_00001_0000.nii)\n",
    "        subfolder = [folder for folder in imagepath_gz.split('/') if 'quiz' in folder][0]   #gets the subdirectory with \"quiz\"\n",
    "        \n",
    "        subtype = subfolder.split('_')[1]\n",
    "        ID = subfolder.split('_')[2]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # study ID // subtype // CT width/height/depth // pancreas width/height/depth // lesion width/height/depth  // pancreas xmin/xmax / ymin/ymax / zmin/zmax \n",
    "          #   // CT spacing x/y/z \n",
    "        df = pd.DataFrame({'train/val':train_or_val, 'ID':ID, 'subtype':subtype,\n",
    "                           'image gz path': imagepath_gz, 'mask gz path': maskpath_gz\n",
    "                           }, index = [0])\n",
    "                           \n",
    "        \n",
    "        maindf = pd.concat([maindf, df])\n",
    "                 \n",
    "            \n",
    "    return maindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# this loop runs through all of the training and validation images, and builds a dataframe with the metadata\n",
    "\n",
    "firstloop = True\n",
    "\n",
    "for train_or_val in ['train', 'val']:\n",
    "    for subtype in range(3):\n",
    "        images_gz, masks_gz = getImageAndMaskFilePaths(train_or_val, subtype)\n",
    "        \n",
    "        subtypedf = getImageFileDataFrame(images_gz, masks_gz, train_or_val)\n",
    "\n",
    "        if firstloop:\n",
    "            maindf = subtypedf\n",
    "            firstloop = False\n",
    "        else:\n",
    "            maindf = pd.concat([maindf, subtypedf])\n",
    "        \n",
    "\n",
    "# saving the metadata to csv file\n",
    "\n",
    "maindf.to_csv(csvpath, index = False)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load main dataframe with all of information\n",
    "maindf = pd.read_csv(csvpath, dtype='string')\n",
    "\n",
    "traindf =  maindf[maindf['train/val'] == 'train']\n",
    "valdf = maindf[maindf['train/val'] == 'val']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying data to folders based on nnUnet data organization\n",
    "\n",
    "### nnUnet data folder structure\n",
    "nnUNet_raw/ <br>\n",
    "1. Dataset001_BrainTumour <br>\n",
    "    - dataset.json <br>\n",
    "    - imagesTr <br>\n",
    "    - imagesTs  # optional  <br>\n",
    "    - labelsTr  <br>\n",
    "<br>\n",
    "- imagesTr contains the images belonging to the training cases. nnU-Net will perform pipeline configuration, training with cross-validation, as well as finding postprocessing and the best ensemble using this data.\n",
    "- imagesTs (optional) contains the images that belong to the test cases. nnU-Net does not use them! This could just be a convenient location for you to store these images. Remnant of the Medical Segmentation Decathlon folder structure.\n",
    "- labelsTr contains the images with the ground truth segmentation maps for the training cases.\n",
    "- dataset.json contains metadata of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. nnUNet_raw/Dataset002_Heart/\n",
    "    1. ├── dataset.json\n",
    "    2. ├── imagesTr\n",
    "        1. ├── la_003_0000.nii.gz\n",
    "        2. ├── la_004_0000.nii.gz\n",
    "        3. ├── ...\n",
    "    3. ├── imagesTs\n",
    "        1. ├── la_001_0000.nii.gz\n",
    "        2. ├── la_002_0000.nii.gz\n",
    "        3. ├── ...\n",
    "    4. └── labelsTr\n",
    "        1. ├── la_003.nii.gz\n",
    "        2. ├── la_004.nii.gz\n",
    "        3. ├── ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyRawFiles(df, images_folder, labels_folder):\n",
    "    for i, row in df.iterrows():\n",
    "        if i % 10 == 9:\n",
    "            print(i+1)\n",
    "        ID = row['ID']\n",
    "    \n",
    "        old_image_path = row['image gz path']\n",
    "        old_mask_path = row['mask gz path']\n",
    "    \n",
    "        image_img = sitk.ReadImage(old_image_path)\n",
    "        mask_img = sitk.ReadImage(old_mask_path, sitk.sitkInt16)    # get rid of rounding error for segmentations\n",
    "        new_mask_img = projectImage(image_img, mask_img, interpolate='NN')   # ensures that the voxel spacing is equal\n",
    "        \n",
    "        ### new file name scheme\n",
    "        ### new_image_name = quiz_[ID]_0000.nii.gz\n",
    "        ### new_mask_name = quiz_[ID].nii.gz\n",
    "    \n",
    "        new_image_name = 'quiz_' + ID + '_0000.nii.gz'\n",
    "        new_mask_name = 'quiz_' + ID + '.nii.gz'\n",
    "    \n",
    "        new_image_path = os.path.join(images_folder, new_image_name)\n",
    "        new_mask_path = os.path.join(labels_folder, new_mask_name)\n",
    "    \n",
    "        sitk.WriteImage(image_img, new_image_path)        \n",
    "        sitk.WriteImage(new_mask_img, new_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying training files...\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      " -- done\n",
      "copying val files\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'images_Ts_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -- done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopying val files\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m copyRawFiles(valdf, images_Ts_folder, labeslTs_folder)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  -- done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images_Ts_folder' is not defined"
     ]
    }
   ],
   "source": [
    "raw_folder = r'C:\\Users\\Leo\\Documents\\UHN-MedImg3D-ML-quiz\\nnUnet_raw'\n",
    "data_folder = r'C:\\Users\\Leo\\Documents\\UHN-MedImg3D-ML-quiz\\nnUnet_raw\\Dataset001_Pancreas'\n",
    "\n",
    "imagesTr_folder = os.path.join(data_folder, 'imagesTr')\n",
    "labelsTr_folder = os.path.join(data_folder, 'labelsTr')\n",
    "\n",
    "for folder in [raw_folder, data_folder, imagesTr_folder, imagesTs_folder, labelsTr_folder, labelsTs_folder]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "\n",
    "print('copying training files...')\n",
    "\n",
    "copyRawFiles(traindf, imagesTr_folder, labelsTr_folder)\n",
    "\n",
    "print(' -- done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying val files\n",
      "260\n",
      "270\n",
      "280\n",
      "  -- done\n"
     ]
    }
   ],
   "source": [
    "imagesTs_folder = os.path.join(data_folder, 'imagesTs')\n",
    "labelsTs_folder = os.path.join(data_folder, 'labelsTs')\n",
    "\n",
    "print('copying val files')\n",
    "copyRawFiles(valdf, imagesTs_folder, labelsTs_folder)\n",
    "\n",
    "    \n",
    "print('  -- done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json_path = os.path.join(data_folder, 'dataset.json')\n",
    "\n",
    "dictionary = {\n",
    "    \"channel_names\": {  # formerly modalities\n",
    "        \"0\": \"CT\", \n",
    "        }, \n",
    "    \n",
    "    \"labels\": {  # THIS IS DIFFERENT NOW!\n",
    "        \"background\": 0,\n",
    "        \"pancreas\": 1,\n",
    "        \"lesion\": 2\n",
    "        }, \n",
    " \n",
    "    \"numTraining\": 252, \n",
    " \n",
    "    \"file_ending\": \".nii.gz\",\n",
    " \n",
    "    \"overwrite_image_reader_writer\": \"SimpleITKIO\"  # optional! If not provided nnU-Net will automatically determine the ReaderWriter\n",
    "}\n",
    " \n",
    "json_object = json.dumps(dictionary, indent=4)\n",
    " \n",
    "with open(dataset_json_path, \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training nnUnet\n",
    "\n",
    "## Pre-processing\n",
    "\n",
    "!nnUNetv2_plan_and_preprocess -d DATASET_ID --verify_dataset_integrity\n",
    "<br>\n",
    "<br>\n",
    "!nnUNet_raw=\"/kaggle/working/nnUnet_raw\" nnUNet_preprocessed=\"/kaggle/working/nnUNet_preprocessed\" nnUNet_results=\"/kaggle/working/nnUNet_results\" nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity  -pl nnUNetPlannerResEncM\n",
    "<br>\n",
    "(for ResNet encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset001_Pancreas\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [ 59. 118. 181.], 3d_lowres: [59, 118, 181]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 132, 'patch_size': (128, 192), 'median_image_size_in_voxels': array([118., 181.]), 'spacing': array([0.73046875, 0.73046875]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 3, 'patch_size': (64, 128, 192), 'median_image_size_in_voxels': array([ 59., 118., 181.]), 'spacing': array([2.        , 0.73046875, 0.73046875]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to C:\\Users\\Leo\\OneDrive\\Documents\\UHN-MedImg3D-ML-quiz\\nnUNet_preprocessed\\Dataset001_Pancreas\\nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset001_Pancreas\n",
      "Configuration: 2d...\n",
      "Configuration: 3d_fullres...\n",
      "Configuration: 3d_lowres...\n",
      "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset001_Pancreas. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/252 [00:00<?, ?it/s]\n",
      "  0%|          | 1/252 [00:07<29:25,  7.03s/it]\n",
      "  1%|          | 2/252 [00:07<12:18,  2.96s/it]\n",
      "  1%|1         | 3/252 [00:08<08:45,  2.11s/it]\n",
      "  2%|1         | 4/252 [00:08<06:16,  1.52s/it]\n",
      "  2%|1         | 5/252 [00:08<04:08,  1.01s/it]\n",
      "  2%|2         | 6/252 [00:09<03:00,  1.37it/s]\n",
      "  3%|3         | 8/252 [00:09<01:36,  2.52it/s]\n",
      "  4%|3         | 10/252 [00:09<01:16,  3.17it/s]\n",
      "  5%|4         | 12/252 [00:10<01:05,  3.66it/s]\n",
      "  5%|5         | 13/252 [00:10<00:56,  4.22it/s]\n",
      "  6%|5         | 15/252 [00:11<01:15,  3.15it/s]\n",
      "  6%|6         | 16/252 [00:11<01:19,  2.98it/s]\n",
      "  7%|6         | 17/252 [00:11<01:11,  3.28it/s]\n",
      "  8%|7         | 19/252 [00:12<01:10,  3.30it/s]\n",
      "  9%|8         | 22/252 [00:12<00:41,  5.58it/s]\n",
      " 10%|9         | 24/252 [00:12<00:49,  4.62it/s]\n",
      " 10%|9         | 25/252 [00:13<00:48,  4.68it/s]\n",
      " 10%|#         | 26/252 [00:13<00:56,  3.97it/s]\n",
      " 11%|#         | 27/252 [00:14<01:19,  2.83it/s]\n",
      " 11%|#1        | 28/252 [00:14<01:05,  3.42it/s]\n",
      " 12%|#1        | 29/252 [00:14<01:05,  3.39it/s]\n",
      " 12%|#1        | 30/252 [00:14<00:59,  3.71it/s]\n",
      " 12%|#2        | 31/252 [00:14<00:49,  4.49it/s]\n",
      " 13%|#2        | 32/252 [00:15<00:47,  4.62it/s]\n",
      " 14%|#3        | 35/252 [00:15<00:25,  8.62it/s]\n",
      " 15%|#4        | 37/252 [00:15<00:31,  6.89it/s]\n",
      " 15%|#5        | 39/252 [00:16<00:45,  4.69it/s]\n",
      " 16%|#5        | 40/252 [00:17<01:09,  3.07it/s]\n",
      " 17%|#6        | 42/252 [00:17<01:02,  3.34it/s]\n",
      " 17%|#7        | 44/252 [00:17<00:48,  4.29it/s]\n",
      " 18%|#7        | 45/252 [00:18<00:50,  4.06it/s]\n",
      " 18%|#8        | 46/252 [00:18<00:48,  4.23it/s]\n",
      " 19%|#9        | 48/252 [00:18<00:37,  5.42it/s]\n",
      " 20%|#9        | 50/252 [00:18<00:31,  6.45it/s]\n",
      " 20%|##        | 51/252 [00:18<00:28,  6.94it/s]\n",
      " 21%|##        | 52/252 [00:19<00:49,  4.06it/s]\n",
      " 21%|##1       | 53/252 [00:19<00:42,  4.74it/s]\n",
      " 21%|##1       | 54/252 [00:20<01:01,  3.21it/s]\n",
      " 22%|##1       | 55/252 [00:21<01:27,  2.25it/s]\n",
      " 22%|##2       | 56/252 [00:21<01:08,  2.86it/s]\n",
      " 23%|##2       | 57/252 [00:21<00:54,  3.59it/s]\n",
      " 23%|##3       | 59/252 [00:21<00:38,  5.02it/s]\n",
      " 24%|##3       | 60/252 [00:21<00:33,  5.71it/s]\n",
      " 24%|##4       | 61/252 [00:21<00:29,  6.41it/s]\n",
      " 25%|##5       | 64/252 [00:21<00:20,  9.15it/s]\n",
      " 26%|##6       | 66/252 [00:21<00:16, 11.15it/s]\n",
      " 27%|##6       | 68/252 [00:22<00:20,  9.15it/s]\n",
      " 28%|##7       | 70/252 [00:22<00:25,  7.24it/s]\n",
      " 28%|##8       | 71/252 [00:23<00:33,  5.36it/s]\n",
      " 29%|##8       | 72/252 [00:23<00:34,  5.27it/s]\n",
      " 29%|##9       | 74/252 [00:23<00:31,  5.71it/s]\n",
      " 30%|##9       | 75/252 [00:23<00:35,  4.96it/s]\n",
      " 30%|###       | 76/252 [00:23<00:31,  5.61it/s]\n",
      " 31%|###       | 78/252 [00:24<00:22,  7.84it/s]\n",
      " 32%|###1      | 80/252 [00:24<00:20,  8.49it/s]\n",
      " 33%|###2      | 82/252 [00:24<00:19,  8.93it/s]\n",
      " 33%|###3      | 84/252 [00:24<00:18,  9.24it/s]\n",
      " 34%|###4      | 86/252 [00:25<00:28,  5.89it/s]\n",
      " 35%|###4      | 87/252 [00:25<00:28,  5.70it/s]\n",
      " 35%|###4      | 88/252 [00:26<00:46,  3.50it/s]\n",
      " 35%|###5      | 89/252 [00:26<00:39,  4.11it/s]\n",
      " 36%|###5      | 90/252 [00:26<00:41,  3.88it/s]\n",
      " 36%|###6      | 91/252 [00:26<00:43,  3.71it/s]\n",
      " 37%|###6      | 92/252 [00:26<00:35,  4.47it/s]\n",
      " 37%|###6      | 93/252 [00:27<00:52,  3.03it/s]\n",
      " 37%|###7      | 94/252 [00:27<00:46,  3.41it/s]\n",
      " 38%|###8      | 97/252 [00:27<00:23,  6.66it/s]\n",
      " 39%|###9      | 99/252 [00:28<00:30,  4.94it/s]\n",
      " 40%|####      | 101/252 [00:28<00:22,  6.57it/s]\n",
      " 41%|####      | 103/252 [00:28<00:20,  7.37it/s]\n",
      " 42%|####1     | 105/252 [00:29<00:20,  7.12it/s]\n",
      " 42%|####2     | 107/252 [00:29<00:27,  5.26it/s]\n",
      " 43%|####2     | 108/252 [00:29<00:27,  5.20it/s]\n",
      " 43%|####3     | 109/252 [00:29<00:24,  5.77it/s]\n",
      " 44%|####3     | 110/252 [00:30<00:25,  5.57it/s]\n",
      " 44%|####4     | 112/252 [00:30<00:18,  7.77it/s]\n",
      " 45%|####5     | 114/252 [00:30<00:18,  7.32it/s]\n",
      " 46%|####5     | 115/252 [00:30<00:20,  6.67it/s]\n",
      " 46%|####6     | 116/252 [00:31<00:25,  5.43it/s]\n",
      " 46%|####6     | 117/252 [00:31<00:28,  4.70it/s]\n",
      " 47%|####7     | 119/252 [00:32<00:41,  3.22it/s]\n",
      " 48%|####7     | 120/252 [00:32<00:46,  2.82it/s]\n",
      " 48%|####8     | 121/252 [00:32<00:41,  3.16it/s]\n",
      " 49%|####8     | 123/252 [00:33<00:29,  4.39it/s]\n",
      " 49%|####9     | 124/252 [00:33<00:37,  3.44it/s]\n",
      " 50%|####9     | 125/252 [00:33<00:34,  3.72it/s]\n",
      " 50%|#####     | 126/252 [00:34<00:31,  3.98it/s]\n",
      " 50%|#####     | 127/252 [00:34<00:26,  4.75it/s]\n",
      " 51%|#####     | 128/252 [00:34<00:25,  4.81it/s]\n",
      " 51%|#####1    | 129/252 [00:34<00:21,  5.64it/s]\n",
      " 52%|#####1    | 131/252 [00:34<00:17,  6.99it/s]\n",
      " 52%|#####2    | 132/252 [00:34<00:15,  7.53it/s]\n",
      " 53%|#####2    | 133/252 [00:35<00:24,  4.94it/s]\n",
      " 53%|#####3    | 134/252 [00:35<00:20,  5.72it/s]\n",
      " 54%|#####3    | 135/252 [00:35<00:27,  4.20it/s]\n",
      " 54%|#####3    | 136/252 [00:36<00:32,  3.52it/s]\n",
      " 54%|#####4    | 137/252 [00:37<00:53,  2.16it/s]\n",
      " 55%|#####4    | 138/252 [00:37<00:54,  2.11it/s]\n",
      " 55%|#####5    | 139/252 [00:37<00:44,  2.54it/s]\n",
      " 56%|#####5    | 140/252 [00:37<00:37,  2.97it/s]\n",
      " 56%|#####5    | 141/252 [00:38<00:36,  3.06it/s]\n",
      " 56%|#####6    | 142/252 [00:38<00:28,  3.86it/s]\n",
      " 57%|#####6    | 143/252 [00:38<00:23,  4.72it/s]\n",
      " 58%|#####7    | 145/252 [00:38<00:22,  4.83it/s]\n",
      " 58%|#####8    | 147/252 [00:39<00:19,  5.42it/s]\n",
      " 59%|#####9    | 149/252 [00:39<00:14,  7.35it/s]\n",
      " 60%|#####9    | 151/252 [00:39<00:12,  8.07it/s]\n",
      " 61%|######    | 153/252 [00:39<00:11,  8.60it/s]\n",
      " 62%|######1   | 155/252 [00:39<00:09, 10.50it/s]\n",
      " 62%|######2   | 157/252 [00:40<00:15,  6.26it/s]\n",
      " 63%|######3   | 159/252 [00:40<00:16,  5.80it/s]\n",
      " 63%|######3   | 160/252 [00:40<00:16,  5.63it/s]\n",
      " 64%|######4   | 162/252 [00:41<00:22,  3.94it/s]\n",
      " 65%|######4   | 163/252 [00:41<00:21,  4.10it/s]\n",
      " 65%|######5   | 164/252 [00:42<00:18,  4.71it/s]\n",
      " 65%|######5   | 165/252 [00:42<00:18,  4.77it/s]\n",
      " 66%|######5   | 166/252 [00:42<00:20,  4.29it/s]\n",
      " 66%|######6   | 167/252 [00:42<00:23,  3.60it/s]\n",
      " 67%|######6   | 168/252 [00:43<00:21,  3.90it/s]\n",
      " 67%|######7   | 169/252 [00:43<00:20,  4.15it/s]\n",
      " 67%|######7   | 170/252 [00:43<00:16,  4.93it/s]\n",
      " 68%|######7   | 171/252 [00:43<00:18,  4.32it/s]\n",
      " 68%|######8   | 172/252 [00:43<00:17,  4.49it/s]\n",
      " 69%|######8   | 173/252 [00:44<00:19,  4.07it/s]\n",
      " 69%|######9   | 174/252 [00:44<00:29,  2.62it/s]\n",
      " 69%|######9   | 175/252 [00:45<00:22,  3.36it/s]\n",
      " 70%|######9   | 176/252 [00:45<00:18,  4.18it/s]\n",
      " 71%|#######   | 178/252 [00:45<00:14,  5.04it/s]\n",
      " 71%|#######1  | 180/252 [00:45<00:10,  7.16it/s]\n",
      " 72%|#######2  | 182/252 [00:45<00:11,  6.18it/s]\n",
      " 73%|#######2  | 183/252 [00:46<00:10,  6.70it/s]\n",
      " 73%|#######3  | 184/252 [00:46<00:10,  6.21it/s]\n",
      " 73%|#######3  | 185/252 [00:46<00:09,  6.83it/s]\n",
      " 75%|#######4  | 188/252 [00:46<00:07,  8.14it/s]\n",
      " 75%|#######5  | 189/252 [00:46<00:08,  7.24it/s]\n",
      " 75%|#######5  | 190/252 [00:46<00:08,  7.70it/s]\n",
      " 76%|#######5  | 191/252 [00:47<00:10,  5.85it/s]\n",
      " 76%|#######6  | 192/252 [00:47<00:13,  4.36it/s]\n",
      " 77%|#######6  | 194/252 [00:47<00:08,  6.48it/s]\n",
      " 78%|#######7  | 196/252 [00:48<00:09,  5.82it/s]\n",
      " 78%|#######8  | 197/252 [00:48<00:09,  5.62it/s]\n",
      " 79%|#######8  | 198/252 [00:48<00:12,  4.35it/s]\n",
      " 79%|#######8  | 199/252 [00:49<00:17,  3.10it/s]\n",
      " 79%|#######9  | 200/252 [00:49<00:13,  3.78it/s]\n",
      " 80%|#######9  | 201/252 [00:49<00:11,  4.55it/s]\n",
      " 80%|########  | 202/252 [00:49<00:12,  4.12it/s]\n",
      " 81%|########  | 203/252 [00:49<00:09,  4.95it/s]\n",
      " 82%|########1 | 206/252 [00:50<00:05,  7.82it/s]\n",
      " 83%|########2 | 208/252 [00:50<00:08,  5.33it/s]\n",
      " 83%|########3 | 210/252 [00:50<00:06,  6.29it/s]\n",
      " 84%|########3 | 211/252 [00:51<00:06,  6.77it/s]\n",
      " 85%|########4 | 213/252 [00:51<00:05,  6.72it/s]\n",
      " 85%|########4 | 214/252 [00:51<00:05,  7.19it/s]\n",
      " 86%|########6 | 217/252 [00:51<00:03, 11.08it/s]\n",
      " 87%|########6 | 219/252 [00:52<00:05,  5.87it/s]\n",
      " 88%|########7 | 221/252 [00:52<00:04,  7.48it/s]\n",
      " 88%|########8 | 223/252 [00:52<00:05,  5.42it/s]\n",
      " 89%|########9 | 225/252 [00:53<00:05,  4.55it/s]\n",
      " 90%|######### | 228/252 [00:53<00:03,  6.26it/s]\n",
      " 91%|#########1| 230/252 [00:54<00:03,  6.36it/s]\n",
      " 92%|#########1| 231/252 [00:54<00:03,  6.08it/s]\n",
      " 92%|#########2| 232/252 [00:54<00:03,  6.56it/s]\n",
      " 92%|#########2| 233/252 [00:54<00:02,  7.08it/s]\n",
      " 93%|#########3| 235/252 [00:54<00:01,  9.35it/s]\n",
      " 94%|#########4| 237/252 [00:54<00:01,  8.18it/s]\n",
      " 95%|#########4| 239/252 [00:55<00:01,  7.58it/s]\n",
      " 95%|#########5| 240/252 [00:55<00:01,  7.95it/s]\n",
      " 96%|#########5| 241/252 [00:55<00:02,  4.83it/s]\n",
      " 96%|#########6| 242/252 [00:56<00:02,  4.36it/s]\n",
      " 96%|#########6| 243/252 [00:56<00:01,  4.50it/s]\n",
      " 97%|#########6| 244/252 [00:56<00:01,  4.11it/s]\n",
      " 97%|#########7| 245/252 [00:56<00:01,  4.32it/s]\n",
      " 98%|#########8| 247/252 [00:56<00:00,  6.58it/s]\n",
      " 99%|#########8| 249/252 [00:57<00:00,  8.87it/s]\n",
      "100%|#########9| 251/252 [00:57<00:00,  7.93it/s]\n",
      "100%|##########| 252/252 [00:59<00:00,  4.22it/s]\n",
      "\n",
      "  0%|          | 0/252 [00:00<?, ?it/s]\n",
      "  0%|          | 1/252 [00:06<26:02,  6.23s/it]\n",
      "  1%|          | 2/252 [00:06<11:40,  2.80s/it]\n",
      "  1%|1         | 3/252 [00:06<06:53,  1.66s/it]\n",
      "  2%|1         | 5/252 [00:07<03:11,  1.29it/s]\n",
      "  2%|2         | 6/252 [00:07<02:23,  1.72it/s]\n",
      "  3%|2         | 7/252 [00:08<02:45,  1.48it/s]\n",
      "  3%|3         | 8/252 [00:08<02:25,  1.68it/s]\n",
      "  4%|3         | 10/252 [00:08<01:40,  2.41it/s]\n",
      "  5%|4         | 12/252 [00:09<01:05,  3.69it/s]\n",
      "  5%|5         | 13/252 [00:09<01:17,  3.10it/s]\n",
      "  6%|5         | 15/252 [00:09<00:51,  4.60it/s]\n",
      "  7%|6         | 17/252 [00:10<01:02,  3.77it/s]\n",
      "  7%|7         | 18/252 [00:10<00:59,  3.96it/s]\n",
      "  8%|7         | 19/252 [00:10<01:01,  3.80it/s]\n",
      "  8%|7         | 20/252 [00:11<01:08,  3.37it/s]\n",
      "  9%|8         | 22/252 [00:11<00:49,  4.62it/s]\n",
      "  9%|9         | 23/252 [00:12<01:14,  3.06it/s]\n",
      " 10%|9         | 24/252 [00:12<01:07,  3.38it/s]\n",
      " 10%|9         | 25/252 [00:12<01:07,  3.36it/s]\n",
      " 10%|#         | 26/252 [00:13<01:19,  2.83it/s]\n",
      " 11%|#         | 27/252 [00:13<01:03,  3.54it/s]\n",
      " 11%|#1        | 28/252 [00:13<00:51,  4.33it/s]\n",
      " 12%|#1        | 29/252 [00:13<00:56,  3.98it/s]\n",
      " 12%|#1        | 30/252 [00:14<01:12,  3.08it/s]\n",
      " 12%|#2        | 31/252 [00:14<00:57,  3.87it/s]\n",
      " 13%|#2        | 32/252 [00:14<01:12,  3.02it/s]\n",
      " 13%|#3        | 33/252 [00:15<01:10,  3.10it/s]\n",
      " 13%|#3        | 34/252 [00:15<01:08,  3.16it/s]\n",
      " 14%|#3        | 35/252 [00:15<00:54,  3.97it/s]\n",
      " 14%|#4        | 36/252 [00:15<00:44,  4.84it/s]\n",
      " 15%|#4        | 37/252 [00:15<00:44,  4.87it/s]\n",
      " 15%|#5        | 38/252 [00:16<00:50,  4.27it/s]\n",
      " 15%|#5        | 39/252 [00:16<01:06,  3.18it/s]\n",
      " 16%|#6        | 41/252 [00:16<00:50,  4.19it/s]\n",
      " 17%|#6        | 42/252 [00:17<01:03,  3.29it/s]\n",
      " 17%|#7        | 43/252 [00:17<01:08,  3.03it/s]\n",
      " 17%|#7        | 44/252 [00:17<00:55,  3.74it/s]\n",
      " 18%|#7        | 45/252 [00:17<00:45,  4.53it/s]\n",
      " 18%|#8        | 46/252 [00:18<00:50,  4.10it/s]\n",
      " 19%|#8        | 47/252 [00:18<00:59,  3.45it/s]\n",
      " 19%|#9        | 49/252 [00:19<00:59,  3.39it/s]\n",
      " 20%|#9        | 50/252 [00:19<00:59,  3.37it/s]\n",
      " 21%|##        | 52/252 [00:20<01:03,  3.13it/s]\n",
      " 21%|##1       | 53/252 [00:20<00:53,  3.71it/s]\n",
      " 21%|##1       | 54/252 [00:21<01:14,  2.66it/s]\n",
      " 22%|##1       | 55/252 [00:21<00:59,  3.28it/s]\n",
      " 22%|##2       | 56/252 [00:21<00:48,  4.01it/s]\n",
      " 23%|##2       | 57/252 [00:21<00:40,  4.81it/s]\n",
      " 23%|##3       | 58/252 [00:22<01:13,  2.65it/s]\n",
      " 24%|##3       | 60/252 [00:22<00:44,  4.33it/s]\n",
      " 25%|##4       | 62/252 [00:23<00:52,  3.60it/s]\n",
      " 25%|##5       | 64/252 [00:23<00:50,  3.72it/s]\n",
      " 26%|##5       | 65/252 [00:23<00:43,  4.27it/s]\n",
      " 27%|##6       | 67/252 [00:23<00:30,  6.00it/s]\n",
      " 27%|##7       | 69/252 [00:24<00:42,  4.34it/s]\n",
      " 28%|##7       | 70/252 [00:24<00:51,  3.52it/s]\n",
      " 28%|##8       | 71/252 [00:25<00:48,  3.76it/s]\n",
      " 29%|##8       | 72/252 [00:25<00:45,  4.00it/s]\n",
      " 29%|##8       | 73/252 [00:25<00:51,  3.46it/s]\n",
      " 29%|##9       | 74/252 [00:26<01:01,  2.89it/s]\n",
      " 30%|###       | 76/252 [00:26<00:42,  4.17it/s]\n",
      " 31%|###       | 77/252 [00:26<00:44,  3.93it/s]\n",
      " 31%|###       | 78/252 [00:27<00:55,  3.16it/s]\n",
      " 31%|###1      | 79/252 [00:27<00:54,  3.20it/s]\n",
      " 32%|###1      | 80/252 [00:27<00:43,  3.93it/s]\n",
      " 33%|###2      | 82/252 [00:28<00:42,  3.95it/s]\n",
      " 33%|###2      | 83/252 [00:28<00:40,  4.16it/s]\n",
      " 33%|###3      | 84/252 [00:28<00:34,  4.88it/s]\n",
      " 34%|###3      | 85/252 [00:28<00:34,  4.90it/s]\n",
      " 34%|###4      | 86/252 [00:28<00:38,  4.33it/s]\n",
      " 35%|###4      | 87/252 [00:29<00:50,  3.25it/s]\n",
      " 35%|###4      | 88/252 [00:30<01:04,  2.55it/s]\n",
      " 36%|###5      | 90/252 [00:30<00:56,  2.85it/s]\n",
      " 36%|###6      | 91/252 [00:31<01:02,  2.58it/s]\n",
      " 37%|###6      | 93/252 [00:31<00:42,  3.70it/s]\n",
      " 38%|###7      | 95/252 [00:31<00:41,  3.80it/s]\n",
      " 38%|###8      | 96/252 [00:32<00:42,  3.69it/s]\n",
      " 38%|###8      | 97/252 [00:32<00:39,  3.92it/s]\n",
      " 39%|###8      | 98/252 [00:32<00:33,  4.61it/s]\n",
      " 39%|###9      | 99/252 [00:32<00:40,  3.77it/s]\n",
      " 40%|###9      | 100/252 [00:33<00:37,  4.04it/s]\n",
      " 40%|####      | 101/252 [00:33<00:43,  3.44it/s]\n",
      " 40%|####      | 102/252 [00:33<00:35,  4.23it/s]\n",
      " 41%|####      | 103/252 [00:33<00:29,  5.07it/s]\n",
      " 41%|####1     | 104/252 [00:33<00:33,  4.39it/s]\n",
      " 42%|####1     | 105/252 [00:34<00:27,  5.26it/s]\n",
      " 42%|####2     | 106/252 [00:34<00:41,  3.54it/s]\n",
      " 42%|####2     | 107/252 [00:34<00:33,  4.38it/s]\n",
      " 43%|####2     | 108/252 [00:35<00:44,  3.22it/s]\n",
      " 43%|####3     | 109/252 [00:35<00:35,  4.04it/s]\n",
      " 44%|####4     | 111/252 [00:35<00:31,  4.42it/s]\n",
      " 44%|####4     | 112/252 [00:35<00:34,  4.09it/s]\n",
      " 45%|####4     | 113/252 [00:36<00:28,  4.83it/s]\n",
      " 45%|####5     | 114/252 [00:36<00:39,  3.48it/s]\n",
      " 46%|####5     | 115/252 [00:36<00:39,  3.43it/s]\n",
      " 46%|####6     | 116/252 [00:37<00:43,  3.10it/s]\n",
      " 46%|####6     | 117/252 [00:37<00:46,  2.89it/s]\n",
      " 47%|####6     | 118/252 [00:38<00:56,  2.38it/s]\n",
      " 47%|####7     | 119/252 [00:38<00:51,  2.59it/s]\n",
      " 48%|####7     | 120/252 [00:38<00:39,  3.32it/s]\n",
      " 48%|####8     | 121/252 [00:39<00:47,  2.77it/s]\n",
      " 49%|####8     | 123/252 [00:39<00:48,  2.63it/s]\n",
      " 49%|####9     | 124/252 [00:40<00:42,  2.98it/s]\n",
      " 50%|####9     | 125/252 [00:40<00:34,  3.65it/s]\n",
      " 50%|#####     | 126/252 [00:40<00:42,  2.97it/s]\n",
      " 50%|#####     | 127/252 [00:41<00:37,  3.35it/s]\n",
      " 51%|#####     | 128/252 [00:41<00:37,  3.34it/s]\n",
      " 52%|#####1    | 130/252 [00:41<00:31,  3.92it/s]\n",
      " 52%|#####1    | 131/252 [00:41<00:29,  4.13it/s]\n",
      " 52%|#####2    | 132/252 [00:42<00:24,  4.86it/s]\n",
      " 53%|#####2    | 133/252 [00:42<00:30,  3.87it/s]\n",
      " 53%|#####3    | 134/252 [00:42<00:28,  4.12it/s]\n",
      " 54%|#####3    | 135/252 [00:43<00:43,  2.68it/s]\n",
      " 54%|#####3    | 136/252 [00:43<00:34,  3.40it/s]\n",
      " 54%|#####4    | 137/252 [00:43<00:34,  3.37it/s]\n",
      " 55%|#####4    | 138/252 [00:44<00:33,  3.36it/s]\n",
      " 55%|#####5    | 139/252 [00:44<00:30,  3.71it/s]\n",
      " 56%|#####5    | 140/252 [00:44<00:31,  3.58it/s]\n",
      " 56%|#####5    | 141/252 [00:44<00:31,  3.50it/s]\n",
      " 57%|#####6    | 143/252 [00:45<00:31,  3.41it/s]\n",
      " 57%|#####7    | 144/252 [00:45<00:29,  3.70it/s]\n",
      " 58%|#####7    | 145/252 [00:45<00:29,  3.59it/s]\n",
      " 58%|#####7    | 146/252 [00:46<00:24,  4.35it/s]\n",
      " 58%|#####8    | 147/252 [00:46<00:32,  3.26it/s]\n",
      " 59%|#####8    | 148/252 [00:46<00:28,  3.62it/s]\n",
      " 59%|#####9    | 149/252 [00:46<00:26,  3.93it/s]\n",
      " 60%|#####9    | 150/252 [00:47<00:21,  4.77it/s]\n",
      " 60%|#####9    | 151/252 [00:47<00:26,  3.76it/s]\n",
      " 60%|######    | 152/252 [00:47<00:21,  4.61it/s]\n",
      " 61%|######    | 153/252 [00:48<00:35,  2.77it/s]\n",
      " 61%|######1   | 154/252 [00:48<00:30,  3.19it/s]\n",
      " 62%|######1   | 155/252 [00:48<00:24,  4.00it/s]\n",
      " 62%|######1   | 156/252 [00:48<00:19,  4.87it/s]\n",
      " 63%|######2   | 158/252 [00:49<00:19,  4.92it/s]\n",
      " 63%|######3   | 159/252 [00:49<00:16,  5.62it/s]\n",
      " 63%|######3   | 160/252 [00:49<00:26,  3.46it/s]\n",
      " 64%|######3   | 161/252 [00:50<00:26,  3.42it/s]\n",
      " 65%|######4   | 163/252 [00:50<00:24,  3.65it/s]\n",
      " 65%|######5   | 164/252 [00:50<00:22,  3.89it/s]\n",
      " 65%|######5   | 165/252 [00:51<00:23,  3.73it/s]\n",
      " 66%|######5   | 166/252 [00:51<00:28,  3.03it/s]\n",
      " 67%|######6   | 168/252 [00:52<00:26,  3.15it/s]\n",
      " 67%|######7   | 169/252 [00:52<00:22,  3.75it/s]\n",
      " 67%|######7   | 170/252 [00:53<00:32,  2.49it/s]\n",
      " 68%|######7   | 171/252 [00:53<00:26,  3.10it/s]\n",
      " 68%|######8   | 172/252 [00:53<00:23,  3.46it/s]\n",
      " 69%|######8   | 173/252 [00:53<00:18,  4.24it/s]\n",
      " 69%|######9   | 174/252 [00:53<00:24,  3.20it/s]\n",
      " 69%|######9   | 175/252 [00:54<00:21,  3.57it/s]\n",
      " 70%|######9   | 176/252 [00:54<00:26,  2.90it/s]\n",
      " 70%|#######   | 177/252 [00:54<00:20,  3.66it/s]\n",
      " 71%|#######   | 178/252 [00:55<00:20,  3.55it/s]\n",
      " 71%|#######1  | 179/252 [00:55<00:16,  4.39it/s]\n",
      " 71%|#######1  | 180/252 [00:55<00:13,  5.27it/s]\n",
      " 72%|#######1  | 181/252 [00:55<00:13,  5.18it/s]\n",
      " 72%|#######2  | 182/252 [00:55<00:15,  4.43it/s]\n",
      " 73%|#######3  | 184/252 [00:56<00:12,  5.23it/s]\n",
      " 73%|#######3  | 185/252 [00:56<00:17,  3.73it/s]\n",
      " 74%|#######3  | 186/252 [00:56<00:16,  3.99it/s]\n",
      " 75%|#######4  | 188/252 [00:57<00:16,  3.99it/s]\n",
      " 75%|#######5  | 190/252 [00:57<00:10,  5.72it/s]\n",
      " 76%|#######5  | 191/252 [00:57<00:12,  4.96it/s]\n",
      " 76%|#######6  | 192/252 [00:57<00:10,  5.62it/s]\n",
      " 77%|#######6  | 193/252 [00:58<00:15,  3.86it/s]\n",
      " 77%|#######6  | 194/252 [00:58<00:12,  4.60it/s]\n",
      " 77%|#######7  | 195/252 [00:58<00:16,  3.39it/s]\n",
      " 78%|#######7  | 196/252 [00:58<00:13,  4.16it/s]\n",
      " 78%|#######8  | 197/252 [00:59<00:18,  2.91it/s]\n",
      " 79%|#######8  | 198/252 [00:59<00:16,  3.30it/s]\n",
      " 79%|#######8  | 199/252 [00:59<00:14,  3.67it/s]\n",
      " 79%|#######9  | 200/252 [01:00<00:11,  4.51it/s]\n",
      " 80%|#######9  | 201/252 [01:00<00:09,  5.38it/s]\n",
      " 80%|########  | 202/252 [01:00<00:18,  2.71it/s]\n",
      " 81%|########  | 204/252 [01:01<00:15,  3.17it/s]\n",
      " 81%|########1 | 205/252 [01:01<00:13,  3.49it/s]\n",
      " 82%|########1 | 206/252 [01:01<00:10,  4.20it/s]\n",
      " 83%|########2 | 208/252 [01:01<00:07,  5.57it/s]\n",
      " 83%|########2 | 209/252 [01:02<00:08,  4.81it/s]\n",
      " 84%|########3 | 211/252 [01:02<00:10,  4.08it/s]\n",
      " 84%|########4 | 212/252 [01:03<00:09,  4.25it/s]\n",
      " 85%|########4 | 214/252 [01:03<00:11,  3.33it/s]\n",
      " 85%|########5 | 215/252 [01:04<00:10,  3.59it/s]\n",
      " 86%|########5 | 216/252 [01:04<00:09,  3.85it/s]\n",
      " 86%|########6 | 217/252 [01:04<00:09,  3.70it/s]\n",
      " 87%|########6 | 218/252 [01:05<00:10,  3.28it/s]\n",
      " 87%|########6 | 219/252 [01:05<00:08,  4.02it/s]\n",
      " 87%|########7 | 220/252 [01:05<00:06,  4.83it/s]\n",
      " 88%|########7 | 221/252 [01:05<00:06,  4.87it/s]\n",
      " 88%|########8 | 222/252 [01:05<00:06,  4.29it/s]\n",
      " 89%|########8 | 224/252 [01:06<00:07,  3.78it/s]\n",
      " 89%|########9 | 225/252 [01:06<00:06,  4.02it/s]\n",
      " 90%|########9 | 226/252 [01:06<00:06,  4.23it/s]\n",
      " 90%|######### | 227/252 [01:07<00:07,  3.24it/s]\n",
      " 90%|######### | 228/252 [01:07<00:06,  3.99it/s]\n",
      " 91%|######### | 229/252 [01:08<00:08,  2.64it/s]\n",
      " 91%|#########1| 230/252 [01:08<00:06,  3.35it/s]\n",
      " 92%|#########1| 231/252 [01:08<00:06,  3.34it/s]\n",
      " 92%|#########2| 232/252 [01:08<00:05,  3.70it/s]\n",
      " 92%|#########2| 233/252 [01:08<00:04,  4.00it/s]\n",
      " 93%|#########2| 234/252 [01:09<00:04,  4.25it/s]\n",
      " 93%|#########3| 235/252 [01:09<00:03,  4.45it/s]\n",
      " 94%|#########3| 236/252 [01:09<00:04,  3.60it/s]\n",
      " 94%|#########4| 238/252 [01:10<00:04,  3.21it/s]\n",
      " 95%|#########4| 239/252 [01:10<00:03,  3.85it/s]\n",
      " 95%|#########5| 240/252 [01:10<00:02,  4.59it/s]\n",
      " 96%|#########5| 241/252 [01:11<00:03,  3.39it/s]\n",
      " 96%|#########6| 242/252 [01:11<00:02,  3.72it/s]\n",
      " 96%|#########6| 243/252 [01:11<00:02,  3.26it/s]\n",
      " 97%|#########6| 244/252 [01:12<00:02,  2.99it/s]\n",
      " 97%|#########7| 245/252 [01:12<00:01,  3.76it/s]\n",
      " 98%|#########7| 246/252 [01:12<00:01,  4.61it/s]\n",
      " 98%|#########8| 247/252 [01:12<00:01,  3.02it/s]\n",
      " 98%|#########8| 248/252 [01:13<00:01,  3.42it/s]\n",
      " 99%|#########9| 250/252 [01:13<00:00,  4.40it/s]\n",
      "100%|#########9| 251/252 [01:13<00:00,  4.53it/s]\n",
      "100%|##########| 252/252 [01:13<00:00,  3.42it/s]\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity\n",
    "#!nnUNet_raw=\"/kaggle/working/nnUnet_raw\" nnUNet_preprocessed=\"/kaggle/working/nnUNet_preprocessed\" nnUNet_results=\"/kaggle/working/nnUNet_results\" nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "can use ' -p nnUNetResEncUNetMPlans ' (for ResNet encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "usage: nnUNetv2_train [-h] [-tr TR] [-p P]\n",
    "                      [-pretrained_weights PRETRAINED_WEIGHTS]\n",
    "                      [-num_gpus NUM_GPUS] [--use_compressed] [--npz] [--c]\n",
    "                      [--val] [--val_best] [--disable_checkpointing]\n",
    "                      [-device DEVICE]\n",
    "                      dataset_name_or_id configuration fold\n",
    "\n",
    "positional arguments:\n",
    "  dataset_name_or_id    Dataset name or ID to train with\n",
    "  configuration         Configuration that should be trained\n",
    "  fold                  Fold of the 5-fold cross-validation. Should be an int\n",
    "                        between 0 and 4.\n",
    "\n",
    "options:\n",
    "  -h, --help            show this help message and exit\n",
    "  -tr TR                [OPTIONAL] Use this flag to specify a custom trainer.\n",
    "                        Default: nnUNetTrainer\n",
    "  -p P                  [OPTIONAL] Use this flag to specify a custom plans\n",
    "                        identifier. Default: nnUNetPlans\n",
    "  -pretrained_weights PRETRAINED_WEIGHTS\n",
    "                        [OPTIONAL] path to nnU-Net checkpoint file to be used\n",
    "                        as pretrained model. Will only be used when actually\n",
    "                        training. Beta. Use with caution.\n",
    "  -num_gpus NUM_GPUS    Specify the number of GPUs to use for training\n",
    "  --use_compressed      [OPTIONAL] If you set this flag the training cases\n",
    "                        will not be decompressed. Reading compressed data is\n",
    "                        much more CPU and (potentially) RAM intensive and\n",
    "                        should only be used if you know what you are doing\n",
    "  --npz                 [OPTIONAL] Save softmax predictions from final\n",
    "                        validation as npz files (in addition to predicted\n",
    "                        segmentations). Needed for finding the best ensemble.\n",
    "  --c                   [OPTIONAL] Continue training from latest checkpoint\n",
    "  --val                 [OPTIONAL] Set this flag to only run the validation.\n",
    "                        Requires training to have finished.\n",
    "  --val_best            [OPTIONAL] If set, the validation will be performed\n",
    "                        with the checkpoint_best instead of checkpoint_final.\n",
    "                        NOT COMPATIBLE with --disable_checkpointing! WARNING:\n",
    "                        This will use the same 'validation' folder as the\n",
    "                        regular validation with no way of distinguishing the\n",
    "                        two!\n",
    "  --disable_checkpointing\n",
    "                        [OPTIONAL] Set this flag to disable checkpointing.\n",
    "                        Ideal for testing things out and you dont want to\n",
    "                        flood your hard drive with checkpoints.\n",
    "  -device DEVICE        Use this to set the device the training should run\n",
    "                        with. Available options are 'cuda' (GPU), 'cpu' (CPU)\n",
    "                        and 'mps' (Apple M1/M2). Do NOT use this to set which\n",
    "                        GPU ID! Use CUDA_VISIBLE_DEVICES=X nnUNetv2_train\n",
    "                        [...] instead!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 2D\n",
    "\n",
    "nnUNetv2_train DATASET_NAME_OR_ID 2d FOLD [--npz]\n",
    "(fold = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in background worker 0:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\data_loader_2d.py\", line 21, in generate_train_batch\n",
      "    data, seg, properties = self._data.load_case(current_key)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\nnunet_dataset.py\", line 86, in load_case\n",
      "    data = np.load(entry['data_file'][:-4] + \".npy\", 'r+')\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\npyio.py\", line 453, in load\n",
      "    return format.open_memmap(file, mode=mmap_mode,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\format.py\", line 945, in open_memmap\n",
      "    marray = numpy.memmap(filename, dtype=dtype, shape=shape, order=order,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 229, in __new__\n",
      "    f_ctx = open(os_fspath(filename), ('r' if mode == 'c' else mode)+'b')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\Leo\\\\OneDrive\\\\Documents\\\\UHN-MedImg3D-ML-quiz\\\\nnUnet_preprocessed\\\\Dataset001_Pancreas\\\\nnUNetPlans_2d\\\\quiz_511.npy'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\data_loader_2d.py\", line 21, in generate_train_batch\n",
      "    data, seg, properties = self._data.load_case(current_key)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\nnunet_dataset.py\", line 86, in load_case\n",
      "    data = np.load(entry['data_file'][:-4] + \".npy\", 'r+')\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\npyio.py\", line 453, in load\n",
      "    return format.open_memmap(file, mode=mmap_mode,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\format.py\", line 945, in open_memmap\n",
      "    marray = numpy.memmap(filename, dtype=dtype, shape=shape, order=order,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 229, in __new__\n",
      "    f_ctx = open(os_fspath(filename), ('r' if mode == 'c' else mode)+'b')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\Leo\\\\OneDrive\\\\Documents\\\\UHN-MedImg3D-ML-quiz\\\\nnUnet_preprocessed\\\\Dataset001_Pancreas\\\\nnUNetPlans_2d\\\\quiz_015.npy'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\data_loader_2d.py\", line 21, in generate_train_batch\n",
      "    data, seg, properties = self._data.load_case(current_key)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\nnunet_dataset.py\", line 86, in load_case\n",
      "    data = np.load(entry['data_file'][:-4] + \".npy\", 'r+')\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\npyio.py\", line 453, in load\n",
      "    return format.open_memmap(file, mode=mmap_mode,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\format.py\", line 945, in open_memmap\n",
      "    marray = numpy.memmap(filename, dtype=dtype, shape=shape, order=order,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 229, in __new__\n",
      "    f_ctx = open(os_fspath(filename), ('r' if mode == 'c' else mode)+'b')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\Leo\\\\OneDrive\\\\Documents\\\\UHN-MedImg3D-ML-quiz\\\\nnUnet_preprocessed\\\\Dataset001_Pancreas\\\\nnUNetPlans_2d\\\\quiz_310.npy'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\data_loader_2d.py\", line 21, in generate_train_batch\n",
      "    data, seg, properties = self._data.load_case(current_key)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\nnunet_dataset.py\", line 97, in load_case\n",
      "    seg = np.load(entry['data_file'][:-4] + \"_seg.npy\", 'r+')\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\npyio.py\", line 453, in load\n",
      "    return format.open_memmap(file, mode=mmap_mode,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\format.py\", line 945, in open_memmap\n",
      "    marray = numpy.memmap(filename, dtype=dtype, shape=shape, order=order,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 229, in __new__\n",
      "    f_ctx = open(os_fspath(filename), ('r' if mode == 'c' else mode)+'b')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\Leo\\\\OneDrive\\\\Documents\\\\UHN-MedImg3D-ML-quiz\\\\nnUnet_preprocessed\\\\Dataset001_Pancreas\\\\nnUNetPlans_2d\\\\quiz_389_seg.npy'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\data_loader_2d.py\", line 21, in generate_train_batch\n",
      "    data, seg, properties = self._data.load_case(current_key)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\nnunet_dataset.py\", line 97, in load_case\n",
      "    seg = np.load(entry['data_file'][:-4] + \"_seg.npy\", 'r+')\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\npyio.py\", line 453, in load\n",
      "    return format.open_memmap(file, mode=mmap_mode,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\format.py\", line 945, in open_memmap\n",
      "    marray = numpy.memmap(filename, dtype=dtype, shape=shape, order=order,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 229, in __new__\n",
      "    f_ctx = open(os_fspath(filename), ('r' if mode == 'c' else mode)+'b')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\Leo\\\\OneDrive\\\\Documents\\\\UHN-MedImg3D-ML-quiz\\\\nnUnet_preprocessed\\\\Dataset001_Pancreas\\\\nnUNetPlans_2d\\\\quiz_265_seg.npy'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\data_loader_2d.py\", line 21, in generate_train_batch\n",
      "    data, seg, properties = self._data.load_case(current_key)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\nnunet_dataset.py\", line 86, in load_case\n",
      "    data = np.load(entry['data_file'][:-4] + \".npy\", 'r+')\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\npyio.py\", line 453, in load\n",
      "    return format.open_memmap(file, mode=mmap_mode,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\format.py\", line 945, in open_memmap\n",
      "    marray = numpy.memmap(filename, dtype=dtype, shape=shape, order=order,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 229, in __new__\n",
      "    f_ctx = open(os_fspath(filename), ('r' if mode == 'c' else mode)+'b')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\Leo\\\\OneDrive\\\\Documents\\\\UHN-MedImg3D-ML-quiz\\\\nnUnet_preprocessed\\\\Dataset001_Pancreas\\\\nnUNetPlans_2d\\\\quiz_374.npy'\n",
      "C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 53, in producer\n",
      "    item = next(data_loader)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\data_loader.py\", line 126, in __next__\n",
      "    return self.generate_train_batch()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\data_loader_2d.py\", line 21, in generate_train_batch\n",
      "    data, seg, properties = self._data.load_case(current_key)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\dataloading\\nnunet_dataset.py\", line 86, in load_case\n",
      "    data = np.load(entry['data_file'][:-4] + \".npy\", 'r+')\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\npyio.py\", line 453, in load\n",
      "    return format.open_memmap(file, mode=mmap_mode,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\lib\\format.py\", line 945, in open_memmap\n",
      "    marray = numpy.memmap(filename, dtype=dtype, shape=shape, order=order,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 229, in __new__\n",
      "    f_ctx = open(os_fspath(filename), ('r' if mode == 'c' else mode)+'b')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\Leo\\\\OneDrive\\\\Documents\\\\UHN-MedImg3D-ML-quiz\\\\nnUnet_preprocessed\\\\Dataset001_Pancreas\\\\nnUNetPlans_2d\\\\quiz_123.npy'\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Scripts\\nnUNetv2_train.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\run\\run_training.py\", line 275, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\run\\run_training.py\", line 211, in run_training\n",
      "    nnunet_trainer.run_training()\n",
      "  File \"C:\\Users\\Leo\\OneDrive\\Documents\\GitHub\\WangLabQuiz\\nnUNet\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py\", line 1370, in run_training\n",
      "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 196, in __next__\n",
      "    item = self.__get_next_item()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 181, in __get_next_item\n",
      "    raise RuntimeError(\"One or more background workers are no longer alive. Exiting. Please check the \"\n",
      "RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message\n",
      "Exception ignored in: <function NonDetMultiThreadedAugmenter.__del__ at 0x000001BAD0F036A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 253, in __del__\n",
      "    self._finish()\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py\", line 238, in _finish\n",
      "    self.abort_event.set()\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\multiprocessing\\synchronize.py\", line 345, in set\n",
      "    self._cond.notify_all()\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\multiprocessing\\synchronize.py\", line 304, in notify_all\n",
      "    self.notify(n=sys.maxsize)\n",
      "  File \"C:\\Users\\Leo\\anaconda3\\envs\\WangLabQuiz\\Lib\\multiprocessing\\synchronize.py\", line 279, in notify\n",
      "    assert not self._wait_semaphore.acquire(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [WinError 6] The handle is invalid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Errno 13] Permission denied: 'C:\\\\Users\\\\Leo\\\\OneDrive\\\\Documents\\\\UHN-MedImg3D-ML-quiz\\\\nnUnet_preprocessed\\\\Dataset001_Pancreas\\\\nnUNetPlans_2d\\\\quiz_389_seg.npy'\n",
      "Exception in background worker 5:\n",
      " [Errno 13] Permission denied: 'C:\\\\Users\\\\Leo\\\\OneDrive\\\\Documents\\\\UHN-MedImg3D-ML-quiz\\\\nnUnet_preprocessed\\\\Dataset001_Pancreas\\\\nnUNetPlans_2d\\\\quiz_123.npy'\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-09-25 15:55:54.764110: do_dummy_2d_data_aug: False\n",
      "2024-09-25 15:55:54.774734: Using splits from existing split file: C:\\Users\\Leo\\OneDrive\\Documents\\UHN-MedImg3D-ML-quiz\\nnUnet_preprocessed\\Dataset001_Pancreas\\splits_final.json\n",
      "2024-09-25 15:55:54.787120: The split file contains 5 splits.\n",
      "2024-09-25 15:55:54.794621: Desired fold for training: 0\n",
      "2024-09-25 15:55:54.801072: This split has 201 training and 51 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 132, 'patch_size': [128, 192], 'median_image_size_in_voxels': [118.0, 181.0], 'spacing': [0.73046875, 0.73046875], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset001_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.0, 0.73046875, 0.73046875], 'original_median_shape_after_transp': [64, 119, 178], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1929.0, 'mean': 74.26173400878906, 'median': 78.00000762939453, 'min': -964.0013427734375, 'percentile_00_5': -71.99081420898438, 'percentile_99_5': 180.0, 'std': 45.40709686279297}}} \n",
      "\n",
      "2024-09-25 15:56:11.299683: unpacking dataset...\n",
      "2024-09-25 15:56:12.144319: unpacking done...\n",
      "2024-09-25 15:56:12.173342: Unable to plot network architecture:\n",
      "2024-09-25 15:56:12.184018: No module named 'hiddenlayer'\n",
      "2024-09-25 15:56:12.224190: \n",
      "2024-09-25 15:56:12.232804: Epoch 0\n",
      "2024-09-25 15:56:12.241616: Current learning rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "#!nnUNet_raw=\"/kaggle/working/nnUnet_raw\" nnUNet_preprocessed=\"/kaggle/working/nnUNet_preprocessed\" nnUNet_results=\"/kaggle/working/nnUNet_results\" nnUNetv2_train 001 2d 0 -device cuda --npz\n",
    "!nnUNetv2_train 001 2d 0 -device cuda --npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 3D full res\n",
    "nnUNetv2_train DATASET_NAME_OR_ID 3d_fullres FOLD [--npz]\n",
    "(fold = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T21:06:49.574107Z",
     "iopub.status.busy": "2024-09-22T21:06:49.573667Z",
     "iopub.status.idle": "2024-09-22T21:06:49.625645Z",
     "shell.execute_reply": "2024-09-22T21:06:49.624208Z",
     "shell.execute_reply.started": "2024-09-22T21:06:49.574065Z"
    }
   },
   "outputs": [],
   "source": [
    "#!nnUNet_raw=\"/kaggle/working/nnUnet_raw\" nnUNet_preprocessed=\"/kaggle/working/nnUNet_preprocessed\" nnUNet_results=\"/kaggle/working/nnUNet_results\" nnUNetv2_train 001 3d_fullres 0 -device cuda --npz"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5566810,
     "sourceId": 9206899,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 116946,
     "modelInstanceId": 92735,
     "sourceId": 110701,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 120216,
     "modelInstanceId": 96029,
     "sourceId": 114370,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 120985,
     "modelInstanceId": 96801,
     "sourceId": 115253,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 123004,
     "modelInstanceId": 98828,
     "sourceId": 117532,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
