{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f9ee83-672e-4a51-a896-a5387682373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "#import util\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c10e352-704e-4dfe-a35e-85a7e86bcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = r'C:\\Users\\Leo\\Documents\\UHN-MedImg3D-ML-quiz\\nnUNet_results\\Dataset001_Pancreas\\nnUNetTrainer__nnUNetPlans__2d\\fold_0\\checkpoint_best.pth'\n",
    "\n",
    "# all the model architecture information is in the plans.json file:\n",
    "plans_json_path = r'C:\\Users\\Leo\\Documents\\UHN-MedImg3D-ML-quiz\\nnUNet_results\\Dataset001_Pancreas\\nnUNetTrainer__nnUNetPlans__2d\\plans.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee64a40-90df-4543-a2ef-552ed94efab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle = torch.load(saved_model_path, weights_only = False)\n",
    "\n",
    "network_weights = pickle['network_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e89b3f5-c1e6-4643-8004-89bd8f8a99b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network_weights\n",
      "optimizer_state\n",
      "grad_scaler_state\n",
      "logging\n",
      "_best_ema\n",
      "current_epoch\n",
      "init_args\n",
      "trainer_name\n",
      "inference_allowed_mirroring_axes\n"
     ]
    }
   ],
   "source": [
    "for key, value in pickle.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73785808-9397-4a24-9090-84cdb2b94bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.stages.0.0.convs.0.conv.weight\n",
      "encoder.stages.0.0.convs.0.conv.bias\n",
      "encoder.stages.0.0.convs.0.norm.weight\n",
      "encoder.stages.0.0.convs.0.norm.bias\n",
      "encoder.stages.0.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.0.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.0.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.0.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.0.0.convs.1.conv.weight\n",
      "encoder.stages.0.0.convs.1.conv.bias\n",
      "encoder.stages.0.0.convs.1.norm.weight\n",
      "encoder.stages.0.0.convs.1.norm.bias\n",
      "encoder.stages.0.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.0.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.0.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.0.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.1.0.convs.0.conv.weight\n",
      "encoder.stages.1.0.convs.0.conv.bias\n",
      "encoder.stages.1.0.convs.0.norm.weight\n",
      "encoder.stages.1.0.convs.0.norm.bias\n",
      "encoder.stages.1.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.1.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.1.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.1.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.1.0.convs.1.conv.weight\n",
      "encoder.stages.1.0.convs.1.conv.bias\n",
      "encoder.stages.1.0.convs.1.norm.weight\n",
      "encoder.stages.1.0.convs.1.norm.bias\n",
      "encoder.stages.1.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.1.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.1.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.1.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.2.0.convs.0.conv.weight\n",
      "encoder.stages.2.0.convs.0.conv.bias\n",
      "encoder.stages.2.0.convs.0.norm.weight\n",
      "encoder.stages.2.0.convs.0.norm.bias\n",
      "encoder.stages.2.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.2.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.2.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.2.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.2.0.convs.1.conv.weight\n",
      "encoder.stages.2.0.convs.1.conv.bias\n",
      "encoder.stages.2.0.convs.1.norm.weight\n",
      "encoder.stages.2.0.convs.1.norm.bias\n",
      "encoder.stages.2.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.2.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.2.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.2.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.3.0.convs.0.conv.weight\n",
      "encoder.stages.3.0.convs.0.conv.bias\n",
      "encoder.stages.3.0.convs.0.norm.weight\n",
      "encoder.stages.3.0.convs.0.norm.bias\n",
      "encoder.stages.3.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.3.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.3.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.3.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.3.0.convs.1.conv.weight\n",
      "encoder.stages.3.0.convs.1.conv.bias\n",
      "encoder.stages.3.0.convs.1.norm.weight\n",
      "encoder.stages.3.0.convs.1.norm.bias\n",
      "encoder.stages.3.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.3.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.3.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.3.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.4.0.convs.0.conv.weight\n",
      "encoder.stages.4.0.convs.0.conv.bias\n",
      "encoder.stages.4.0.convs.0.norm.weight\n",
      "encoder.stages.4.0.convs.0.norm.bias\n",
      "encoder.stages.4.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.4.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.4.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.4.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.4.0.convs.1.conv.weight\n",
      "encoder.stages.4.0.convs.1.conv.bias\n",
      "encoder.stages.4.0.convs.1.norm.weight\n",
      "encoder.stages.4.0.convs.1.norm.bias\n",
      "encoder.stages.4.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.4.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.4.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.4.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.5.0.convs.0.conv.weight\n",
      "encoder.stages.5.0.convs.0.conv.bias\n",
      "encoder.stages.5.0.convs.0.norm.weight\n",
      "encoder.stages.5.0.convs.0.norm.bias\n",
      "encoder.stages.5.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.5.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.5.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.5.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.5.0.convs.1.conv.weight\n",
      "encoder.stages.5.0.convs.1.conv.bias\n",
      "encoder.stages.5.0.convs.1.norm.weight\n",
      "encoder.stages.5.0.convs.1.norm.bias\n",
      "encoder.stages.5.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.5.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.5.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.5.0.convs.1.all_modules.1.bias\n",
      "decoder.encoder.stages.0.0.convs.0.conv.weight\n",
      "decoder.encoder.stages.0.0.convs.0.conv.bias\n",
      "decoder.encoder.stages.0.0.convs.0.norm.weight\n",
      "decoder.encoder.stages.0.0.convs.0.norm.bias\n",
      "decoder.encoder.stages.0.0.convs.0.all_modules.0.weight\n",
      "decoder.encoder.stages.0.0.convs.0.all_modules.0.bias\n",
      "decoder.encoder.stages.0.0.convs.0.all_modules.1.weight\n",
      "decoder.encoder.stages.0.0.convs.0.all_modules.1.bias\n",
      "decoder.encoder.stages.0.0.convs.1.conv.weight\n",
      "decoder.encoder.stages.0.0.convs.1.conv.bias\n",
      "decoder.encoder.stages.0.0.convs.1.norm.weight\n",
      "decoder.encoder.stages.0.0.convs.1.norm.bias\n",
      "decoder.encoder.stages.0.0.convs.1.all_modules.0.weight\n",
      "decoder.encoder.stages.0.0.convs.1.all_modules.0.bias\n",
      "decoder.encoder.stages.0.0.convs.1.all_modules.1.weight\n",
      "decoder.encoder.stages.0.0.convs.1.all_modules.1.bias\n",
      "decoder.encoder.stages.1.0.convs.0.conv.weight\n",
      "decoder.encoder.stages.1.0.convs.0.conv.bias\n",
      "decoder.encoder.stages.1.0.convs.0.norm.weight\n",
      "decoder.encoder.stages.1.0.convs.0.norm.bias\n",
      "decoder.encoder.stages.1.0.convs.0.all_modules.0.weight\n",
      "decoder.encoder.stages.1.0.convs.0.all_modules.0.bias\n",
      "decoder.encoder.stages.1.0.convs.0.all_modules.1.weight\n",
      "decoder.encoder.stages.1.0.convs.0.all_modules.1.bias\n",
      "decoder.encoder.stages.1.0.convs.1.conv.weight\n",
      "decoder.encoder.stages.1.0.convs.1.conv.bias\n",
      "decoder.encoder.stages.1.0.convs.1.norm.weight\n",
      "decoder.encoder.stages.1.0.convs.1.norm.bias\n",
      "decoder.encoder.stages.1.0.convs.1.all_modules.0.weight\n",
      "decoder.encoder.stages.1.0.convs.1.all_modules.0.bias\n",
      "decoder.encoder.stages.1.0.convs.1.all_modules.1.weight\n",
      "decoder.encoder.stages.1.0.convs.1.all_modules.1.bias\n",
      "decoder.encoder.stages.2.0.convs.0.conv.weight\n",
      "decoder.encoder.stages.2.0.convs.0.conv.bias\n",
      "decoder.encoder.stages.2.0.convs.0.norm.weight\n",
      "decoder.encoder.stages.2.0.convs.0.norm.bias\n",
      "decoder.encoder.stages.2.0.convs.0.all_modules.0.weight\n",
      "decoder.encoder.stages.2.0.convs.0.all_modules.0.bias\n",
      "decoder.encoder.stages.2.0.convs.0.all_modules.1.weight\n",
      "decoder.encoder.stages.2.0.convs.0.all_modules.1.bias\n",
      "decoder.encoder.stages.2.0.convs.1.conv.weight\n",
      "decoder.encoder.stages.2.0.convs.1.conv.bias\n",
      "decoder.encoder.stages.2.0.convs.1.norm.weight\n",
      "decoder.encoder.stages.2.0.convs.1.norm.bias\n",
      "decoder.encoder.stages.2.0.convs.1.all_modules.0.weight\n",
      "decoder.encoder.stages.2.0.convs.1.all_modules.0.bias\n",
      "decoder.encoder.stages.2.0.convs.1.all_modules.1.weight\n",
      "decoder.encoder.stages.2.0.convs.1.all_modules.1.bias\n",
      "decoder.encoder.stages.3.0.convs.0.conv.weight\n",
      "decoder.encoder.stages.3.0.convs.0.conv.bias\n",
      "decoder.encoder.stages.3.0.convs.0.norm.weight\n",
      "decoder.encoder.stages.3.0.convs.0.norm.bias\n",
      "decoder.encoder.stages.3.0.convs.0.all_modules.0.weight\n",
      "decoder.encoder.stages.3.0.convs.0.all_modules.0.bias\n",
      "decoder.encoder.stages.3.0.convs.0.all_modules.1.weight\n",
      "decoder.encoder.stages.3.0.convs.0.all_modules.1.bias\n",
      "decoder.encoder.stages.3.0.convs.1.conv.weight\n",
      "decoder.encoder.stages.3.0.convs.1.conv.bias\n",
      "decoder.encoder.stages.3.0.convs.1.norm.weight\n",
      "decoder.encoder.stages.3.0.convs.1.norm.bias\n",
      "decoder.encoder.stages.3.0.convs.1.all_modules.0.weight\n",
      "decoder.encoder.stages.3.0.convs.1.all_modules.0.bias\n",
      "decoder.encoder.stages.3.0.convs.1.all_modules.1.weight\n",
      "decoder.encoder.stages.3.0.convs.1.all_modules.1.bias\n",
      "decoder.encoder.stages.4.0.convs.0.conv.weight\n",
      "decoder.encoder.stages.4.0.convs.0.conv.bias\n",
      "decoder.encoder.stages.4.0.convs.0.norm.weight\n",
      "decoder.encoder.stages.4.0.convs.0.norm.bias\n",
      "decoder.encoder.stages.4.0.convs.0.all_modules.0.weight\n",
      "decoder.encoder.stages.4.0.convs.0.all_modules.0.bias\n",
      "decoder.encoder.stages.4.0.convs.0.all_modules.1.weight\n",
      "decoder.encoder.stages.4.0.convs.0.all_modules.1.bias\n",
      "decoder.encoder.stages.4.0.convs.1.conv.weight\n",
      "decoder.encoder.stages.4.0.convs.1.conv.bias\n",
      "decoder.encoder.stages.4.0.convs.1.norm.weight\n",
      "decoder.encoder.stages.4.0.convs.1.norm.bias\n",
      "decoder.encoder.stages.4.0.convs.1.all_modules.0.weight\n",
      "decoder.encoder.stages.4.0.convs.1.all_modules.0.bias\n",
      "decoder.encoder.stages.4.0.convs.1.all_modules.1.weight\n",
      "decoder.encoder.stages.4.0.convs.1.all_modules.1.bias\n",
      "decoder.encoder.stages.5.0.convs.0.conv.weight\n",
      "decoder.encoder.stages.5.0.convs.0.conv.bias\n",
      "decoder.encoder.stages.5.0.convs.0.norm.weight\n",
      "decoder.encoder.stages.5.0.convs.0.norm.bias\n",
      "decoder.encoder.stages.5.0.convs.0.all_modules.0.weight\n",
      "decoder.encoder.stages.5.0.convs.0.all_modules.0.bias\n",
      "decoder.encoder.stages.5.0.convs.0.all_modules.1.weight\n",
      "decoder.encoder.stages.5.0.convs.0.all_modules.1.bias\n",
      "decoder.encoder.stages.5.0.convs.1.conv.weight\n",
      "decoder.encoder.stages.5.0.convs.1.conv.bias\n",
      "decoder.encoder.stages.5.0.convs.1.norm.weight\n",
      "decoder.encoder.stages.5.0.convs.1.norm.bias\n",
      "decoder.encoder.stages.5.0.convs.1.all_modules.0.weight\n",
      "decoder.encoder.stages.5.0.convs.1.all_modules.0.bias\n",
      "decoder.encoder.stages.5.0.convs.1.all_modules.1.weight\n",
      "decoder.encoder.stages.5.0.convs.1.all_modules.1.bias\n",
      "decoder.stages.0.convs.0.conv.weight\n",
      "decoder.stages.0.convs.0.conv.bias\n",
      "decoder.stages.0.convs.0.norm.weight\n",
      "decoder.stages.0.convs.0.norm.bias\n",
      "decoder.stages.0.convs.0.all_modules.0.weight\n",
      "decoder.stages.0.convs.0.all_modules.0.bias\n",
      "decoder.stages.0.convs.0.all_modules.1.weight\n",
      "decoder.stages.0.convs.0.all_modules.1.bias\n",
      "decoder.stages.0.convs.1.conv.weight\n",
      "decoder.stages.0.convs.1.conv.bias\n",
      "decoder.stages.0.convs.1.norm.weight\n",
      "decoder.stages.0.convs.1.norm.bias\n",
      "decoder.stages.0.convs.1.all_modules.0.weight\n",
      "decoder.stages.0.convs.1.all_modules.0.bias\n",
      "decoder.stages.0.convs.1.all_modules.1.weight\n",
      "decoder.stages.0.convs.1.all_modules.1.bias\n",
      "decoder.stages.1.convs.0.conv.weight\n",
      "decoder.stages.1.convs.0.conv.bias\n",
      "decoder.stages.1.convs.0.norm.weight\n",
      "decoder.stages.1.convs.0.norm.bias\n",
      "decoder.stages.1.convs.0.all_modules.0.weight\n",
      "decoder.stages.1.convs.0.all_modules.0.bias\n",
      "decoder.stages.1.convs.0.all_modules.1.weight\n",
      "decoder.stages.1.convs.0.all_modules.1.bias\n",
      "decoder.stages.1.convs.1.conv.weight\n",
      "decoder.stages.1.convs.1.conv.bias\n",
      "decoder.stages.1.convs.1.norm.weight\n",
      "decoder.stages.1.convs.1.norm.bias\n",
      "decoder.stages.1.convs.1.all_modules.0.weight\n",
      "decoder.stages.1.convs.1.all_modules.0.bias\n",
      "decoder.stages.1.convs.1.all_modules.1.weight\n",
      "decoder.stages.1.convs.1.all_modules.1.bias\n",
      "decoder.stages.2.convs.0.conv.weight\n",
      "decoder.stages.2.convs.0.conv.bias\n",
      "decoder.stages.2.convs.0.norm.weight\n",
      "decoder.stages.2.convs.0.norm.bias\n",
      "decoder.stages.2.convs.0.all_modules.0.weight\n",
      "decoder.stages.2.convs.0.all_modules.0.bias\n",
      "decoder.stages.2.convs.0.all_modules.1.weight\n",
      "decoder.stages.2.convs.0.all_modules.1.bias\n",
      "decoder.stages.2.convs.1.conv.weight\n",
      "decoder.stages.2.convs.1.conv.bias\n",
      "decoder.stages.2.convs.1.norm.weight\n",
      "decoder.stages.2.convs.1.norm.bias\n",
      "decoder.stages.2.convs.1.all_modules.0.weight\n",
      "decoder.stages.2.convs.1.all_modules.0.bias\n",
      "decoder.stages.2.convs.1.all_modules.1.weight\n",
      "decoder.stages.2.convs.1.all_modules.1.bias\n",
      "decoder.stages.3.convs.0.conv.weight\n",
      "decoder.stages.3.convs.0.conv.bias\n",
      "decoder.stages.3.convs.0.norm.weight\n",
      "decoder.stages.3.convs.0.norm.bias\n",
      "decoder.stages.3.convs.0.all_modules.0.weight\n",
      "decoder.stages.3.convs.0.all_modules.0.bias\n",
      "decoder.stages.3.convs.0.all_modules.1.weight\n",
      "decoder.stages.3.convs.0.all_modules.1.bias\n",
      "decoder.stages.3.convs.1.conv.weight\n",
      "decoder.stages.3.convs.1.conv.bias\n",
      "decoder.stages.3.convs.1.norm.weight\n",
      "decoder.stages.3.convs.1.norm.bias\n",
      "decoder.stages.3.convs.1.all_modules.0.weight\n",
      "decoder.stages.3.convs.1.all_modules.0.bias\n",
      "decoder.stages.3.convs.1.all_modules.1.weight\n",
      "decoder.stages.3.convs.1.all_modules.1.bias\n",
      "decoder.stages.4.convs.0.conv.weight\n",
      "decoder.stages.4.convs.0.conv.bias\n",
      "decoder.stages.4.convs.0.norm.weight\n",
      "decoder.stages.4.convs.0.norm.bias\n",
      "decoder.stages.4.convs.0.all_modules.0.weight\n",
      "decoder.stages.4.convs.0.all_modules.0.bias\n",
      "decoder.stages.4.convs.0.all_modules.1.weight\n",
      "decoder.stages.4.convs.0.all_modules.1.bias\n",
      "decoder.stages.4.convs.1.conv.weight\n",
      "decoder.stages.4.convs.1.conv.bias\n",
      "decoder.stages.4.convs.1.norm.weight\n",
      "decoder.stages.4.convs.1.norm.bias\n",
      "decoder.stages.4.convs.1.all_modules.0.weight\n",
      "decoder.stages.4.convs.1.all_modules.0.bias\n",
      "decoder.stages.4.convs.1.all_modules.1.weight\n",
      "decoder.stages.4.convs.1.all_modules.1.bias\n",
      "decoder.transpconvs.0.weight\n",
      "decoder.transpconvs.0.bias\n",
      "decoder.transpconvs.1.weight\n",
      "decoder.transpconvs.1.bias\n",
      "decoder.transpconvs.2.weight\n",
      "decoder.transpconvs.2.bias\n",
      "decoder.transpconvs.3.weight\n",
      "decoder.transpconvs.3.bias\n",
      "decoder.transpconvs.4.weight\n",
      "decoder.transpconvs.4.bias\n",
      "decoder.seg_layers.0.weight\n",
      "decoder.seg_layers.0.bias\n",
      "decoder.seg_layers.1.weight\n",
      "decoder.seg_layers.1.bias\n",
      "decoder.seg_layers.2.weight\n",
      "decoder.seg_layers.2.bias\n",
      "decoder.seg_layers.3.weight\n",
      "decoder.seg_layers.3.bias\n",
      "decoder.seg_layers.4.weight\n",
      "decoder.seg_layers.4.bias\n"
     ]
    }
   ],
   "source": [
    "for key, value in network_weights.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01482b32-d9fe-4918-bb2d-6246da0a73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder is a module list\n",
    "#stages is a module list\n",
    "#stage is a module list\n",
    "\n",
    "#convs is a module list\n",
    "# conv is a module\n",
    "# norm is a module\n",
    "# all_modules is a module list\n",
    "#    0\n",
    "#    1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63368c8f-e606-4989-b8ca-42e529683c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fda1d6-c97f-4aab-8a06-8c5380daf159",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(plans_json_path) as f:\n",
    "    plans_json_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d696e5f6-08f9-4b96-96f6-b50afc61fe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name\n",
      "plans_name\n",
      "original_median_spacing_after_transp\n",
      "original_median_shape_after_transp\n",
      "image_reader_writer\n",
      "transpose_forward\n",
      "transpose_backward\n",
      "configurations\n",
      "experiment_planner_used\n",
      "label_manager\n",
      "foreground_intensity_properties_per_channel\n"
     ]
    }
   ],
   "source": [
    "for key, value in plans_json_dict.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f8ef383-2fd2-4c9f-a429-b95b83ea1228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_identifier\n",
      "preprocessor_name\n",
      "batch_size\n",
      "patch_size\n",
      "median_image_size_in_voxels\n",
      "spacing\n",
      "normalization_schemes\n",
      "use_mask_for_norm\n",
      "resampling_fn_data\n",
      "resampling_fn_seg\n",
      "resampling_fn_data_kwargs\n",
      "resampling_fn_seg_kwargs\n",
      "resampling_fn_probabilities\n",
      "resampling_fn_probabilities_kwargs\n",
      "architecture\n",
      "batch_dice\n"
     ]
    }
   ],
   "source": [
    "for key, value in plans_json_dict['configurations']['2d'].items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "403cab54-f4f2-4557-9b65-77e2d401a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_stages\n",
      "features_per_stage\n",
      "conv_op\n",
      "kernel_sizes\n",
      "strides\n",
      "n_conv_per_stage\n",
      "n_conv_per_stage_decoder\n",
      "conv_bias\n",
      "norm_op\n",
      "norm_op_kwargs\n",
      "dropout_op\n",
      "dropout_op_kwargs\n",
      "nonlin\n",
      "nonlin_kwargs\n"
     ]
    }
   ],
   "source": [
    "arch_kwargs = plans_json_dict['configurations']['2d']['architecture']['arch_kwargs']\n",
    "\n",
    "for key, value in arch_kwargs.items():\n",
    "    print(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5568862b-bbae-4e08-9163-e177460c82de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}\n"
     ]
    }
   ],
   "source": [
    "print(arch_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c51c315-a48f-4331-9406-f446e45497cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.utilities.get_network_from_plans import get_network_from_plans\n",
    "\n",
    "# create the classification model\n",
    "classify_model = get_network_from_plans(\n",
    "        arch_class_name='dynamic_network_architectures.architectures.unet.ClassifyinnUNet',\n",
    "        arch_kwargs=arch_kwargs,\n",
    "        arch_kwargs_req_import=[\"conv_op\", \"norm_op\", \"dropout_op\", \"nonlin\"],\n",
    "        input_channels=1,\n",
    "        output_channels=3,\n",
    "        allow_init=True,\n",
    "        deep_supervision=False)\n",
    "\n",
    "classify_model = classify_model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc90402-5a6f-426e-96ce-f7930e48c33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand(3, 1, 128, 192)\n",
    "\n",
    "data = data.cuda()\n",
    "outputs = classify_model(data) # this should be a list of torch.Tensor\n",
    "\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a892a72b-93f3-433c-9384-1a473c756539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560\n"
     ]
    }
   ],
   "source": [
    "print(classify_model.compute_conv_feature_map_size([4, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7893b282-e2ff-47cc-8088-13daf14281cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.stages.0.0.convs.0.conv.weight torch.Size([32, 1, 3, 3])\n",
      "encoder.stages.0.0.convs.0.conv.bias torch.Size([32])\n",
      "encoder.stages.0.0.convs.0.norm.weight torch.Size([32])\n",
      "encoder.stages.0.0.convs.0.norm.bias torch.Size([32])\n",
      "encoder.stages.0.0.convs.1.conv.weight torch.Size([32, 32, 3, 3])\n",
      "encoder.stages.0.0.convs.1.conv.bias torch.Size([32])\n",
      "encoder.stages.0.0.convs.1.norm.weight torch.Size([32])\n",
      "encoder.stages.0.0.convs.1.norm.bias torch.Size([32])\n",
      "encoder.stages.0.0.classify_convs.0.conv.weight torch.Size([32, 1, 3, 3])\n",
      "encoder.stages.0.0.classify_convs.0.conv.bias torch.Size([32])\n",
      "encoder.stages.0.0.classify_convs.0.norm.weight torch.Size([32])\n",
      "encoder.stages.0.0.classify_convs.0.norm.bias torch.Size([32])\n",
      "encoder.stages.0.0.classify_convs.1.conv.weight torch.Size([32, 32, 3, 3])\n",
      "encoder.stages.0.0.classify_convs.1.conv.bias torch.Size([32])\n",
      "encoder.stages.0.0.classify_convs.1.norm.weight torch.Size([32])\n",
      "encoder.stages.0.0.classify_convs.1.norm.bias torch.Size([32])\n",
      "encoder.stages.0.0.attention_gate.conv.weight torch.Size([1, 32, 1, 1])\n",
      "encoder.stages.0.0.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.1.0.convs.0.conv.weight torch.Size([64, 32, 3, 3])\n",
      "encoder.stages.1.0.convs.0.conv.bias torch.Size([64])\n",
      "encoder.stages.1.0.convs.0.norm.weight torch.Size([64])\n",
      "encoder.stages.1.0.convs.0.norm.bias torch.Size([64])\n",
      "encoder.stages.1.0.convs.1.conv.weight torch.Size([64, 64, 3, 3])\n",
      "encoder.stages.1.0.convs.1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.0.convs.1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.0.convs.1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.0.classify_convs.0.conv.weight torch.Size([64, 32, 3, 3])\n",
      "encoder.stages.1.0.classify_convs.0.conv.bias torch.Size([64])\n",
      "encoder.stages.1.0.classify_convs.0.norm.weight torch.Size([64])\n",
      "encoder.stages.1.0.classify_convs.0.norm.bias torch.Size([64])\n",
      "encoder.stages.1.0.classify_convs.1.conv.weight torch.Size([64, 64, 3, 3])\n",
      "encoder.stages.1.0.classify_convs.1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.0.classify_convs.1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.0.classify_convs.1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.0.attention_gate.conv.weight torch.Size([1, 64, 1, 1])\n",
      "encoder.stages.1.0.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.2.0.convs.0.conv.weight torch.Size([128, 64, 3, 3])\n",
      "encoder.stages.2.0.convs.0.conv.bias torch.Size([128])\n",
      "encoder.stages.2.0.convs.0.norm.weight torch.Size([128])\n",
      "encoder.stages.2.0.convs.0.norm.bias torch.Size([128])\n",
      "encoder.stages.2.0.convs.1.conv.weight torch.Size([128, 128, 3, 3])\n",
      "encoder.stages.2.0.convs.1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.0.convs.1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.0.convs.1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.0.classify_convs.0.conv.weight torch.Size([128, 64, 3, 3])\n",
      "encoder.stages.2.0.classify_convs.0.conv.bias torch.Size([128])\n",
      "encoder.stages.2.0.classify_convs.0.norm.weight torch.Size([128])\n",
      "encoder.stages.2.0.classify_convs.0.norm.bias torch.Size([128])\n",
      "encoder.stages.2.0.classify_convs.1.conv.weight torch.Size([128, 128, 3, 3])\n",
      "encoder.stages.2.0.classify_convs.1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.0.classify_convs.1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.0.classify_convs.1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.0.attention_gate.conv.weight torch.Size([1, 128, 1, 1])\n",
      "encoder.stages.2.0.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.3.0.convs.0.conv.weight torch.Size([256, 128, 3, 3])\n",
      "encoder.stages.3.0.convs.0.conv.bias torch.Size([256])\n",
      "encoder.stages.3.0.convs.0.norm.weight torch.Size([256])\n",
      "encoder.stages.3.0.convs.0.norm.bias torch.Size([256])\n",
      "encoder.stages.3.0.convs.1.conv.weight torch.Size([256, 256, 3, 3])\n",
      "encoder.stages.3.0.convs.1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.0.convs.1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.0.convs.1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.0.classify_convs.0.conv.weight torch.Size([256, 128, 3, 3])\n",
      "encoder.stages.3.0.classify_convs.0.conv.bias torch.Size([256])\n",
      "encoder.stages.3.0.classify_convs.0.norm.weight torch.Size([256])\n",
      "encoder.stages.3.0.classify_convs.0.norm.bias torch.Size([256])\n",
      "encoder.stages.3.0.classify_convs.1.conv.weight torch.Size([256, 256, 3, 3])\n",
      "encoder.stages.3.0.classify_convs.1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.0.classify_convs.1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.0.classify_convs.1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.0.attention_gate.conv.weight torch.Size([1, 256, 1, 1])\n",
      "encoder.stages.3.0.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.4.0.convs.0.conv.weight torch.Size([512, 256, 3, 3])\n",
      "encoder.stages.4.0.convs.0.conv.bias torch.Size([512])\n",
      "encoder.stages.4.0.convs.0.norm.weight torch.Size([512])\n",
      "encoder.stages.4.0.convs.0.norm.bias torch.Size([512])\n",
      "encoder.stages.4.0.convs.1.conv.weight torch.Size([512, 512, 3, 3])\n",
      "encoder.stages.4.0.convs.1.conv.bias torch.Size([512])\n",
      "encoder.stages.4.0.convs.1.norm.weight torch.Size([512])\n",
      "encoder.stages.4.0.convs.1.norm.bias torch.Size([512])\n",
      "encoder.stages.4.0.classify_convs.0.conv.weight torch.Size([512, 256, 3, 3])\n",
      "encoder.stages.4.0.classify_convs.0.conv.bias torch.Size([512])\n",
      "encoder.stages.4.0.classify_convs.0.norm.weight torch.Size([512])\n",
      "encoder.stages.4.0.classify_convs.0.norm.bias torch.Size([512])\n",
      "encoder.stages.4.0.classify_convs.1.conv.weight torch.Size([512, 512, 3, 3])\n",
      "encoder.stages.4.0.classify_convs.1.conv.bias torch.Size([512])\n",
      "encoder.stages.4.0.classify_convs.1.norm.weight torch.Size([512])\n",
      "encoder.stages.4.0.classify_convs.1.norm.bias torch.Size([512])\n",
      "encoder.stages.4.0.attention_gate.conv.weight torch.Size([1, 512, 1, 1])\n",
      "encoder.stages.4.0.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.5.0.convs.0.conv.weight torch.Size([512, 512, 3, 3])\n",
      "encoder.stages.5.0.convs.0.conv.bias torch.Size([512])\n",
      "encoder.stages.5.0.convs.0.norm.weight torch.Size([512])\n",
      "encoder.stages.5.0.convs.0.norm.bias torch.Size([512])\n",
      "encoder.stages.5.0.convs.1.conv.weight torch.Size([512, 512, 3, 3])\n",
      "encoder.stages.5.0.convs.1.conv.bias torch.Size([512])\n",
      "encoder.stages.5.0.convs.1.norm.weight torch.Size([512])\n",
      "encoder.stages.5.0.convs.1.norm.bias torch.Size([512])\n",
      "encoder.stages.5.0.classify_convs.0.conv.weight torch.Size([512, 512, 3, 3])\n",
      "encoder.stages.5.0.classify_convs.0.conv.bias torch.Size([512])\n",
      "encoder.stages.5.0.classify_convs.0.norm.weight torch.Size([512])\n",
      "encoder.stages.5.0.classify_convs.0.norm.bias torch.Size([512])\n",
      "encoder.stages.5.0.classify_convs.1.conv.weight torch.Size([512, 512, 3, 3])\n",
      "encoder.stages.5.0.classify_convs.1.conv.bias torch.Size([512])\n",
      "encoder.stages.5.0.classify_convs.1.norm.weight torch.Size([512])\n",
      "encoder.stages.5.0.classify_convs.1.norm.bias torch.Size([512])\n",
      "encoder.stages.5.0.attention_gate.conv.weight torch.Size([1, 512, 1, 1])\n",
      "encoder.stages.5.0.attention_gate.conv.bias torch.Size([1])\n",
      "decoder.FC1.weight torch.Size([1000, 30720])\n",
      "decoder.FC1.bias torch.Size([1000])\n",
      "decoder.FC2.weight torch.Size([3, 1000])\n",
      "decoder.FC2.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, param in classify_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e54404fb-be7d-42ee-80e3-192e3b30cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.stem.convs.0.conv.weight torch.Size([32, 1, 1, 3, 3])\n",
      "encoder.stem.convs.0.conv.bias torch.Size([32])\n",
      "encoder.stem.convs.0.norm.weight torch.Size([32])\n",
      "encoder.stem.convs.0.norm.bias torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.0.weight torch.Size([32, 1, 1, 3, 3])\n",
      "encoder.stem.convs.0.all_modules.0.bias torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.1.weight torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.1.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.conv.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv1.conv.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.norm.weight torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.norm.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.0.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.0.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.1.weight torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.1.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.conv.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv2.conv.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.norm.weight torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.norm.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.0.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.0.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.1.weight torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.1.bias torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv1.conv.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.classify_blocks.0.conv1.conv.bias torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv1.norm.weight torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv1.norm.bias torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv1.all_modules.0.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.classify_blocks.0.conv1.all_modules.0.bias torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv1.all_modules.1.weight torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv1.all_modules.1.bias torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv2.conv.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.classify_blocks.0.conv2.conv.bias torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv2.norm.weight torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv2.norm.bias torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv2.all_modules.0.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.classify_blocks.0.conv2.all_modules.0.bias torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv2.all_modules.1.weight torch.Size([32])\n",
      "encoder.stages.0.classify_blocks.0.conv2.all_modules.1.bias torch.Size([32])\n",
      "encoder.stages.0.attention_gate.conv.weight torch.Size([1, 32, 1, 1, 1])\n",
      "encoder.stages.0.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.0.attention_gate.attention_gate.1.weight torch.Size([1, 32, 1, 1, 1])\n",
      "encoder.stages.0.attention_gate.attention_gate.1.bias torch.Size([1])\n",
      "encoder.stages.1.blocks.0.conv1.conv.weight torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.0.weight torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv2.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.conv.weight torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.blocks.0.skip.1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.0.weight torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv2.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv2.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv1.conv.weight torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.0.conv1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv1.all_modules.0.weight torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.0.conv1.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.0.conv2.conv.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv2.norm.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv2.norm.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.0.conv2.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv2.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.conv2.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.skip.1.conv.weight torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.classify_blocks.0.skip.1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.skip.1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.skip.1.all_modules.0.weight torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.classify_blocks.0.skip.1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.0.skip.1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv1.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.1.conv1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv1.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.1.conv1.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.1.conv2.conv.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv2.norm.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv2.norm.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.1.conv2.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv2.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.1.conv2.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv1.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.2.conv1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv1.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.2.conv1.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.2.conv2.conv.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv2.norm.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv2.norm.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.classify_blocks.2.conv2.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv2.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.classify_blocks.2.conv2.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.attention_gate.conv.weight torch.Size([1, 64, 1, 1, 1])\n",
      "encoder.stages.1.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.1.attention_gate.attention_gate.1.weight torch.Size([1, 64, 1, 1, 1])\n",
      "encoder.stages.1.attention_gate.attention_gate.1.bias torch.Size([1])\n",
      "encoder.stages.2.blocks.0.conv1.conv.weight torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.0.weight torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.conv.weight torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.blocks.0.skip.1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.0.weight torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv1.conv.weight torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.0.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv1.all_modules.0.weight torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.0.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.0.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.0.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.skip.1.conv.weight torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.classify_blocks.0.skip.1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.skip.1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.skip.1.all_modules.0.weight torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.classify_blocks.0.skip.1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.0.skip.1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.1.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.1.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.1.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.1.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.1.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.2.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.2.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.2.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.2.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.2.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.3.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.3.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.3.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.classify_blocks.3.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.classify_blocks.3.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.attention_gate.conv.weight torch.Size([1, 128, 1, 1, 1])\n",
      "encoder.stages.2.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.2.attention_gate.attention_gate.1.weight torch.Size([1, 128, 1, 1, 1])\n",
      "encoder.stages.2.attention_gate.attention_gate.1.bias torch.Size([1])\n",
      "encoder.stages.3.blocks.0.conv1.conv.weight torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.0.weight torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.conv.weight torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.blocks.0.skip.1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.0.weight torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv1.conv.weight torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.0.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv1.all_modules.0.weight torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.0.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.0.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.0.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.skip.1.conv.weight torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.classify_blocks.0.skip.1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.skip.1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.skip.1.all_modules.0.weight torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.classify_blocks.0.skip.1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.0.skip.1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.1.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.1.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.1.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.1.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.1.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.2.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.2.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.2.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.2.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.2.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.3.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.3.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.3.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.3.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.3.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.4.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.4.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.4.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.4.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.4.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.5.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.5.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.5.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.classify_blocks.5.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.classify_blocks.5.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.attention_gate.conv.weight torch.Size([1, 256, 1, 1, 1])\n",
      "encoder.stages.3.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.3.attention_gate.attention_gate.1.weight torch.Size([1, 256, 1, 1, 1])\n",
      "encoder.stages.3.attention_gate.attention_gate.1.bias torch.Size([1])\n",
      "encoder.stages.4.blocks.0.conv1.conv.weight torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.0.weight torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.conv.weight torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.blocks.0.skip.1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.0.weight torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv1.conv.weight torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.0.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv1.all_modules.0.weight torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.0.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.0.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.0.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.skip.1.conv.weight torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.classify_blocks.0.skip.1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.skip.1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.skip.1.all_modules.0.weight torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.classify_blocks.0.skip.1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.0.skip.1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.1.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.1.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.1.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.1.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.1.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.2.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.2.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.2.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.2.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.2.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.3.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.3.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.3.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.3.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.3.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.4.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.4.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.4.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.4.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.4.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.5.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.5.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.5.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.classify_blocks.5.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.classify_blocks.5.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.attention_gate.conv.weight torch.Size([1, 320, 1, 1, 1])\n",
      "encoder.stages.4.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.4.attention_gate.attention_gate.1.weight torch.Size([1, 320, 1, 1, 1])\n",
      "encoder.stages.4.attention_gate.attention_gate.1.bias torch.Size([1])\n",
      "encoder.stages.5.blocks.0.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.0.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.0.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.0.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.0.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.0.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.1.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.1.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.1.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.1.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.1.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.2.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.2.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.2.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.2.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.2.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.3.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.3.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.3.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.3.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.3.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.4.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.4.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.4.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.4.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.4.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.5.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.5.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.5.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.classify_blocks.5.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.classify_blocks.5.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.attention_gate.conv.weight torch.Size([1, 320, 1, 1, 1])\n",
      "encoder.stages.5.attention_gate.conv.bias torch.Size([1])\n",
      "encoder.stages.5.attention_gate.attention_gate.1.weight torch.Size([1, 320, 1, 1, 1])\n",
      "encoder.stages.5.attention_gate.attention_gate.1.bias torch.Size([1])\n",
      "decoder.FC1.weight torch.Size([1000, 30720])\n",
      "decoder.FC1.bias torch.Size([1000])\n",
      "decoder.FC2.weight torch.Size([3, 1000])\n",
      "decoder.FC2.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "classify_model_weights = classify_model.state_dict()\n",
    "\n",
    "for key, value in classify_model_weights.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04d5ea57-b19e-46f0-ab1f-decdb1654d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.stem.convs.0.conv.weight torch.Size([32, 1, 1, 3, 3])\n",
      "encoder.stem.convs.0.conv.bias torch.Size([32])\n",
      "encoder.stem.convs.0.norm.weight torch.Size([32])\n",
      "encoder.stem.convs.0.norm.bias torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.0.weight torch.Size([32, 1, 1, 3, 3])\n",
      "encoder.stem.convs.0.all_modules.0.bias torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.1.weight torch.Size([32])\n",
      "encoder.stem.convs.0.all_modules.1.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.conv.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv1.conv.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.norm.weight torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.norm.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.0.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.0.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.1.weight torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv1.all_modules.1.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.conv.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv2.conv.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.norm.weight torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.norm.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.0.weight torch.Size([32, 32, 1, 3, 3])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.0.bias torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.1.weight torch.Size([32])\n",
      "encoder.stages.0.blocks.0.conv2.all_modules.1.bias torch.Size([32])\n",
      "encoder.stages.1.blocks.0.conv1.conv.weight torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.0.weight torch.Size([64, 32, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv2.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.conv2.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.conv.weight torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.blocks.0.skip.1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.0.weight torch.Size([64, 32, 1, 1, 1])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.0.skip.1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv2.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.1.conv2.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv1.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv1.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv2.conv.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.norm.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.norm.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.0.bias torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.1.weight torch.Size([64])\n",
      "encoder.stages.1.blocks.2.conv2.all_modules.1.bias torch.Size([64])\n",
      "encoder.stages.2.blocks.0.conv1.conv.weight torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.0.weight torch.Size([128, 64, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.conv.weight torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.blocks.0.skip.1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.0.weight torch.Size([128, 64, 1, 1, 1])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.0.skip.1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.1.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.2.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv1.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv1.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv2.conv.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.norm.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.norm.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.0.bias torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.1.weight torch.Size([128])\n",
      "encoder.stages.2.blocks.3.conv2.all_modules.1.bias torch.Size([128])\n",
      "encoder.stages.3.blocks.0.conv1.conv.weight torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.0.weight torch.Size([256, 128, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.conv.weight torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.blocks.0.skip.1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.0.weight torch.Size([256, 128, 1, 1, 1])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.0.skip.1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.1.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.2.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.3.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.4.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv1.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv1.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv2.conv.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.norm.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.norm.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.0.bias torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.1.weight torch.Size([256])\n",
      "encoder.stages.3.blocks.5.conv2.all_modules.1.bias torch.Size([256])\n",
      "encoder.stages.4.blocks.0.conv1.conv.weight torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.0.weight torch.Size([320, 256, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.conv.weight torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.blocks.0.skip.1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.0.weight torch.Size([320, 256, 1, 1, 1])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.0.skip.1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.1.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.2.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.3.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.4.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.4.blocks.5.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.0.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.1.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.2.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.3.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.4.conv2.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv1.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv1.all_modules.1.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv2.conv.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.norm.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.norm.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.0.bias torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.1.weight torch.Size([320])\n",
      "encoder.stages.5.blocks.5.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stem.convs.0.conv.weight torch.Size([32, 1, 1, 3, 3])\n",
      "decoder.encoder.stem.convs.0.conv.bias torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.norm.weight torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.norm.bias torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.all_modules.0.weight torch.Size([32, 1, 1, 3, 3])\n",
      "decoder.encoder.stem.convs.0.all_modules.0.bias torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.all_modules.1.weight torch.Size([32])\n",
      "decoder.encoder.stem.convs.0.all_modules.1.bias torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.conv.weight torch.Size([32, 32, 1, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.conv.bias torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.norm.weight torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.norm.bias torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.0.weight torch.Size([32, 32, 1, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.0.bias torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.1.weight torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv1.all_modules.1.bias torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.conv.weight torch.Size([32, 32, 1, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.conv.bias torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.norm.weight torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.norm.bias torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.0.weight torch.Size([32, 32, 1, 3, 3])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.0.bias torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.1.weight torch.Size([32])\n",
      "decoder.encoder.stages.0.blocks.0.conv2.all_modules.1.bias torch.Size([32])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.conv.weight torch.Size([64, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.conv.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.norm.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.norm.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.0.weight torch.Size([64, 32, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.0.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.1.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv1.all_modules.1.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.conv.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.norm.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.norm.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.0.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.1.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.conv2.all_modules.1.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.conv.weight torch.Size([64, 32, 1, 1, 1])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.norm.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.norm.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.all_modules.0.weight torch.Size([64, 32, 1, 1, 1])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.all_modules.1.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.0.skip.1.all_modules.1.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.conv.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.norm.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.norm.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.0.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.1.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv1.all_modules.1.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.conv.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.norm.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.norm.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.0.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.1.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.1.conv2.all_modules.1.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.conv.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.norm.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.norm.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.0.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.1.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv1.all_modules.1.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.conv.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.conv.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.norm.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.norm.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.0.weight torch.Size([64, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.0.bias torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.1.weight torch.Size([64])\n",
      "decoder.encoder.stages.1.blocks.2.conv2.all_modules.1.bias torch.Size([64])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.conv.weight torch.Size([128, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.conv.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.norm.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.norm.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.0.weight torch.Size([128, 64, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.0.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.1.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv1.all_modules.1.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.conv.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.norm.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.norm.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.0.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.1.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.conv2.all_modules.1.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.conv.weight torch.Size([128, 64, 1, 1, 1])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.norm.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.norm.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.all_modules.0.weight torch.Size([128, 64, 1, 1, 1])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.all_modules.1.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.0.skip.1.all_modules.1.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.conv.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.norm.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.norm.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.0.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.1.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv1.all_modules.1.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.conv.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.norm.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.norm.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.0.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.1.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.1.conv2.all_modules.1.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.conv.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.norm.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.norm.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.0.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.1.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv1.all_modules.1.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.conv.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.norm.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.norm.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.0.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.1.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.2.conv2.all_modules.1.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.conv.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.norm.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.norm.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.0.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.1.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv1.all_modules.1.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.conv.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.conv.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.norm.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.norm.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.0.weight torch.Size([128, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.0.bias torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.1.weight torch.Size([128])\n",
      "decoder.encoder.stages.2.blocks.3.conv2.all_modules.1.bias torch.Size([128])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.conv.weight torch.Size([256, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.0.weight torch.Size([256, 128, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv1.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.conv2.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.conv.weight torch.Size([256, 128, 1, 1, 1])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.all_modules.0.weight torch.Size([256, 128, 1, 1, 1])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.0.skip.1.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv1.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.1.conv2.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv1.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.2.conv2.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv1.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.3.conv2.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv1.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.4.conv2.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv1.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.conv.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.conv.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.norm.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.norm.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.0.weight torch.Size([256, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.0.bias torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.1.weight torch.Size([256])\n",
      "decoder.encoder.stages.3.blocks.5.conv2.all_modules.1.bias torch.Size([256])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.conv.weight torch.Size([320, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.0.weight torch.Size([320, 256, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.conv.weight torch.Size([320, 256, 1, 1, 1])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.all_modules.0.weight torch.Size([320, 256, 1, 1, 1])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.0.skip.1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.1.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.2.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.3.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.4.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.4.blocks.5.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.0.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.1.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.2.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.3.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.4.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv1.all_modules.1.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.conv.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.conv.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.norm.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.norm.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.0.weight torch.Size([320, 320, 3, 3, 3])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.0.bias torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.1.weight torch.Size([320])\n",
      "decoder.encoder.stages.5.blocks.5.conv2.all_modules.1.bias torch.Size([320])\n",
      "decoder.stages.0.convs.0.conv.weight torch.Size([320, 640, 3, 3, 3])\n",
      "decoder.stages.0.convs.0.conv.bias torch.Size([320])\n",
      "decoder.stages.0.convs.0.norm.weight torch.Size([320])\n",
      "decoder.stages.0.convs.0.norm.bias torch.Size([320])\n",
      "decoder.stages.0.convs.0.all_modules.0.weight torch.Size([320, 640, 3, 3, 3])\n",
      "decoder.stages.0.convs.0.all_modules.0.bias torch.Size([320])\n",
      "decoder.stages.0.convs.0.all_modules.1.weight torch.Size([320])\n",
      "decoder.stages.0.convs.0.all_modules.1.bias torch.Size([320])\n",
      "decoder.stages.1.convs.0.conv.weight torch.Size([256, 512, 3, 3, 3])\n",
      "decoder.stages.1.convs.0.conv.bias torch.Size([256])\n",
      "decoder.stages.1.convs.0.norm.weight torch.Size([256])\n",
      "decoder.stages.1.convs.0.norm.bias torch.Size([256])\n",
      "decoder.stages.1.convs.0.all_modules.0.weight torch.Size([256, 512, 3, 3, 3])\n",
      "decoder.stages.1.convs.0.all_modules.0.bias torch.Size([256])\n",
      "decoder.stages.1.convs.0.all_modules.1.weight torch.Size([256])\n",
      "decoder.stages.1.convs.0.all_modules.1.bias torch.Size([256])\n",
      "decoder.stages.2.convs.0.conv.weight torch.Size([128, 256, 3, 3, 3])\n",
      "decoder.stages.2.convs.0.conv.bias torch.Size([128])\n",
      "decoder.stages.2.convs.0.norm.weight torch.Size([128])\n",
      "decoder.stages.2.convs.0.norm.bias torch.Size([128])\n",
      "decoder.stages.2.convs.0.all_modules.0.weight torch.Size([128, 256, 3, 3, 3])\n",
      "decoder.stages.2.convs.0.all_modules.0.bias torch.Size([128])\n",
      "decoder.stages.2.convs.0.all_modules.1.weight torch.Size([128])\n",
      "decoder.stages.2.convs.0.all_modules.1.bias torch.Size([128])\n",
      "decoder.stages.3.convs.0.conv.weight torch.Size([64, 128, 3, 3, 3])\n",
      "decoder.stages.3.convs.0.conv.bias torch.Size([64])\n",
      "decoder.stages.3.convs.0.norm.weight torch.Size([64])\n",
      "decoder.stages.3.convs.0.norm.bias torch.Size([64])\n",
      "decoder.stages.3.convs.0.all_modules.0.weight torch.Size([64, 128, 3, 3, 3])\n",
      "decoder.stages.3.convs.0.all_modules.0.bias torch.Size([64])\n",
      "decoder.stages.3.convs.0.all_modules.1.weight torch.Size([64])\n",
      "decoder.stages.3.convs.0.all_modules.1.bias torch.Size([64])\n",
      "decoder.stages.4.convs.0.conv.weight torch.Size([32, 64, 1, 3, 3])\n",
      "decoder.stages.4.convs.0.conv.bias torch.Size([32])\n",
      "decoder.stages.4.convs.0.norm.weight torch.Size([32])\n",
      "decoder.stages.4.convs.0.norm.bias torch.Size([32])\n",
      "decoder.stages.4.convs.0.all_modules.0.weight torch.Size([32, 64, 1, 3, 3])\n",
      "decoder.stages.4.convs.0.all_modules.0.bias torch.Size([32])\n",
      "decoder.stages.4.convs.0.all_modules.1.weight torch.Size([32])\n",
      "decoder.stages.4.convs.0.all_modules.1.bias torch.Size([32])\n",
      "decoder.transpconvs.0.weight torch.Size([320, 320, 2, 2, 2])\n",
      "decoder.transpconvs.0.bias torch.Size([320])\n",
      "decoder.transpconvs.1.weight torch.Size([320, 256, 2, 2, 2])\n",
      "decoder.transpconvs.1.bias torch.Size([256])\n",
      "decoder.transpconvs.2.weight torch.Size([256, 128, 2, 2, 2])\n",
      "decoder.transpconvs.2.bias torch.Size([128])\n",
      "decoder.transpconvs.3.weight torch.Size([128, 64, 2, 2, 2])\n",
      "decoder.transpconvs.3.bias torch.Size([64])\n",
      "decoder.transpconvs.4.weight torch.Size([64, 32, 1, 2, 2])\n",
      "decoder.transpconvs.4.bias torch.Size([32])\n",
      "decoder.seg_layers.0.weight torch.Size([3, 320, 1, 1, 1])\n",
      "decoder.seg_layers.0.bias torch.Size([3])\n",
      "decoder.seg_layers.1.weight torch.Size([3, 256, 1, 1, 1])\n",
      "decoder.seg_layers.1.bias torch.Size([3])\n",
      "decoder.seg_layers.2.weight torch.Size([3, 128, 1, 1, 1])\n",
      "decoder.seg_layers.2.bias torch.Size([3])\n",
      "decoder.seg_layers.3.weight torch.Size([3, 64, 1, 1, 1])\n",
      "decoder.seg_layers.3.bias torch.Size([3])\n",
      "decoder.seg_layers.4.weight torch.Size([3, 32, 1, 1, 1])\n",
      "decoder.seg_layers.4.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "pickle = torch.load(saved_model_path, weights_only = False)\n",
    "segmentation_model_weights = pickle['network_weights']\n",
    "\n",
    "for key, value in segmentation_model_weights.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53d2e479-87bd-4734-b6f7-53d1cbeebd48",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResidualClassifyinnUNet:\n\tUnexpected key(s) in state_dict: \"encoder.stem.classify_convs.0.all_modules.0.bias\", \"encoder.stem.classify_convs.0.all_modules.0.weight\", \"encoder.stem.classify_convs.0.all_modules.1.bias\", \"encoder.stem.classify_convs.0.all_modules.1.weight\", \"encoder.stem.classify_convs.0.conv.bias\", \"encoder.stem.classify_convs.0.conv.weight\", \"encoder.stem.classify_convs.0.norm.bias\", \"encoder.stem.classify_convs.0.norm.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     classify_model_weights[classify_key] \u001b[38;5;241m=\u001b[39m segmentation_model_weights[key]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# update the model\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m classify_model\u001b[38;5;241m.\u001b[39mload_state_dict(classify_model_weights)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\WangLabQuiz\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResidualClassifyinnUNet:\n\tUnexpected key(s) in state_dict: \"encoder.stem.classify_convs.0.all_modules.0.bias\", \"encoder.stem.classify_convs.0.all_modules.0.weight\", \"encoder.stem.classify_convs.0.all_modules.1.bias\", \"encoder.stem.classify_convs.0.all_modules.1.weight\", \"encoder.stem.classify_convs.0.conv.bias\", \"encoder.stem.classify_convs.0.conv.weight\", \"encoder.stem.classify_convs.0.norm.bias\", \"encoder.stem.classify_convs.0.norm.weight\". "
     ]
    }
   ],
   "source": [
    "# load the segmentation model weights\n",
    "pickle = torch.load(saved_model_path, weights_only = False)\n",
    "segmentation_model_weights = pickle['network_weights']\n",
    "\n",
    "# get the weights of the classification model (with random initializations)\n",
    "classify_model_weights = classify_model.state_dict()\n",
    "\n",
    "# identify which layers are both in the segmentation encoder and classification encoder\n",
    "common_keys = classify_model_weights.keys() & segmentation_model_weights.keys()\n",
    "common_keys = list(common_keys)\n",
    "common_keys.sort()\n",
    "\n",
    "# replace the weights of the classification model with pre-trained segmentation model weights\n",
    "for key in common_keys:\n",
    "    classify_model_weights[key] = segmentation_model_weights[key]\n",
    "    \n",
    "    classify_key = key.replace('convs', 'classify_convs')\n",
    "    classify_model_weights[classify_key] = segmentation_model_weights[key]\n",
    "\n",
    "# update the model\n",
    "classify_model.load_state_dict(classify_model_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b88353-a365-4312-82e0-4145546e2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in classify_model.named_parameters():\n",
    "    if 'convs' in name and 'classify' not in name:\n",
    "        param.requires_grad = False\n",
    "    #if name contains convs\n",
    "    # then freeze param\n",
    "\n",
    "    # if name contains convs but not contains classify\n",
    "    # freeze param\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "154e6382-27e3-4f8c-b2f8-0f67f075905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.stages.0.0.convs.0.conv.weight False\n",
      "encoder.stages.0.0.convs.0.conv.bias False\n",
      "encoder.stages.0.0.convs.0.norm.weight False\n",
      "encoder.stages.0.0.convs.0.norm.bias False\n",
      "encoder.stages.0.0.convs.1.conv.weight False\n",
      "encoder.stages.0.0.convs.1.conv.bias False\n",
      "encoder.stages.0.0.convs.1.norm.weight False\n",
      "encoder.stages.0.0.convs.1.norm.bias False\n",
      "encoder.stages.0.0.classify_convs.0.conv.weight True\n",
      "encoder.stages.0.0.classify_convs.0.conv.bias True\n",
      "encoder.stages.0.0.classify_convs.0.norm.weight True\n",
      "encoder.stages.0.0.classify_convs.0.norm.bias True\n",
      "encoder.stages.0.0.classify_convs.1.conv.weight True\n",
      "encoder.stages.0.0.classify_convs.1.conv.bias True\n",
      "encoder.stages.0.0.classify_convs.1.norm.weight True\n",
      "encoder.stages.0.0.classify_convs.1.norm.bias True\n",
      "encoder.stages.0.0.attention_gate.conv.weight True\n",
      "encoder.stages.0.0.attention_gate.conv.bias True\n",
      "encoder.stages.1.0.convs.0.conv.weight False\n",
      "encoder.stages.1.0.convs.0.conv.bias False\n",
      "encoder.stages.1.0.convs.0.norm.weight False\n",
      "encoder.stages.1.0.convs.0.norm.bias False\n",
      "encoder.stages.1.0.convs.1.conv.weight False\n",
      "encoder.stages.1.0.convs.1.conv.bias False\n",
      "encoder.stages.1.0.convs.1.norm.weight False\n",
      "encoder.stages.1.0.convs.1.norm.bias False\n",
      "encoder.stages.1.0.classify_convs.0.conv.weight True\n",
      "encoder.stages.1.0.classify_convs.0.conv.bias True\n",
      "encoder.stages.1.0.classify_convs.0.norm.weight True\n",
      "encoder.stages.1.0.classify_convs.0.norm.bias True\n",
      "encoder.stages.1.0.classify_convs.1.conv.weight True\n",
      "encoder.stages.1.0.classify_convs.1.conv.bias True\n",
      "encoder.stages.1.0.classify_convs.1.norm.weight True\n",
      "encoder.stages.1.0.classify_convs.1.norm.bias True\n",
      "encoder.stages.1.0.attention_gate.conv.weight True\n",
      "encoder.stages.1.0.attention_gate.conv.bias True\n",
      "encoder.stages.2.0.convs.0.conv.weight False\n",
      "encoder.stages.2.0.convs.0.conv.bias False\n",
      "encoder.stages.2.0.convs.0.norm.weight False\n",
      "encoder.stages.2.0.convs.0.norm.bias False\n",
      "encoder.stages.2.0.convs.1.conv.weight False\n",
      "encoder.stages.2.0.convs.1.conv.bias False\n",
      "encoder.stages.2.0.convs.1.norm.weight False\n",
      "encoder.stages.2.0.convs.1.norm.bias False\n",
      "encoder.stages.2.0.classify_convs.0.conv.weight True\n",
      "encoder.stages.2.0.classify_convs.0.conv.bias True\n",
      "encoder.stages.2.0.classify_convs.0.norm.weight True\n",
      "encoder.stages.2.0.classify_convs.0.norm.bias True\n",
      "encoder.stages.2.0.classify_convs.1.conv.weight True\n",
      "encoder.stages.2.0.classify_convs.1.conv.bias True\n",
      "encoder.stages.2.0.classify_convs.1.norm.weight True\n",
      "encoder.stages.2.0.classify_convs.1.norm.bias True\n",
      "encoder.stages.2.0.attention_gate.conv.weight True\n",
      "encoder.stages.2.0.attention_gate.conv.bias True\n",
      "encoder.stages.3.0.convs.0.conv.weight False\n",
      "encoder.stages.3.0.convs.0.conv.bias False\n",
      "encoder.stages.3.0.convs.0.norm.weight False\n",
      "encoder.stages.3.0.convs.0.norm.bias False\n",
      "encoder.stages.3.0.convs.1.conv.weight False\n",
      "encoder.stages.3.0.convs.1.conv.bias False\n",
      "encoder.stages.3.0.convs.1.norm.weight False\n",
      "encoder.stages.3.0.convs.1.norm.bias False\n",
      "encoder.stages.3.0.classify_convs.0.conv.weight True\n",
      "encoder.stages.3.0.classify_convs.0.conv.bias True\n",
      "encoder.stages.3.0.classify_convs.0.norm.weight True\n",
      "encoder.stages.3.0.classify_convs.0.norm.bias True\n",
      "encoder.stages.3.0.classify_convs.1.conv.weight True\n",
      "encoder.stages.3.0.classify_convs.1.conv.bias True\n",
      "encoder.stages.3.0.classify_convs.1.norm.weight True\n",
      "encoder.stages.3.0.classify_convs.1.norm.bias True\n",
      "encoder.stages.3.0.attention_gate.conv.weight True\n",
      "encoder.stages.3.0.attention_gate.conv.bias True\n",
      "encoder.stages.4.0.convs.0.conv.weight False\n",
      "encoder.stages.4.0.convs.0.conv.bias False\n",
      "encoder.stages.4.0.convs.0.norm.weight False\n",
      "encoder.stages.4.0.convs.0.norm.bias False\n",
      "encoder.stages.4.0.convs.1.conv.weight False\n",
      "encoder.stages.4.0.convs.1.conv.bias False\n",
      "encoder.stages.4.0.convs.1.norm.weight False\n",
      "encoder.stages.4.0.convs.1.norm.bias False\n",
      "encoder.stages.4.0.classify_convs.0.conv.weight True\n",
      "encoder.stages.4.0.classify_convs.0.conv.bias True\n",
      "encoder.stages.4.0.classify_convs.0.norm.weight True\n",
      "encoder.stages.4.0.classify_convs.0.norm.bias True\n",
      "encoder.stages.4.0.classify_convs.1.conv.weight True\n",
      "encoder.stages.4.0.classify_convs.1.conv.bias True\n",
      "encoder.stages.4.0.classify_convs.1.norm.weight True\n",
      "encoder.stages.4.0.classify_convs.1.norm.bias True\n",
      "encoder.stages.4.0.attention_gate.conv.weight True\n",
      "encoder.stages.4.0.attention_gate.conv.bias True\n",
      "encoder.stages.5.0.convs.0.conv.weight False\n",
      "encoder.stages.5.0.convs.0.conv.bias False\n",
      "encoder.stages.5.0.convs.0.norm.weight False\n",
      "encoder.stages.5.0.convs.0.norm.bias False\n",
      "encoder.stages.5.0.convs.1.conv.weight False\n",
      "encoder.stages.5.0.convs.1.conv.bias False\n",
      "encoder.stages.5.0.convs.1.norm.weight False\n",
      "encoder.stages.5.0.convs.1.norm.bias False\n",
      "encoder.stages.5.0.classify_convs.0.conv.weight True\n",
      "encoder.stages.5.0.classify_convs.0.conv.bias True\n",
      "encoder.stages.5.0.classify_convs.0.norm.weight True\n",
      "encoder.stages.5.0.classify_convs.0.norm.bias True\n",
      "encoder.stages.5.0.classify_convs.1.conv.weight True\n",
      "encoder.stages.5.0.classify_convs.1.conv.bias True\n",
      "encoder.stages.5.0.classify_convs.1.norm.weight True\n",
      "encoder.stages.5.0.classify_convs.1.norm.bias True\n",
      "encoder.stages.5.0.attention_gate.conv.weight True\n",
      "encoder.stages.5.0.attention_gate.conv.bias True\n",
      "decoder.FC1.weight True\n",
      "decoder.FC1.bias True\n",
      "decoder.FC2.weight True\n",
      "decoder.FC2.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in classify_model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3b3efb3-3f6c-4f99-9dd7-9d0d74ad0f92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.stages.0.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.0.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.0.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.0.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.0.0.convs.0.conv.bias\n",
      "encoder.stages.0.0.convs.0.conv.weight\n",
      "encoder.stages.0.0.convs.0.norm.bias\n",
      "encoder.stages.0.0.convs.0.norm.weight\n",
      "encoder.stages.0.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.0.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.0.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.0.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.0.0.convs.1.conv.bias\n",
      "encoder.stages.0.0.convs.1.conv.weight\n",
      "encoder.stages.0.0.convs.1.norm.bias\n",
      "encoder.stages.0.0.convs.1.norm.weight\n",
      "encoder.stages.1.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.1.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.1.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.1.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.1.0.convs.0.conv.bias\n",
      "encoder.stages.1.0.convs.0.conv.weight\n",
      "encoder.stages.1.0.convs.0.norm.bias\n",
      "encoder.stages.1.0.convs.0.norm.weight\n",
      "encoder.stages.1.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.1.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.1.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.1.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.1.0.convs.1.conv.bias\n",
      "encoder.stages.1.0.convs.1.conv.weight\n",
      "encoder.stages.1.0.convs.1.norm.bias\n",
      "encoder.stages.1.0.convs.1.norm.weight\n",
      "encoder.stages.2.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.2.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.2.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.2.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.2.0.convs.0.conv.bias\n",
      "encoder.stages.2.0.convs.0.conv.weight\n",
      "encoder.stages.2.0.convs.0.norm.bias\n",
      "encoder.stages.2.0.convs.0.norm.weight\n",
      "encoder.stages.2.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.2.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.2.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.2.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.2.0.convs.1.conv.bias\n",
      "encoder.stages.2.0.convs.1.conv.weight\n",
      "encoder.stages.2.0.convs.1.norm.bias\n",
      "encoder.stages.2.0.convs.1.norm.weight\n",
      "encoder.stages.3.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.3.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.3.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.3.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.3.0.convs.0.conv.bias\n",
      "encoder.stages.3.0.convs.0.conv.weight\n",
      "encoder.stages.3.0.convs.0.norm.bias\n",
      "encoder.stages.3.0.convs.0.norm.weight\n",
      "encoder.stages.3.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.3.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.3.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.3.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.3.0.convs.1.conv.bias\n",
      "encoder.stages.3.0.convs.1.conv.weight\n",
      "encoder.stages.3.0.convs.1.norm.bias\n",
      "encoder.stages.3.0.convs.1.norm.weight\n",
      "encoder.stages.4.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.4.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.4.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.4.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.4.0.convs.0.conv.bias\n",
      "encoder.stages.4.0.convs.0.conv.weight\n",
      "encoder.stages.4.0.convs.0.norm.bias\n",
      "encoder.stages.4.0.convs.0.norm.weight\n",
      "encoder.stages.4.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.4.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.4.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.4.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.4.0.convs.1.conv.bias\n",
      "encoder.stages.4.0.convs.1.conv.weight\n",
      "encoder.stages.4.0.convs.1.norm.bias\n",
      "encoder.stages.4.0.convs.1.norm.weight\n",
      "encoder.stages.5.0.convs.0.all_modules.0.bias\n",
      "encoder.stages.5.0.convs.0.all_modules.0.weight\n",
      "encoder.stages.5.0.convs.0.all_modules.1.bias\n",
      "encoder.stages.5.0.convs.0.all_modules.1.weight\n",
      "encoder.stages.5.0.convs.0.conv.bias\n",
      "encoder.stages.5.0.convs.0.conv.weight\n",
      "encoder.stages.5.0.convs.0.norm.bias\n",
      "encoder.stages.5.0.convs.0.norm.weight\n",
      "encoder.stages.5.0.convs.1.all_modules.0.bias\n",
      "encoder.stages.5.0.convs.1.all_modules.0.weight\n",
      "encoder.stages.5.0.convs.1.all_modules.1.bias\n",
      "encoder.stages.5.0.convs.1.all_modules.1.weight\n",
      "encoder.stages.5.0.convs.1.conv.bias\n",
      "encoder.stages.5.0.convs.1.conv.weight\n",
      "encoder.stages.5.0.convs.1.norm.bias\n",
      "encoder.stages.5.0.convs.1.norm.weight\n"
     ]
    }
   ],
   "source": [
    "for key in common_keys:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081822de-12a5-4913-8eb1-b153bfd0168d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a980623d-4813-4f00-9d45-d1c334cd5d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-7.2278e-02, -3.3149e-02, -4.2815e-02],\n",
      "           [-7.2781e-02, -9.2624e-02,  2.9016e-01],\n",
      "           [ 4.4994e-01, -4.1597e-01,  4.4787e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.2829e-01,  9.0586e-02,  4.3066e-01],\n",
      "           [-6.6217e-01,  7.9920e-02,  6.7638e-01],\n",
      "           [-3.7028e-01, -1.8988e-01,  5.3336e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.8833e-01,  4.5634e-01,  2.3674e-01],\n",
      "           [-1.0797e-01,  4.0362e-01,  1.4066e-01],\n",
      "           [ 3.3304e-03, -7.0152e-01, -9.2850e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.4078e-01, -5.8295e-01,  4.7005e-01],\n",
      "           [-3.2339e-01, -5.3966e-01,  3.3987e-01],\n",
      "           [-5.8612e-02,  5.8490e-01,  7.2286e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.1391e-01,  8.6111e-02,  2.2119e-01],\n",
      "           [ 3.3159e-01,  3.7024e-01, -1.9706e-01],\n",
      "           [-1.4893e-02,  1.6651e-01, -4.8422e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1574e-01,  2.4167e-01, -3.8216e-01],\n",
      "           [-3.8319e-01,  3.9457e-01,  1.7448e-03],\n",
      "           [ 5.2181e-02,  1.0879e-02, -2.8775e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.4068e-01, -3.5391e-01,  1.5401e-01],\n",
      "           [-1.5114e-01, -5.5124e-01, -1.1130e-01],\n",
      "           [ 2.7489e-01, -4.0689e-01,  1.2528e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6650e-01, -7.8283e-02,  1.3884e-01],\n",
      "           [ 1.4714e-02,  6.4932e-02, -4.8938e-02],\n",
      "           [ 3.0095e-01,  2.6000e-03,  4.2376e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.9993e-01,  2.4653e-01,  2.0129e-01],\n",
      "           [-1.8422e-01,  6.2073e-02, -4.0553e-01],\n",
      "           [ 8.6886e-02,  3.1134e-02, -2.5813e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.2722e-02,  3.1329e-01,  3.5401e-01],\n",
      "           [ 8.8314e-02,  2.1406e-02,  2.7517e-01],\n",
      "           [-3.9401e-01,  1.1625e-01, -5.3299e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1041e-01, -5.2047e-01,  6.8465e-03],\n",
      "           [ 4.1224e-01,  4.3761e-01,  2.1033e-01],\n",
      "           [ 4.9028e-01,  9.1134e-02, -5.7714e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 5.4136e-01, -2.1104e-01,  1.2127e-01],\n",
      "           [-2.4770e-02, -1.8547e-01, -4.6079e-01],\n",
      "           [-3.0718e-01, -1.4434e-01, -2.1920e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.1967e-01,  3.6581e-01,  8.0882e-01],\n",
      "           [-1.8232e-02,  1.3409e-01,  3.1874e-01],\n",
      "           [-6.3050e-01, -8.9668e-01, -2.5530e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6629e-01, -1.4730e-01, -4.2901e-01],\n",
      "           [ 3.3936e-02,  4.5664e-01,  1.6700e-01],\n",
      "           [-1.2450e-01, -3.3423e-01, -8.0051e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.2171e-01,  2.0839e-02,  7.9844e-02],\n",
      "           [-2.1375e-01,  3.5642e-01,  6.2530e-01],\n",
      "           [-3.7417e-01, -2.0081e-01,  2.1332e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.6229e-01, -2.2799e-01,  1.5185e-01],\n",
      "           [-1.7348e-01,  5.0339e-02,  2.7911e-01],\n",
      "           [ 3.7582e-01, -9.8407e-02,  2.0451e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.3586e-01, -3.6981e-01,  9.2282e-02],\n",
      "           [-2.8573e-01,  6.0338e-01, -1.2991e-01],\n",
      "           [ 4.2026e-01, -7.4931e-04,  2.6605e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1131e-01,  4.4632e-01,  4.3030e-02],\n",
      "           [-1.7967e-01, -1.6237e-01,  9.0884e-02],\n",
      "           [ 3.0445e-02, -7.0263e-01, -3.9988e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-8.8214e-02,  2.9311e-01, -7.5819e-02],\n",
      "           [ 1.4613e-01,  1.3260e-03,  2.2243e-01],\n",
      "           [ 2.9774e-01, -1.0320e-01,  8.3228e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.8302e-02,  2.2906e-01, -1.1333e-02],\n",
      "           [ 1.3230e-01,  5.7250e-02,  1.5237e-01],\n",
      "           [ 4.1598e-01, -1.3882e-02,  1.8526e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.8518e-01, -6.2788e-01,  1.9852e-01],\n",
      "           [-1.1502e-02, -8.4247e-02,  1.4349e-01],\n",
      "           [ 8.7122e-02,  5.3828e-01,  1.8391e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.5287e-01, -2.1856e-02, -1.0526e+00],\n",
      "           [ 5.7537e-01, -3.3896e-01, -8.3055e-01],\n",
      "           [ 4.7835e-01,  4.5460e-01,  2.7480e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.7427e-01, -9.4581e-01, -6.6154e-01],\n",
      "           [ 3.8666e-01, -1.0533e-01, -3.4075e-02],\n",
      "           [ 6.6215e-01,  7.2406e-01,  6.1030e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.4384e-01, -2.0137e-01, -2.4429e-01],\n",
      "           [ 4.5550e-04, -3.0852e-01, -4.1074e-01],\n",
      "           [ 2.3441e-02, -9.8645e-02,  1.7738e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.2006e-01,  5.9769e-02,  5.5822e-01],\n",
      "           [-2.3183e-01,  2.2737e-01,  2.8589e-01],\n",
      "           [-2.9154e-01,  1.3073e-02,  4.4778e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.6636e-01, -4.1546e-02, -5.1378e-01],\n",
      "           [ 4.0439e-02,  8.7156e-01,  4.1592e-01],\n",
      "           [-3.1879e-01, -2.1090e-01,  3.7152e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.5641e-01, -2.6198e-01, -3.5578e-02],\n",
      "           [-5.0512e-02,  9.4043e-03, -2.6287e-01],\n",
      "           [ 4.5526e-01,  1.3788e-01,  4.7837e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.9951e-01,  2.0120e-01,  1.8493e-01],\n",
      "           [ 3.9317e-02,  2.3589e-01,  1.4783e-01],\n",
      "           [-1.9850e-01, -2.5738e-01, -4.2087e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.5384e-01, -1.0884e-01,  1.9847e-01],\n",
      "           [-1.2220e-01, -3.7519e-03,  2.1625e-01],\n",
      "           [-5.8314e-01, -2.2334e-01,  6.6643e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.7868e-01,  4.1827e-01,  3.8458e-01],\n",
      "           [-3.4891e-01, -1.0184e-01,  1.6509e-01],\n",
      "           [ 3.6310e-01, -2.0314e-01, -2.8370e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.9889e-01, -3.4620e-02,  1.8525e-01],\n",
      "           [-6.3874e-02,  2.2982e-01,  1.5629e-01],\n",
      "           [-6.6389e-01,  4.7128e-02,  1.0234e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.1662e-01,  6.9957e-02,  4.0835e-02],\n",
      "           [ 6.9419e-01, -5.0743e-02, -1.0109e+00],\n",
      "           [ 5.5998e-01, -4.5499e-01, -3.5846e-01]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test to see if they are the same\n",
    "test_classify_model_weights = classify_model.state_dict()\n",
    "\n",
    "print(test_classify_model_weights['encoder.stages.0.0.convs.0.conv.weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edd779f2-789f-4ac8-b39c-3c644bf61526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-7.2278e-02, -3.3149e-02, -4.2815e-02],\n",
      "           [-7.2781e-02, -9.2624e-02,  2.9016e-01],\n",
      "           [ 4.4994e-01, -4.1597e-01,  4.4787e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.2829e-01,  9.0586e-02,  4.3066e-01],\n",
      "           [-6.6217e-01,  7.9920e-02,  6.7638e-01],\n",
      "           [-3.7028e-01, -1.8988e-01,  5.3336e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.8833e-01,  4.5634e-01,  2.3674e-01],\n",
      "           [-1.0797e-01,  4.0362e-01,  1.4066e-01],\n",
      "           [ 3.3304e-03, -7.0152e-01, -9.2850e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.4078e-01, -5.8295e-01,  4.7005e-01],\n",
      "           [-3.2339e-01, -5.3966e-01,  3.3987e-01],\n",
      "           [-5.8612e-02,  5.8490e-01,  7.2286e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.1391e-01,  8.6111e-02,  2.2119e-01],\n",
      "           [ 3.3159e-01,  3.7024e-01, -1.9706e-01],\n",
      "           [-1.4893e-02,  1.6651e-01, -4.8422e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1574e-01,  2.4167e-01, -3.8216e-01],\n",
      "           [-3.8319e-01,  3.9457e-01,  1.7448e-03],\n",
      "           [ 5.2181e-02,  1.0879e-02, -2.8775e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.4068e-01, -3.5391e-01,  1.5401e-01],\n",
      "           [-1.5114e-01, -5.5124e-01, -1.1130e-01],\n",
      "           [ 2.7489e-01, -4.0689e-01,  1.2528e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6650e-01, -7.8283e-02,  1.3884e-01],\n",
      "           [ 1.4714e-02,  6.4932e-02, -4.8938e-02],\n",
      "           [ 3.0095e-01,  2.6000e-03,  4.2376e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.9993e-01,  2.4653e-01,  2.0129e-01],\n",
      "           [-1.8422e-01,  6.2073e-02, -4.0553e-01],\n",
      "           [ 8.6886e-02,  3.1134e-02, -2.5813e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.2722e-02,  3.1329e-01,  3.5401e-01],\n",
      "           [ 8.8314e-02,  2.1406e-02,  2.7517e-01],\n",
      "           [-3.9401e-01,  1.1625e-01, -5.3299e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1041e-01, -5.2047e-01,  6.8465e-03],\n",
      "           [ 4.1224e-01,  4.3761e-01,  2.1033e-01],\n",
      "           [ 4.9028e-01,  9.1134e-02, -5.7714e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 5.4136e-01, -2.1104e-01,  1.2127e-01],\n",
      "           [-2.4770e-02, -1.8547e-01, -4.6079e-01],\n",
      "           [-3.0718e-01, -1.4434e-01, -2.1920e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.1967e-01,  3.6581e-01,  8.0882e-01],\n",
      "           [-1.8232e-02,  1.3409e-01,  3.1874e-01],\n",
      "           [-6.3050e-01, -8.9668e-01, -2.5530e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6629e-01, -1.4730e-01, -4.2901e-01],\n",
      "           [ 3.3936e-02,  4.5664e-01,  1.6700e-01],\n",
      "           [-1.2450e-01, -3.3423e-01, -8.0051e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.2171e-01,  2.0839e-02,  7.9844e-02],\n",
      "           [-2.1375e-01,  3.5642e-01,  6.2530e-01],\n",
      "           [-3.7417e-01, -2.0081e-01,  2.1332e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.6229e-01, -2.2799e-01,  1.5185e-01],\n",
      "           [-1.7348e-01,  5.0339e-02,  2.7911e-01],\n",
      "           [ 3.7582e-01, -9.8407e-02,  2.0451e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.3586e-01, -3.6981e-01,  9.2282e-02],\n",
      "           [-2.8573e-01,  6.0338e-01, -1.2991e-01],\n",
      "           [ 4.2026e-01, -7.4931e-04,  2.6605e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1131e-01,  4.4632e-01,  4.3030e-02],\n",
      "           [-1.7967e-01, -1.6237e-01,  9.0884e-02],\n",
      "           [ 3.0445e-02, -7.0263e-01, -3.9988e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-8.8214e-02,  2.9311e-01, -7.5819e-02],\n",
      "           [ 1.4613e-01,  1.3260e-03,  2.2243e-01],\n",
      "           [ 2.9774e-01, -1.0320e-01,  8.3228e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.8302e-02,  2.2906e-01, -1.1333e-02],\n",
      "           [ 1.3230e-01,  5.7250e-02,  1.5237e-01],\n",
      "           [ 4.1598e-01, -1.3882e-02,  1.8526e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.8518e-01, -6.2788e-01,  1.9852e-01],\n",
      "           [-1.1502e-02, -8.4247e-02,  1.4349e-01],\n",
      "           [ 8.7122e-02,  5.3828e-01,  1.8391e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.5287e-01, -2.1856e-02, -1.0526e+00],\n",
      "           [ 5.7537e-01, -3.3896e-01, -8.3055e-01],\n",
      "           [ 4.7835e-01,  4.5460e-01,  2.7480e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.7427e-01, -9.4581e-01, -6.6154e-01],\n",
      "           [ 3.8666e-01, -1.0533e-01, -3.4075e-02],\n",
      "           [ 6.6215e-01,  7.2406e-01,  6.1030e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.4384e-01, -2.0137e-01, -2.4429e-01],\n",
      "           [ 4.5550e-04, -3.0852e-01, -4.1074e-01],\n",
      "           [ 2.3441e-02, -9.8645e-02,  1.7738e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.2006e-01,  5.9769e-02,  5.5822e-01],\n",
      "           [-2.3183e-01,  2.2737e-01,  2.8589e-01],\n",
      "           [-2.9154e-01,  1.3073e-02,  4.4778e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.6636e-01, -4.1546e-02, -5.1378e-01],\n",
      "           [ 4.0439e-02,  8.7156e-01,  4.1592e-01],\n",
      "           [-3.1879e-01, -2.1090e-01,  3.7152e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.5641e-01, -2.6198e-01, -3.5578e-02],\n",
      "           [-5.0512e-02,  9.4043e-03, -2.6287e-01],\n",
      "           [ 4.5526e-01,  1.3788e-01,  4.7837e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.9951e-01,  2.0120e-01,  1.8493e-01],\n",
      "           [ 3.9317e-02,  2.3589e-01,  1.4783e-01],\n",
      "           [-1.9850e-01, -2.5738e-01, -4.2087e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.5384e-01, -1.0884e-01,  1.9847e-01],\n",
      "           [-1.2220e-01, -3.7519e-03,  2.1625e-01],\n",
      "           [-5.8314e-01, -2.2334e-01,  6.6643e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.7868e-01,  4.1827e-01,  3.8458e-01],\n",
      "           [-3.4891e-01, -1.0184e-01,  1.6509e-01],\n",
      "           [ 3.6310e-01, -2.0314e-01, -2.8370e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.9889e-01, -3.4620e-02,  1.8525e-01],\n",
      "           [-6.3874e-02,  2.2982e-01,  1.5629e-01],\n",
      "           [-6.6389e-01,  4.7128e-02,  1.0234e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.1662e-01,  6.9957e-02,  4.0835e-02],\n",
      "           [ 6.9419e-01, -5.0743e-02, -1.0109e+00],\n",
      "           [ 5.5998e-01, -4.5499e-01, -3.5846e-01]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(segmentation_model_weights['encoder.stages.0.0.convs.0.conv.weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5c6aa32-90eb-41e1-99d9-d5ec95c0b87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-7.2278e-02, -3.3149e-02, -4.2815e-02],\n",
      "           [-7.2781e-02, -9.2624e-02,  2.9016e-01],\n",
      "           [ 4.4994e-01, -4.1597e-01,  4.4787e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.2829e-01,  9.0586e-02,  4.3066e-01],\n",
      "           [-6.6217e-01,  7.9920e-02,  6.7638e-01],\n",
      "           [-3.7028e-01, -1.8988e-01,  5.3336e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.8833e-01,  4.5634e-01,  2.3674e-01],\n",
      "           [-1.0797e-01,  4.0362e-01,  1.4066e-01],\n",
      "           [ 3.3304e-03, -7.0152e-01, -9.2850e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.4078e-01, -5.8295e-01,  4.7005e-01],\n",
      "           [-3.2339e-01, -5.3966e-01,  3.3987e-01],\n",
      "           [-5.8612e-02,  5.8490e-01,  7.2286e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.1391e-01,  8.6111e-02,  2.2119e-01],\n",
      "           [ 3.3159e-01,  3.7024e-01, -1.9706e-01],\n",
      "           [-1.4893e-02,  1.6651e-01, -4.8422e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1574e-01,  2.4167e-01, -3.8216e-01],\n",
      "           [-3.8319e-01,  3.9457e-01,  1.7448e-03],\n",
      "           [ 5.2181e-02,  1.0879e-02, -2.8775e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.4068e-01, -3.5391e-01,  1.5401e-01],\n",
      "           [-1.5114e-01, -5.5124e-01, -1.1130e-01],\n",
      "           [ 2.7489e-01, -4.0689e-01,  1.2528e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6650e-01, -7.8283e-02,  1.3884e-01],\n",
      "           [ 1.4714e-02,  6.4932e-02, -4.8938e-02],\n",
      "           [ 3.0095e-01,  2.6000e-03,  4.2376e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.9993e-01,  2.4653e-01,  2.0129e-01],\n",
      "           [-1.8422e-01,  6.2073e-02, -4.0553e-01],\n",
      "           [ 8.6886e-02,  3.1134e-02, -2.5813e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.2722e-02,  3.1329e-01,  3.5401e-01],\n",
      "           [ 8.8314e-02,  2.1406e-02,  2.7517e-01],\n",
      "           [-3.9401e-01,  1.1625e-01, -5.3299e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1041e-01, -5.2047e-01,  6.8465e-03],\n",
      "           [ 4.1224e-01,  4.3761e-01,  2.1033e-01],\n",
      "           [ 4.9028e-01,  9.1134e-02, -5.7714e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 5.4136e-01, -2.1104e-01,  1.2127e-01],\n",
      "           [-2.4770e-02, -1.8547e-01, -4.6079e-01],\n",
      "           [-3.0718e-01, -1.4434e-01, -2.1920e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.1967e-01,  3.6581e-01,  8.0882e-01],\n",
      "           [-1.8232e-02,  1.3409e-01,  3.1874e-01],\n",
      "           [-6.3050e-01, -8.9668e-01, -2.5530e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6629e-01, -1.4730e-01, -4.2901e-01],\n",
      "           [ 3.3936e-02,  4.5664e-01,  1.6700e-01],\n",
      "           [-1.2450e-01, -3.3423e-01, -8.0051e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.2171e-01,  2.0839e-02,  7.9844e-02],\n",
      "           [-2.1375e-01,  3.5642e-01,  6.2530e-01],\n",
      "           [-3.7417e-01, -2.0081e-01,  2.1332e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.6229e-01, -2.2799e-01,  1.5185e-01],\n",
      "           [-1.7348e-01,  5.0339e-02,  2.7911e-01],\n",
      "           [ 3.7582e-01, -9.8407e-02,  2.0451e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.3586e-01, -3.6981e-01,  9.2282e-02],\n",
      "           [-2.8573e-01,  6.0338e-01, -1.2991e-01],\n",
      "           [ 4.2026e-01, -7.4931e-04,  2.6605e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1131e-01,  4.4632e-01,  4.3030e-02],\n",
      "           [-1.7967e-01, -1.6237e-01,  9.0884e-02],\n",
      "           [ 3.0445e-02, -7.0263e-01, -3.9988e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-8.8214e-02,  2.9311e-01, -7.5819e-02],\n",
      "           [ 1.4613e-01,  1.3260e-03,  2.2243e-01],\n",
      "           [ 2.9774e-01, -1.0320e-01,  8.3228e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.8302e-02,  2.2906e-01, -1.1333e-02],\n",
      "           [ 1.3230e-01,  5.7250e-02,  1.5237e-01],\n",
      "           [ 4.1598e-01, -1.3882e-02,  1.8526e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.8518e-01, -6.2788e-01,  1.9852e-01],\n",
      "           [-1.1502e-02, -8.4247e-02,  1.4349e-01],\n",
      "           [ 8.7122e-02,  5.3828e-01,  1.8391e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.5287e-01, -2.1856e-02, -1.0526e+00],\n",
      "           [ 5.7537e-01, -3.3896e-01, -8.3055e-01],\n",
      "           [ 4.7835e-01,  4.5460e-01,  2.7480e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.7427e-01, -9.4581e-01, -6.6154e-01],\n",
      "           [ 3.8666e-01, -1.0533e-01, -3.4075e-02],\n",
      "           [ 6.6215e-01,  7.2406e-01,  6.1030e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.4384e-01, -2.0137e-01, -2.4429e-01],\n",
      "           [ 4.5550e-04, -3.0852e-01, -4.1074e-01],\n",
      "           [ 2.3441e-02, -9.8645e-02,  1.7738e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.2006e-01,  5.9769e-02,  5.5822e-01],\n",
      "           [-2.3183e-01,  2.2737e-01,  2.8589e-01],\n",
      "           [-2.9154e-01,  1.3073e-02,  4.4778e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.6636e-01, -4.1546e-02, -5.1378e-01],\n",
      "           [ 4.0439e-02,  8.7156e-01,  4.1592e-01],\n",
      "           [-3.1879e-01, -2.1090e-01,  3.7152e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.5641e-01, -2.6198e-01, -3.5578e-02],\n",
      "           [-5.0512e-02,  9.4043e-03, -2.6287e-01],\n",
      "           [ 4.5526e-01,  1.3788e-01,  4.7837e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.9951e-01,  2.0120e-01,  1.8493e-01],\n",
      "           [ 3.9317e-02,  2.3589e-01,  1.4783e-01],\n",
      "           [-1.9850e-01, -2.5738e-01, -4.2087e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.5384e-01, -1.0884e-01,  1.9847e-01],\n",
      "           [-1.2220e-01, -3.7519e-03,  2.1625e-01],\n",
      "           [-5.8314e-01, -2.2334e-01,  6.6643e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.7868e-01,  4.1827e-01,  3.8458e-01],\n",
      "           [-3.4891e-01, -1.0184e-01,  1.6509e-01],\n",
      "           [ 3.6310e-01, -2.0314e-01, -2.8370e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.9889e-01, -3.4620e-02,  1.8525e-01],\n",
      "           [-6.3874e-02,  2.2982e-01,  1.5629e-01],\n",
      "           [-6.6389e-01,  4.7128e-02,  1.0234e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.1662e-01,  6.9957e-02,  4.0835e-02],\n",
      "           [ 6.9419e-01, -5.0743e-02, -1.0109e+00],\n",
      "           [ 5.5998e-01, -4.5499e-01, -3.5846e-01]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(test_classify_model_weights['encoder.stages.0.0.convs.0.conv.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32f666d9-ef03-4b4b-adca-36a5e649f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-7.2278e-02, -3.3149e-02, -4.2815e-02],\n",
      "           [-7.2781e-02, -9.2624e-02,  2.9016e-01],\n",
      "           [ 4.4994e-01, -4.1597e-01,  4.4787e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.2829e-01,  9.0586e-02,  4.3066e-01],\n",
      "           [-6.6217e-01,  7.9920e-02,  6.7638e-01],\n",
      "           [-3.7028e-01, -1.8988e-01,  5.3336e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.8833e-01,  4.5634e-01,  2.3674e-01],\n",
      "           [-1.0797e-01,  4.0362e-01,  1.4066e-01],\n",
      "           [ 3.3304e-03, -7.0152e-01, -9.2850e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.4078e-01, -5.8295e-01,  4.7005e-01],\n",
      "           [-3.2339e-01, -5.3966e-01,  3.3987e-01],\n",
      "           [-5.8612e-02,  5.8490e-01,  7.2286e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.1391e-01,  8.6111e-02,  2.2119e-01],\n",
      "           [ 3.3159e-01,  3.7024e-01, -1.9706e-01],\n",
      "           [-1.4893e-02,  1.6651e-01, -4.8422e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1574e-01,  2.4167e-01, -3.8216e-01],\n",
      "           [-3.8319e-01,  3.9457e-01,  1.7448e-03],\n",
      "           [ 5.2181e-02,  1.0879e-02, -2.8775e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.4068e-01, -3.5391e-01,  1.5401e-01],\n",
      "           [-1.5114e-01, -5.5124e-01, -1.1130e-01],\n",
      "           [ 2.7489e-01, -4.0689e-01,  1.2528e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6650e-01, -7.8283e-02,  1.3884e-01],\n",
      "           [ 1.4714e-02,  6.4932e-02, -4.8938e-02],\n",
      "           [ 3.0095e-01,  2.6000e-03,  4.2376e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.9993e-01,  2.4653e-01,  2.0129e-01],\n",
      "           [-1.8422e-01,  6.2073e-02, -4.0553e-01],\n",
      "           [ 8.6886e-02,  3.1134e-02, -2.5813e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.2722e-02,  3.1329e-01,  3.5401e-01],\n",
      "           [ 8.8314e-02,  2.1406e-02,  2.7517e-01],\n",
      "           [-3.9401e-01,  1.1625e-01, -5.3299e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1041e-01, -5.2047e-01,  6.8465e-03],\n",
      "           [ 4.1224e-01,  4.3761e-01,  2.1033e-01],\n",
      "           [ 4.9028e-01,  9.1134e-02, -5.7714e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 5.4136e-01, -2.1104e-01,  1.2127e-01],\n",
      "           [-2.4770e-02, -1.8547e-01, -4.6079e-01],\n",
      "           [-3.0718e-01, -1.4434e-01, -2.1920e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.1967e-01,  3.6581e-01,  8.0882e-01],\n",
      "           [-1.8232e-02,  1.3409e-01,  3.1874e-01],\n",
      "           [-6.3050e-01, -8.9668e-01, -2.5530e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6629e-01, -1.4730e-01, -4.2901e-01],\n",
      "           [ 3.3936e-02,  4.5664e-01,  1.6700e-01],\n",
      "           [-1.2450e-01, -3.3423e-01, -8.0051e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.2171e-01,  2.0839e-02,  7.9844e-02],\n",
      "           [-2.1375e-01,  3.5642e-01,  6.2530e-01],\n",
      "           [-3.7417e-01, -2.0081e-01,  2.1332e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.6229e-01, -2.2799e-01,  1.5185e-01],\n",
      "           [-1.7348e-01,  5.0339e-02,  2.7911e-01],\n",
      "           [ 3.7582e-01, -9.8407e-02,  2.0451e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.3586e-01, -3.6981e-01,  9.2282e-02],\n",
      "           [-2.8573e-01,  6.0338e-01, -1.2991e-01],\n",
      "           [ 4.2026e-01, -7.4931e-04,  2.6605e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1131e-01,  4.4632e-01,  4.3030e-02],\n",
      "           [-1.7967e-01, -1.6237e-01,  9.0884e-02],\n",
      "           [ 3.0445e-02, -7.0263e-01, -3.9988e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-8.8214e-02,  2.9311e-01, -7.5819e-02],\n",
      "           [ 1.4613e-01,  1.3260e-03,  2.2243e-01],\n",
      "           [ 2.9774e-01, -1.0320e-01,  8.3228e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.8302e-02,  2.2906e-01, -1.1333e-02],\n",
      "           [ 1.3230e-01,  5.7250e-02,  1.5237e-01],\n",
      "           [ 4.1598e-01, -1.3882e-02,  1.8526e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.8518e-01, -6.2788e-01,  1.9852e-01],\n",
      "           [-1.1502e-02, -8.4247e-02,  1.4349e-01],\n",
      "           [ 8.7122e-02,  5.3828e-01,  1.8391e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.5287e-01, -2.1856e-02, -1.0526e+00],\n",
      "           [ 5.7537e-01, -3.3896e-01, -8.3055e-01],\n",
      "           [ 4.7835e-01,  4.5460e-01,  2.7480e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-5.7427e-01, -9.4581e-01, -6.6154e-01],\n",
      "           [ 3.8666e-01, -1.0533e-01, -3.4075e-02],\n",
      "           [ 6.6215e-01,  7.2406e-01,  6.1030e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.4384e-01, -2.0137e-01, -2.4429e-01],\n",
      "           [ 4.5550e-04, -3.0852e-01, -4.1074e-01],\n",
      "           [ 2.3441e-02, -9.8645e-02,  1.7738e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.2006e-01,  5.9769e-02,  5.5822e-01],\n",
      "           [-2.3183e-01,  2.2737e-01,  2.8589e-01],\n",
      "           [-2.9154e-01,  1.3073e-02,  4.4778e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.6636e-01, -4.1546e-02, -5.1378e-01],\n",
      "           [ 4.0439e-02,  8.7156e-01,  4.1592e-01],\n",
      "           [-3.1879e-01, -2.1090e-01,  3.7152e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.5641e-01, -2.6198e-01, -3.5578e-02],\n",
      "           [-5.0512e-02,  9.4043e-03, -2.6287e-01],\n",
      "           [ 4.5526e-01,  1.3788e-01,  4.7837e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.9951e-01,  2.0120e-01,  1.8493e-01],\n",
      "           [ 3.9317e-02,  2.3589e-01,  1.4783e-01],\n",
      "           [-1.9850e-01, -2.5738e-01, -4.2087e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.5384e-01, -1.0884e-01,  1.9847e-01],\n",
      "           [-1.2220e-01, -3.7519e-03,  2.1625e-01],\n",
      "           [-5.8314e-01, -2.2334e-01,  6.6643e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.7868e-01,  4.1827e-01,  3.8458e-01],\n",
      "           [-3.4891e-01, -1.0184e-01,  1.6509e-01],\n",
      "           [ 3.6310e-01, -2.0314e-01, -2.8370e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.9889e-01, -3.4620e-02,  1.8525e-01],\n",
      "           [-6.3874e-02,  2.2982e-01,  1.5629e-01],\n",
      "           [-6.6389e-01,  4.7128e-02,  1.0234e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.1662e-01,  6.9957e-02,  4.0835e-02],\n",
      "           [ 6.9419e-01, -5.0743e-02, -1.0109e+00],\n",
      "           [ 5.5998e-01, -4.5499e-01, -3.5846e-01]]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(classify_model_weights['encoder.stages.0.0.classify_convs.0.conv.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16718235-9867-4a8a-80f1-b2e8dd7fcee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844a31e-5d9b-4618-8c06-3e6664030705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3468765-9b1d-4fdd-91b3-fc6eb8cf98a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd989e02-3bca-4f2c-9b24-547bcd42de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(3, 1, 64, 128, 192)\n",
    "\n",
    "data = data.cuda()\n",
    "outputs = classify_model(data) # this should be a list of torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b46635db-4e5f-40b6-9870-9101692b45fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0111,  0.0458, -0.0181],\n",
      "        [-0.0086,  0.0299, -0.0497],\n",
      "        [-0.0100,  0.0515, -0.0363]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2b3d2ce-d06b-4d7c-89e4-3ecfa9284c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lesions = torch.tensor([[0., 1., 0.], \n",
    " [1., 0., 0.], \n",
    " [0., 0., 1.]])\n",
    "lesions = lesions.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d95bb924-6257-466b-843b-7fea2b5949ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fx = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94df04f8-c867-4451-b614-ba148ab7fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = torch.tensor([[.05, .9, .05], \n",
    " [.9, .05, .05], \n",
    " [0., 0., 1.]])\n",
    "predict = predict.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1319a47-ba07-44df-87a4-6a2eaa61b71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5957, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(loss_fx(predict, lesions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c595940f-dc7f-4819-931e-8a41a61ae047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ENCODERS and DECODER-ENCODER and DECODERS:\n",
    "\n",
    "# there are 3 types: encoder, decoder.encoder, and decoder\n",
    "#encoder.stages.0.0.convs.0.conv.weight\n",
    "#decoder.encoder.stages.0.0.convs.0.conv.weight\n",
    "#decoder.stages.0.convs.0.conv.weight\n",
    "\n",
    "\n",
    "# for encoder and decoder.encoder, there are 6 stages (0 to 5):\n",
    "#encoder.stages.0.0.convs.0.conv.weight\n",
    "#...\n",
    "#encoder.stages.5.0.convs.0.conv.weight\n",
    "#          and\n",
    "#decoder.encoder.stages.0.0.convs.0.conv.weight\n",
    "#...\n",
    "#decoder.encoder.stages.5.0.convs.0.conv.weight\n",
    "\n",
    "\n",
    "## each stage has two convs: \n",
    "#encoder.stages.0.0.convs.0.conv.weight\n",
    "#encoder.stages.0.0.convs.1.conv.weight\n",
    "\n",
    "## and each stage has these modules:\n",
    "#encoder.stages.0.0.convs.0.conv.weight\n",
    "#encoder.stages.0.0.convs.0.conv.bias\n",
    "#encoder.stages.0.0.convs.0.norm.weight\n",
    "#encoder.stages.0.0.convs.0.norm.bias\n",
    "#encoder.stages.0.0.convs.0.all_modules.0.weight\n",
    "#encoder.stages.0.0.convs.0.all_modules.0.bias\n",
    "#encoder.stages.0.0.convs.0.all_modules.1.weight\n",
    "#encoder.stages.0.0.convs.0.all_modules.1.bias\n",
    "\n",
    "\n",
    "\n",
    "# for decoder, there are 5 stages (0 to 4)\n",
    "#   for each stage, there are two convs (0 and 1)\n",
    "     # decoder.stages.0.convs.0.conv.weight\n",
    "     # decoder.stages.1.convs.0.conv.weight\n",
    "     # these have the modules\n",
    "            #decoder.stages.0.convs.0.conv.weight\n",
    "            #decoder.stages.0.convs.0.conv.bias\n",
    "            #decoder.stages.0.convs.0.norm.weight\n",
    "            #decoder.stages.0.convs.0.norm.bias\n",
    "            #decoder.stages.0.convs.0.all_modules.0.weight\n",
    "            #decoder.stages.0.convs.0.all_modules.0.bias\n",
    "            #decoder.stages.0.convs.0.all_modules.1.weight\n",
    "            #decoder.stages.0.convs.0.all_modules.1.bias\n",
    "\n",
    "   # there are the transpconvs and seg_layers, one per decoder stage\n",
    "        #decoder.transpconvs.0.weight  and bias\n",
    "        #...\n",
    "        #decoder.transpconvs.4.weight\n",
    "        #decoder.transpconvs.4.bias\n",
    "       \n",
    "        \n",
    "        #decoder.seg_layers.0.weight\n",
    "        #decoder.seg_layers.0.bias\n",
    "        #...\n",
    "        #decoder.seg_layers.4.weight\n",
    "        #decoder.seg_layers.4.bias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20062e-b841-4f97-8790-de2f27601db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stages = arch_kwargs['n_stages']\n",
    "features_per_stage = arch_kwargs['features_per_stage']\n",
    "kernel_sizes = arch_kwargs['kernel_sizes']\n",
    "strides = arch_kwargs['strides']\n",
    "\n",
    "n_conv_per_stage = arch_kwargs['n_conv_per_stage']\n",
    "n_conv_per_stage_decoder = arch_kwargs['n_conv_per_stage_decoder']\n",
    "\n",
    "# can I use these?\n",
    "#conv_op = arch_kwargs['conv_op']\n",
    "#norm_op = arch_kwargs['norm_op']\n",
    "\n",
    "\n",
    "# encoders\n",
    "\n",
    "# for encoder and decoder.encoder, there are 6 stages (0 to 5):\n",
    "#encoder.stages.0.0.convs.0.conv.weight\n",
    "#...\n",
    "#encoder.stages.5.0.convs.0.conv.weight\n",
    "#          and\n",
    "#decoder.encoder.stages.0.0.convs.0.conv.weight\n",
    "#...\n",
    "#decoder.encoder.stages.5.0.convs.0.conv.weight\n",
    "\n",
    "\n",
    "## each stage has two convs: \n",
    "#encoder.stages.0.0.convs.0.conv.weight\n",
    "#encoder.stages.0.0.convs.1.conv.weight\n",
    "\n",
    "## and each stage has these modules:\n",
    "#encoder.stages.0.0.convs.0.conv.weight\n",
    "#encoder.stages.0.0.convs.0.conv.bias\n",
    "#encoder.stages.0.0.convs.0.norm.weight\n",
    "#encoder.stages.0.0.convs.0.norm.bias\n",
    "#encoder.stages.0.0.convs.0.all_modules.0.weight\n",
    "#encoder.stages.0.0.convs.0.all_modules.0.bias\n",
    "#encoder.stages.0.0.convs.0.all_modules.1.weight\n",
    "#encoder.stages.0.0.convs.0.all_modules.1.bias\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
