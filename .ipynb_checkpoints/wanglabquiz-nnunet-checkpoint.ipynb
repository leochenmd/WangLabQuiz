{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9206899,"sourceType":"datasetVersion","datasetId":5566810},{"sourceId":110701,"sourceType":"modelInstanceVersion","modelInstanceId":92735,"modelId":116946},{"sourceId":114370,"sourceType":"modelInstanceVersion","modelInstanceId":96029,"modelId":120216},{"sourceId":115253,"sourceType":"modelInstanceVersion","modelInstanceId":96801,"modelId":120985},{"sourceId":117532,"sourceType":"modelInstanceVersion","modelInstanceId":98828,"modelId":123004}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"****# Coding exercise for Wang Lab\n### Implementation of nnU-net for the segmentation of pancreas and pancreatic lesions on CT scan, with classication of the pancreatic lesions\n### by Leo Chen\n### August/September 2024","metadata":{}},{"cell_type":"code","source":"### IMPORTS\nimport os\nimport glob\n#import util\n\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nfrom torch.autograd import Variable\nimport torch.nn.init as init\n\nfrom collections import defaultdict\nfrom collections import Counter\n\nfrom datetime import datetime\n\nimport SimpleITK as sitk\n#import nibabel as nib\n\nimport json\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:15:17.092428Z","iopub.execute_input":"2024-09-24T02:15:17.093091Z","iopub.status.idle":"2024-09-24T02:15:17.104013Z","shell.execute_reply.started":"2024-09-24T02:15:17.093043Z","shell.execute_reply":"2024-09-24T02:15:17.101767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### GLOBAL VARIABLES\n\n# using GPU?\ngpu = False\n\n# first time running? need to generate csv and npy files\nfirstrun = True\n\n# use resampled (1x1x3 mm voxel size) or original data?\nuseResampledData = True\n\n# directories where the files are\ntraindir = '/kaggle/input/pancreas/train/'\nvaldir = '/kaggle/input/pancreas/validation/'\ntestdir = '/kaggle/input/pancreas/test'\n\nnumpydir = '/kaggle/working/numpy'\n\nmodeldir = '/kaggle/working/models'\n\ncsvpath = '/kaggle/working/trainval_metadata.csv'   # csv with the image dimensions, image and mask file paths\n\nresampleddir = '/kaggle/working/resampled'\n\nif os.path.exists(modeldir) == False:\n    os.makedirs(modeldir)\n\n\nmodel_depth = 5\n\n# patch size\npatch_width = 48\npatch_height = 48\npatch_depth = 48\n\n# CT windowing\nwindow_width = 400\nwindow_center = 50","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:15:21.137939Z","iopub.execute_input":"2024-09-24T02:15:21.138423Z","iopub.status.idle":"2024-09-24T02:15:21.148875Z","shell.execute_reply.started":"2024-09-24T02:15:21.138379Z","shell.execute_reply":"2024-09-24T02:15:21.147007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### FUNCTIONS FOR SITK and IMAGE AUGMENTATION\n\ndef rotateImage(original, anglex, angley, anglez, interpolate='linear'):\n    \"\"\" Returns the 'rotated' 3d image about the physical center that is resampled based on the 'original' image\n    1. original - original image \n    2. angle x is roll / twisting the body like a rolling pin, turning in dance\n    3. angle y is yaw / rotating the body like a propeller blade, like break dancing\n    4. angle z - pitch / tilt along the superior/inferior axis (i.e trendelenburg)\n    \n    \"\"\"\n\n    if interpolate == 'linear':\n        interpolator = sitk.sitkLinear\n    elif interpolate == 'NN':\n        interpolator = sitk.sitkNearestNeighbor\n\n    radx = anglex * math.pi / 180\n    rady = angley * math.pi / 180\n    radz = anglez * math.pi / 180\n\n    origin = np.array(original.GetOrigin())\n    pixelcenter = np.array(sitk.GetSize(original)) / 2.\n    physicalcenter = sitk.TransformContinuousIndexToPhysicalPoint(pixelcenter)\n\n    transform = sitk.Euler3DTransform()\n    transform.SetCenter(physicalcenter)\n    transform.SetRotation(radz, rady, radx)    # note the order is z, y, x\n\n    unitvecs = np.transpose(np.reshape(original.GetDirection(), (-1, 3)))\n    #print(unitvecs)\n    matrix = np.reshape(transform.GetMatrix(), (-1, 3))\n    inverse = np.linalg.inv(matrix)\n\n\n    # the transform matrix is actually mapping backwards: post to pre\n    # therefore the forward transformation is the inverse matrix\n    transformedunitvecs = inverse @ unitvecs   # new i, j, k are columns\n    #print(transformedunitvecs)\n    newdirection = transformedunitvecs.flatten('F')    # flatten by column\n\n    print(newdirection)\n    neworigin = (matrix @ (origin - physicalcenter)) + physicalcenter\n\n    rotatedImage = sitk.Resample(original, original, transform, interpolator)\n    rotatedImage.SetDirection(newdirection)\n    rotatedImage.SetOrigin(neworigin)\n\n    return rotatedImage\n\ndef flipImage(original):\n    \"\"\"Flips an SimpleITK over left/right axis\"\"\"\n    flipped = sitk.Flip(original, [True, False, False])\n    return flipped\n\ndef flipslice(original):\n    \"\"\"Flips a numpy slice (2d image) \"\"\"\n    # flips 2D slice (reverses x indices)\n    flipped = np.flipud(original)  #np.fliplr(original)\n    return flipped\n\ndef bbox_3D(img):\n    \"\"\"Finds the bounding box around a 3D image (numpy)\n    returns rmin, rmax, cmin, cmax, zmin, zmax (r = row, c = column)\"\"\"\n    try:    \n        z = np.any(img, axis=(1, 2))    #z\n        c = np.any(img, axis=(0, 1))    #x , (c = column)\n        r = np.any(img, axis=(0, 2))    #y , (r = row)\n\n        rmin, rmax = np.where(r)[0][[0, -1]]\n        cmin, cmax = np.where(c)[0][[0, -1]]\n        zmin, zmax = np.where(z)[0][[0, -1]]\n\n        #x min max, y min max, z min max\n        return [rmin, rmax, cmin, cmax, zmin, zmax]\n    except:\n        return -1, -1, -1, -1, -1, -1\n\n\ndef bbox_2D(img):\n    \"\"\"Finds the bounding box around a 2D image (numpy)\n    returns rmin, rmax, cmin, cmax (r = row, c = column)\n    If no elements exist, then returns (-1, -1, -1, -1)\"\"\"\n    \n    try:\n        c = np.any(img, axis=0)    #y , (c = column)\n        r = np.any(img, axis=1)    #x , (r = row)\n\n        rmin, rmax = np.where(r)[0][[0, -1]]\n        cmin, cmax = np.where(c)[0][[0, -1]]\n    \n        return rmin, rmax, cmin, cmax\n    except:\n        return -1, -1, -1, -1\n\n\ndef cropImage(image, threshold, xshift, yshift):\n    \"\"\"Crops SimpleITK image to remove pixels below a threshold (e.g. black space)\n    Can also shift by *xshift and *yshift (random shifts in pixels) for augmentation\"\"\"\n    # load image\n    npy = sitk.GetArrayFromImage(image)\n\n    # GET METADATA\n    direction = image.GetDirection()\n    spacing = image.GetSpacing()\n\n    # CALCULATE BOUNDING BOX OF BODY (removes black space)\n    mask = npy > threshold\n    [xmin, xmax, ymin, ymax, zmin, zmax] = bbox_3D(mask)\n\n    # check to make sure shifts do not extend outside boundaries of image\n    if xmin + xshift < 0 or xmax + xshift > npy.shape[2]:\n        xshift = 0\n\n    if ymin + yshift < 0 or ymax + yshift > npy.shape[1]:\n        yshift = 0\n\n    # CROP IMAGE\n    newnpy = npy[zmin:zmax, (ymin+yshift):(ymax+yshift), (xmin+xshift):(xmax+xshift)]\n\n    newimage = sitk.GetImageFromArray(newnpy)\n    topleft = [int(xmin+xshift), int(ymin+yshift), zmin]\n    neworigin = image.TransformIndexToPhysicalPoint(topleft)\n\n    newimage.SetOrigin(neworigin)\n    newimage.SetDirection(direction)\n    newimage.SetSpacing(spacing)\n\n    return newimage\n\n\ndef squareImage(image):\n    \"\"\"Makes an SimpleITK image square by padding with zeros\n    (square meaning width = height)\"\"\"\n    [numcols, numrows, numslices] = image.GetSize()\n    npy = sitk.GetArrayFromImage(image)\n\n    if numcols < numrows:    #pad columns\n        numzerostopad = numrows - numcols\n        leftpad = int(numzerostopad / 2)\n        rightpad = numzerostopad - leftpad\n\n        newnpy = np.concatenate((np.zeros([numslices, numrows, leftpad]), npy, np.zeros([numslices, numrows, rightpad])), axis=2)\n\n        topleft = [-leftpad, 0, 0]\n        neworigin = image.TransformIndexToPhysicalPoint(topleft)\n\n    elif numrows <= numcols:  #pad rows\n        numzerostopad = numcols - numrows\n        toppad = int(numzerostopad / 2)\n        botpad = numzerostopad - toppad\n\n        newnpy = np.concatenate((np.zeros([numslices, toppad, numcols]), npy, np.zeros([numslices, botpad, numcols])), axis=1)\n\n        topleft = [0, -toppad, 0]\n        neworigin = image.TransformIndexToPhysicalPoint(topleft)\n\n    paddedimg = sitk.GetImageFromArray(newnpy)\n    paddedimg.SetOrigin(neworigin)\n    paddedimg.SetDirection(image.GetDirection())\n    paddedimg.SetSpacing(image.GetSpacing())\n\n    return paddedimg\n\ndef resampleImage(image, finalsize, interpolation='linear'):\n    \"\"\"Resamples SimpleITK image to finalsize x finalsize (width and height in pixels)\n    Preserves the original physical size of the image and number of slices\n    Changes the resolution so that the new image has numslices x *finalsize x *finalsize dimensions\"\"\"\n    \n    size = image.GetSize()\n    numslices = size[2]\n    squaresize = size[1]\n\n    # RESAMPLE TO finalsize x finalsize\n    finalnpy = np.zeros([numslices, finalsize, finalsize])\n    reference = sitk.GetImageFromArray(finalnpy)\n    reference.SetOrigin(image.GetOrigin())\n    reference.SetDirection(image.GetDirection())\n\n    spacing = image.GetSpacing()\n    newspacing = np.zeros(3)\n    newspacing[0:2] = (squaresize - 1) * np.array(spacing[0:2]) / (finalsize - 1)\n    newspacing[2] = spacing[2]\n    reference.SetSpacing(newspacing)\n\n\n    # MAKING RESAMPLING FILTER\n    resample = sitk.ResampleImageFilter()\n    resample.SetReferenceImage(reference)\n    if interpolation == 'linear':\n        resample.SetInterpolator(sitk.sitkLinear)\n    elif interpolation == 'NN':\n        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    # RESAMPLE TO finalsize x finalsize x n\n    resampledimg = resample.Execute(image)\n\n    return resampledimg\n\n\ndef projectImage(reference, moving, interpolate = 'linear'):\n    \"\"\"Projects an SimpleITK image (*moving onto *reference)\n    interpolate* = linear or NN (nearest neighbor)\"\"\"\n    \n    resample = sitk.ResampleImageFilter()\n    resample.SetReferenceImage(reference)\n    if interpolate == 'linear':\n        resample.SetInterpolator(sitk.sitkLinear)\n    elif interpolate == 'NN':\n        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    resampledimg = resample.Execute(moving)\n\n    return resampledimg\n\n\ndef resampleImageToVoxelSize(image, voxelx, voxely, voxelz, interpolation='linear'):\n    \"\"\"Resamples SimpleITK *image* to spacing *[voxelx, voxely, voxelz] in mm\n    Preserves the original physical size of the image\n    *voxelz is slice thickness (usually)\n    *voxelx and *voxely are voxel width and height, respectively\n    \"\"\"\n    \n    original_spacing = image.GetSpacing()\n    original_size = image.GetSize()\n    \n    new_spacing = [voxelx, voxely, voxelz]\n    new_size = [int(round(osz*ospc/nspc)) for osz,ospc,nspc in zip(original_size, original_spacing, new_spacing)]\n    # new dimension will be original size * original spacing / new spacing\n    # based on physical distance formula: \n    #    original size (pixel) * original spacing (mm / pixel) = new size (pixel) * new spacing (mm / pixel)\n    \n    if interpolation == 'linear':\n        interpolator = sitk.sitkLinear\n    elif interpolation == 'NN':\n        interpolator = sitk.sitkNearestNeighbor\n    \n    # creates new image\n    new_image = sitk.Resample(image, new_size, sitk.Transform(), interpolator,\n                         image.GetOrigin(), new_spacing, image.GetDirection(), 0,\n                         image.GetPixelID())\n    \n    return new_image\n\n\ndef windowImage(image, window_width, window_center, output_min=0, output_max=255):\n    \"\"\"Normalizes SimpleITK *image* (CT scan) based on window specification\n    (example, abdominal soft tissue window is W = 400, C = 50, or -350 to 450)\n    Clips values above 0 and 1\n    \"\"\"\n    \n    window_min = window_center - window_width / 2\n    window_max = window_center + window_width / 2\n    \n    output_min = 0\n    output_max = 255\n    \n    windowed_image = sitk.IntensityWindowing(image, window_min, window_max, output_min, output_max)\n    \n    return windowed_image\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:15:26.928978Z","iopub.execute_input":"2024-09-24T02:15:26.929538Z","iopub.status.idle":"2024-09-24T02:15:26.986773Z","shell.execute_reply.started":"2024-09-24T02:15:26.929488Z","shell.execute_reply":"2024-09-24T02:15:26.985324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install nn-Unet on Kaggle","metadata":{}},{"cell_type":"code","source":"base_dir = '/kaggle/working/'\nos.chdir(base_dir)\n\n!git clone https://github.com/MIC-DKFZ/nnUNet.git\n\nrespository_dir = os.path.join(base_dir,'nnUNet')\nos.chdir(respository_dir)\n\n!pip install -e .\n#(optional installation)\n!pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git\n\nos.chdir(base_dir)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:15:32.668886Z","iopub.execute_input":"2024-09-24T02:15:32.669405Z","iopub.status.idle":"2024-09-24T02:17:10.137759Z","shell.execute_reply.started":"2024-09-24T02:15:32.669361Z","shell.execute_reply":"2024-09-24T02:17:10.136027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setting up environment variables","metadata":{}},{"cell_type":"code","source":"!export nnUNet_raw=\"/kaggle/working/nnUnet_raw\"\n!export nnUNet_preprocessed=\"/kaggle/working/nnUNet_preprocessed\"\n!export nnUNet_results=\"/kaggle/working/nnUNet_results\"\n!echo ${nnUNet_raw}","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:41:40.478305Z","iopub.execute_input":"2024-09-24T02:41:40.478915Z","iopub.status.idle":"2024-09-24T02:41:45.193459Z","shell.execute_reply.started":"2024-09-24T02:41:40.478863Z","shell.execute_reply":"2024-09-24T02:41:45.191493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data pre-processing\n","metadata":{}},{"cell_type":"markdown","source":"## Functions","metadata":{}},{"cell_type":"code","source":"### FUNCTIONS FOR READING/LOADING THE DATA\n\ndef getImageAndMaskFilePaths(train_or_val, subtype):\n    '''\n    returns a list of file paths, sorted alphabetically\n    [image_niftis_gz, mask_niftis_gz, image_niftis_panorama, mask_niftis_panorama]\n    input: training or validation images ('train' or 'val', and the subtype {0, 1, or 2}\n    \n    '''\n    \n    if train_or_val == 'train':\n        rootdir = traindir        \n    elif train_or_val == 'val':\n        rootdir = valdir\n        \n    subtypedir = os.path.join(rootdir, 'subtype' + str(subtype))\n    \n    \n    ## this gets all of the file paths in the subtype folder for the image and mask files\n    \n    # example file path for a training image of subtype 0:\n    #   '/kaggle/input/pancreas/train/subtype0/quiz_0_041_0000.nii'\n        \n    image_niftis_gz = [os.path.join(subtypedir, file_name) for file_name in os.listdir(subtypedir) if '0000' in file_name]\n    image_niftis_gz.sort()\n    \n    mask_niftis_gz = [file_name.partition(\"_0000\")[0] + '.nii' for file_name in image_niftis_gz]\n    \n    \n    \n    ## however the actual CT / segmentation is within the zipped files:\n    #   '/kaggle/input/pancreas/train/subtype0/quiz_0_041_0000.nii/PANORAMA_101960_00001_0000.nii'\n    \n    # this gets the actual PANORAMA file:\n    image_niftis_panorama= [os.path.join(image, os.listdir(image)[0]) for image in image_niftis_gz]\n    mask_niftis_panorama = [os.path.join(mask, os.listdir(mask)[0]) for mask in mask_niftis_gz]\n    \n    return [image_niftis_gz, mask_niftis_gz, image_niftis_panorama, mask_niftis_panorama]\n   \n    \n    \ndef getImageFileDetails(imageniftis, maskniftis, train_or_val):\n    '''Creates a dataframe with the following:\n        study ID // subtype // CT width/height/depth // pancreas width/height/depth // lesion width/height/depth  // pancreas xmin/xmax / ymin/ymax / zmin/zmax \n          // CT spacing x/y/z \n       \n       Input is a list of image nifti file paths, mask nifti file paths (panorama), and {'train' or 'val'}\n    '''\n    \n    ### THIS IS NOT USED TO SPEED UP TRAINING ###\n    ### (WAS INITIALLY USED IN 2D and 3D MODELS FROM SCRATCH)\n    \n    maindf = pd.DataFrame({'ID': pd.Series(dtype='string'),\n                   'train/val': pd.Series(dtype='string'),\n                   'subtype': pd.Series(dtype='int'),\n                   'CT width': pd.Series(dtype='int'),\n                   'CT height': pd.Series(dtype='int'),\n                   'CT depth': pd.Series(dtype='int'),\n                   'panc width': pd.Series(dtype='int'),\n                   'panc height': pd.Series(dtype='int'),\n                   'panc depth': pd.Series(dtype='int'),\n                   'lesion width': pd.Series(dtype='int'),\n                   'lesion height': pd.Series(dtype='int'),\n                   'lesion depth': pd.Series(dtype='int'),\n                   'panc xmin': pd.Series(dtype='int'),\n                   'panc xmax': pd.Series(dtype='int'),\n                   'panc ymin': pd.Series(dtype='int'),\n                   'panc ymax': pd.Series(dtype='int'),\n                   'panc zmin': pd.Series(dtype='int'),\n                   'panc zmax': pd.Series(dtype='int'),\n                   'CT spacing x': pd.Series(dtype='float'),\n                   'CT spacing y': pd.Series(dtype='float'),\n                   'CT spacing z': pd.Series(dtype='float'),\n                   'CT direction x': pd.Series(dtype='float'),\n                   'CT direction y': pd.Series(dtype='float'),\n                   'CT direction z': pd.Series(dtype='float'),        \n                   'image path': pd.Series(dtype='string'),\n                   'mask path': pd.Series(dtype='string')\n                  })\n\n    for i, imagepath in enumerate(imageniftis):\n        maskpath = maskniftis[i]\n        \n        ## gets the subtype, ID for the current image\n        # (format of the file name is: /kaggle/input/pancreas/train/subtype0/quiz_0_041_0000.nii/PANORAMA_101960_00001_0000.nii)\n        subfolder = [folder for folder in imagepath.split('/') if 'quiz' in folder][0]   #gets the subdirectory with \"quiz\"\n        \n        subtype = subfolder.split('_')[1]\n        ID = int(subfolder.split('_')[2])\n        \n        \n        ## gets the dimensions of CT image in pixels\n        img = sitk.ReadImage(imagepath)\n        \n        CTwidth = img.GetWidth()\n        CTheight = img.GetHeight()\n        CTdepth = img.GetDepth()\n                \n        ## gets the dimensions of the pancreas and lesion segmentations\n        mask = sitk.ReadImage(maskpath)\n        mask_vol = sitk.GetArrayFromImage(mask)\n    \n        [xmin1, xmax1, ymin1, ymax1, zmin1, zmax1] = bbox_3D(np.int64(mask_vol) == 1)   # 1 = pancreas\n        [xmin2, xmax2, ymin2, ymax2, zmin2, zmax2] = bbox_3D(np.int64(mask_vol) == 2)   # 2 = lesion\n \n        width1 = xmax1 - xmin1\n        height1 = ymax1 - ymin1\n        depth1 = zmax1 - zmin1\n        \n        width2 = xmax2 - xmin2\n        height2 = ymax2 - ymin2\n        depth2 = zmax2 - zmin2\n\n        ## gets the spacing (mm) and 'direction' vectors of x/y/z axis\n        spacing = img.GetSpacing()\n        direction = img.GetDirection()\n        directionx = str(direction[0:2])\n        directiony = str(direction[3:5])\n        directionz = str(direction[6:8])\n        \n        ## eventual numpy file names\n        image_filename =  os.path.join(numpydir, str(train_or_val) + '_' + \"{:03d}\".format(ID) + '_image.npy')\n        mask_filename = os.path.join(numpydir, str(train_or_val) + '_' + \"{:03d}\".format(ID) + '_mask.npy')\n\n        \n        # study ID // subtype // CT width/height/depth // pancreas width/height/depth // lesion width/height/depth  // pancreas xmin/xmax / ymin/ymax / zmin/zmax \n          #   // CT spacing x/y/z \n        df = pd.DataFrame({'train/val':train_or_val, 'ID':ID, 'subtype':subtype, 'CT width':CTwidth, 'CT height':CTheight, 'CT depth':CTdepth, \n                           'panc width':width1, 'panc height':height1, 'panc depth':depth1, \n                           'lesion width':width2, 'lesion height':height2, 'lesion depth':depth2,\n                           'panc xmin':xmin1, 'panc xmax':xmax1, 'panc ymin': ymin1, 'panc ymax':ymax1, 'panc zmin': zmin1, 'panc zmax':zmax1,\n                           'CT spacing x':spacing[0], 'CT spacing y':spacing[1], 'CT spacing z':spacing[2], \n                           'CT direction x':directionx, 'CT direction y':directiony, 'CT direction z':directionz, \n                           'image path': imagepath, 'mask path': maskpath, 'image npy': image_filename, 'mask npy':mask_filename}, index = [0])\n                           \n        \n        maindf = pd.concat([maindf, df])\n                 \n            \n    return maindf\n\ndef getImageFileDataFrame(imageniftis_gz, maskniftis_gz, imageniftis_pano, maskniftis_pano, train_or_val):\n    '''Creates a dataframe with the following:\n        study ID // train/val // subtype // image gz path // mask gz path // image pano path // mask pano path\n       \n       Input is a list of image nifti file paths, mask nifti file paths (panorama), and {'train' or 'val'}\n    '''\n    \n    \n    maindf = pd.DataFrame({'ID': pd.Series(dtype='string'),\n                           'train/val': pd.Series(dtype='string'),\n                           'subtype': pd.Series(dtype='string'),\n                           'image gz path': pd.Series(dtype='string'),\n                           'mask gz path': pd.Series(dtype='string'),\n                           'image panorama path': pd.Series(dtype='string'),\n                           'mask panorama path': pd.Series(dtype='string')\n                          })\n\n    for i, imagepath_gz in enumerate(imageniftis_gz):\n        maskpath_gz = maskniftis_gz[i]\n        imagepath_pano = imageniftis_pano[i]\n        maskpath_pano = maskniftis_pano[i]\n        \n        ## gets the subtype, ID for the current image\n        # (format of the file name is: /kaggle/input/pancreas/train/subtype0/quiz_0_041_0000.nii/PANORAMA_101960_00001_0000.nii)\n        subfolder = [folder for folder in imagepath_gz.split('/') if 'quiz' in folder][0]   #gets the subdirectory with \"quiz\"\n        \n        subtype = subfolder.split('_')[1]\n        ID = subfolder.split('_')[2]\n        \n        \n        \n        # study ID // subtype // CT width/height/depth // pancreas width/height/depth // lesion width/height/depth  // pancreas xmin/xmax / ymin/ymax / zmin/zmax \n          #   // CT spacing x/y/z \n        df = pd.DataFrame({'train/val':train_or_val, 'ID':ID, 'subtype':subtype,\n                           'image gz path': imagepath_gz, 'mask gz path': maskpath_gz, \n                           'image panorama path': imagepath_pano, 'mask panorama path': maskpath_pano}, index = [0])\n                           \n        \n        maindf = pd.concat([maindf, df])\n                 \n            \n    return maindf","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:17:28.971265Z","iopub.execute_input":"2024-09-24T02:17:28.971887Z","iopub.status.idle":"2024-09-24T02:17:29.024293Z","shell.execute_reply.started":"2024-09-24T02:17:28.971824Z","shell.execute_reply":"2024-09-24T02:17:29.022889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this loop runs through all of the training and validation images, and builds a dataframe with the metadata\n\nfirstloop = True\n\nfor train_or_val in ['train', 'val']:\n    for subtype in range(3):\n        images_gz, masks_gz, images_pano, masks_pano = getImageAndMaskFilePaths(train_or_val, subtype)\n        \n        subtypedf = getImageFileDataFrame(images_gz, masks_gz, images_pano, masks_pano, train_or_val)\n\n        if firstloop:\n            maindf = subtypedf\n            firstloop = False\n        else:\n            maindf = pd.concat([maindf, subtypedf])\n        \n\n# saving the metadata to csv file\n\ncsvpath = '/kaggle/working/trainval_metadata.csv'\nmaindf.to_csv(csvpath, index = False)\n\nprint('done')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:17:30.970305Z","iopub.execute_input":"2024-09-24T02:17:30.972457Z","iopub.status.idle":"2024-09-24T02:17:33.963760Z","shell.execute_reply.started":"2024-09-24T02:17:30.972358Z","shell.execute_reply":"2024-09-24T02:17:33.961927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load main dataframe with all of information\nmaindf = pd.read_csv(csvpath, dtype='string')\n\ntraindf =  maindf[maindf['train/val'] == 'train']\nvaldf = maindf[maindf['train/val'] == 'val']\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:17:37.778136Z","iopub.execute_input":"2024-09-24T02:17:37.778609Z","iopub.status.idle":"2024-09-24T02:17:37.804345Z","shell.execute_reply.started":"2024-09-24T02:17:37.778563Z","shell.execute_reply":"2024-09-24T02:17:37.802405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Copying data to folders based on nnUnet data organization\n\n### nnUnet data folder structure\nnnUNet_raw/ <br>\n1. Dataset001_BrainTumour <br>\n    - dataset.json <br>\n    - imagesTr <br>\n    - imagesTs  # optional  <br>\n    - labelsTr  <br>\n<br>\n- imagesTr contains the images belonging to the training cases. nnU-Net will perform pipeline configuration, training with cross-validation, as well as finding postprocessing and the best ensemble using this data.\n- imagesTs (optional) contains the images that belong to the test cases. nnU-Net does not use them! This could just be a convenient location for you to store these images. Remnant of the Medical Segmentation Decathlon folder structure.\n- labelsTr contains the images with the ground truth segmentation maps for the training cases.\n- dataset.json contains metadata of the dataset.","metadata":{}},{"cell_type":"markdown","source":"1. nnUNet_raw/Dataset002_Heart/\n    1. ├── dataset.json\n    2. ├── imagesTr\n        1. ├── la_003_0000.nii.gz\n        2. ├── la_004_0000.nii.gz\n        3. ├── ...\n    3. ├── imagesTs\n        1. ├── la_001_0000.nii.gz\n        2. ├── la_002_0000.nii.gz\n        3. ├── ...\n    4. └── labelsTr\n        1. ├── la_003.nii.gz\n        2. ├── la_004.nii.gz\n        3. ├── ...","metadata":{}},{"cell_type":"code","source":"raw_folder = '/kaggle/working/nnUnet_raw/'\ndata_folder = '/kaggle/working/nnUnet_raw/Dataset001_Pancreas/'\n\nimagesTr_folder = os.path.join(data_folder, 'imagesTr')\nlabelsTr_folder = os.path.join(data_folder, 'labelsTr')\n\nimagesTs_folder = os.path.join(data_folder, 'imagesTs')\nlabelsTs_folder = os.path.join(data_folder, 'labelsTs')\n\n\nfor folder in [raw_folder, data_folder, imagesTr_folder, imagesTs_folder, labelsTr_folder, labelsTs_folder]:\n    if not os.path.exists(folder):\n        os.makedirs(folder)\n\n\nprint('copying training files...')\n        \nfor i, row in traindf.iterrows():\n    if i % 10 == 9:\n        print(i+1)\n    ID = row['ID']\n\n    old_image_path = row['image panorama path']\n    old_mask_path = row['mask panorama path']\n\n    image_img = sitk.ReadImage(old_image_path)\n    mask_img = sitk.ReadImage(old_mask_path, sitk.sitkInt16)    # get rid of rounding error for segmentations\n    new_mask_img = projectImage(image_img, mask_img, interpolate='NN')   # ensures that the voxel spacing is equal\n    \n    ### new file name scheme\n    ### new_image_name = quiz_[ID]_0000.nii.gz\n    ### new_mask_name = quiz_[ID].nii.gz\n\n    new_image_name = 'quiz_' + ID + '_0000.nii.gz'\n    new_mask_name = 'quiz_' + ID + '.nii.gz'\n\n    new_image_path = os.path.join(imagesTr_folder, new_image_name)\n    new_mask_path = os.path.join(labelsTr_folder, new_mask_name)\n\n    shutil.copyfile(old_image_path, new_image_path)\n    \n    sitk.WriteImage(new_mask_img, new_mask_path)\n    \nprint(' -- done')\n\nprint('copying val files')\n\nfor i, row in valdf.iterrows():\n    if i % 10 == 9:\n        print(i+1)\n    ID = row['ID']\n\n    old_image_path = row['image panorama path']\n    old_mask_path = row['mask panorama path']\n\n    image_img = sitk.ReadImage(old_image_path)\n    mask_img = sitk.ReadImage(old_mask_path, sitk.sitkInt16)    # get rid of rounding error for segmentations\n    new_mask_img = projectImage(image_img, mask_img, interpolate='NN')   # ensures that the voxel spacing is equal\n    \n    ### new file name scheme\n    ### new_image_name = quiz_[ID]_0000.nii.gz\n    ### new_mask_name = quiz_[ID].nii.gz\n\n    new_image_name = 'quiz_' + ID + '_0000.nii.gz'\n    new_mask_name = 'quiz_' + ID + '.nii.gz'\n\n    new_image_path = os.path.join(imagesTs_folder, new_image_name)\n    new_mask_path = os.path.join(labelsTs_folder, new_mask_name)\n\n    shutil.copyfile(old_image_path, new_image_path)\n    \n    sitk.WriteImage(new_mask_img, new_mask_path)\n    \nprint('  -- done')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:21:59.167377Z","iopub.execute_input":"2024-09-24T02:21:59.171028Z","iopub.status.idle":"2024-09-24T02:22:50.445511Z","shell.execute_reply.started":"2024-09-24T02:21:59.170937Z","shell.execute_reply":"2024-09-24T02:22:50.444034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### dataset.json","metadata":{}},{"cell_type":"code","source":"dataset_json_path = os.path.join(data_folder, 'dataset.json')\n\ndictionary = {\n    \"channel_names\": {  # formerly modalities\n        \"0\": \"CT\", \n        }, \n    \n    \"labels\": {  # THIS IS DIFFERENT NOW!\n        \"background\": 0,\n        \"pancreas\": 1,\n        \"lesion\": 2\n        }, \n \n    \"numTraining\": 252, \n \n    \"file_ending\": \".nii.gz\",\n \n    \"overwrite_image_reader_writer\": \"SimpleITKIO\"  # optional! If not provided nnU-Net will automatically determine the ReaderWriter\n}\n \njson_object = json.dumps(dictionary, indent=4)\n \nwith open(dataset_json_path, \"w\") as outfile:\n    outfile.write(json_object)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:24:34.605428Z","iopub.execute_input":"2024-09-24T02:24:34.605966Z","iopub.status.idle":"2024-09-24T02:24:34.616629Z","shell.execute_reply.started":"2024-09-24T02:24:34.605917Z","shell.execute_reply":"2024-09-24T02:24:34.615261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### splits_final.json\nusing the original train/val split","metadata":{}},{"cell_type":"code","source":"#os.remove(splits_json_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:09:56.476104Z","iopub.execute_input":"2024-09-24T02:09:56.476647Z","iopub.status.idle":"2024-09-24T02:09:56.484217Z","shell.execute_reply.started":"2024-09-24T02:09:56.476591Z","shell.execute_reply":"2024-09-24T02:09:56.482647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#maindf['quiz_ID'] = 'quiz_' + maindf['ID']\n\n#traindf =  maindf[maindf['train/val'] == 'train']\n#valdf = maindf[maindf['train/val'] == 'val']\n\n#train_list = traindf['quiz_ID'].tolist()\n#val_list = valdf['quiz_ID'].tolist()\n\n#splits_json_path = os.path.join(data_folder, 'splits_final.json')\n\n#splits = []\n#for i in range(5):\n#    splits.append({\n#    \"train\": train_list,\n#    \"val\": val_list\n#})\n \n\n#json_object = json.dumps(splits, indent=4)\n \n#with open(splits_json_path, \"w\") as outfile:\n#    outfile.write(json_object)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:08:49.104281Z","iopub.execute_input":"2024-09-24T02:08:49.105596Z","iopub.status.idle":"2024-09-24T02:08:49.125514Z","shell.execute_reply.started":"2024-09-24T02:08:49.105532Z","shell.execute_reply":"2024-09-24T02:08:49.124076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from batchgenerators.utilities.file_and_folder_operations import load_json\n\n#splits = load_json(splits_json_path)\n\n#print(splits[0].keys())","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:09:00.996242Z","iopub.execute_input":"2024-09-24T02:09:00.996734Z","iopub.status.idle":"2024-09-24T02:09:01.005217Z","shell.execute_reply.started":"2024-09-24T02:09:00.996685Z","shell.execute_reply":"2024-09-24T02:09:01.003841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training nnUnet\n\n## Pre-processing\n\n!nnUNetv2_plan_and_preprocess -d DATASET_ID --verify_dataset_integrity\n<br>\n<br>\n!nnUNet_raw=\"/kaggle/working/nnUnet_raw\" nnUNet_preprocessed=\"/kaggle/working/nnUNet_preprocessed\" nnUNet_results=\"/kaggle/working/nnUNet_results\" nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity  -pl nnUNetPlannerResEncM\n<br>\n(for ResNet encoder)","metadata":{}},{"cell_type":"code","source":"#!nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity\n!nnUNet_raw=\"/kaggle/working/nnUnet_raw\" nnUNet_preprocessed=\"/kaggle/working/nnUNet_preprocessed\" nnUNet_results=\"/kaggle/working/nnUNet_results\" nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:24:38.931170Z","iopub.execute_input":"2024-09-24T02:24:38.931696Z","iopub.status.idle":"2024-09-24T02:32:04.735847Z","shell.execute_reply.started":"2024-09-24T02:24:38.931650Z","shell.execute_reply":"2024-09-24T02:32:04.733361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training\n\ncan use ' -p nnUNetResEncUNetMPlans ' (for ResNet encoder)","metadata":{}},{"cell_type":"code","source":"'''\nusage: nnUNetv2_train [-h] [-tr TR] [-p P]\n                      [-pretrained_weights PRETRAINED_WEIGHTS]\n                      [-num_gpus NUM_GPUS] [--use_compressed] [--npz] [--c]\n                      [--val] [--val_best] [--disable_checkpointing]\n                      [-device DEVICE]\n                      dataset_name_or_id configuration fold\n\npositional arguments:\n  dataset_name_or_id    Dataset name or ID to train with\n  configuration         Configuration that should be trained\n  fold                  Fold of the 5-fold cross-validation. Should be an int\n                        between 0 and 4.\n\noptions:\n  -h, --help            show this help message and exit\n  -tr TR                [OPTIONAL] Use this flag to specify a custom trainer.\n                        Default: nnUNetTrainer\n  -p P                  [OPTIONAL] Use this flag to specify a custom plans\n                        identifier. Default: nnUNetPlans\n  -pretrained_weights PRETRAINED_WEIGHTS\n                        [OPTIONAL] path to nnU-Net checkpoint file to be used\n                        as pretrained model. Will only be used when actually\n                        training. Beta. Use with caution.\n  -num_gpus NUM_GPUS    Specify the number of GPUs to use for training\n  --use_compressed      [OPTIONAL] If you set this flag the training cases\n                        will not be decompressed. Reading compressed data is\n                        much more CPU and (potentially) RAM intensive and\n                        should only be used if you know what you are doing\n  --npz                 [OPTIONAL] Save softmax predictions from final\n                        validation as npz files (in addition to predicted\n                        segmentations). Needed for finding the best ensemble.\n  --c                   [OPTIONAL] Continue training from latest checkpoint\n  --val                 [OPTIONAL] Set this flag to only run the validation.\n                        Requires training to have finished.\n  --val_best            [OPTIONAL] If set, the validation will be performed\n                        with the checkpoint_best instead of checkpoint_final.\n                        NOT COMPATIBLE with --disable_checkpointing! WARNING:\n                        This will use the same 'validation' folder as the\n                        regular validation with no way of distinguishing the\n                        two!\n  --disable_checkpointing\n                        [OPTIONAL] Set this flag to disable checkpointing.\n                        Ideal for testing things out and you dont want to\n                        flood your hard drive with checkpoints.\n  -device DEVICE        Use this to set the device the training should run\n                        with. Available options are 'cuda' (GPU), 'cpu' (CPU)\n                        and 'mps' (Apple M1/M2). Do NOT use this to set which\n                        GPU ID! Use CUDA_VISIBLE_DEVICES=X nnUNetv2_train\n                        [...] instead!\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training 2D\n\nnnUNetv2_train DATASET_NAME_OR_ID 2d FOLD [--npz]\n(fold = 0)","metadata":{}},{"cell_type":"code","source":"!nnUNet_raw=\"/kaggle/working/nnUnet_raw\" nnUNet_preprocessed=\"/kaggle/working/nnUNet_preprocessed\" nnUNet_results=\"/kaggle/working/nnUNet_results\" nnUNetv2_train 001 2d 0 -device cuda --npz","metadata":{"execution":{"iopub.status.busy":"2024-09-24T02:43:16.392494Z","iopub.execute_input":"2024-09-24T02:43:16.393084Z","iopub.status.idle":"2024-09-24T02:43:50.871488Z","shell.execute_reply.started":"2024-09-24T02:43:16.393032Z","shell.execute_reply":"2024-09-24T02:43:50.869506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training 3D full res\nnnUNetv2_train DATASET_NAME_OR_ID 3d_fullres FOLD [--npz]\n(fold = 0)","metadata":{}},{"cell_type":"code","source":"#!nnUNet_raw=\"/kaggle/working/nnUnet_raw\" nnUNet_preprocessed=\"/kaggle/working/nnUNet_preprocessed\" nnUNet_results=\"/kaggle/working/nnUNet_results\" nnUNetv2_train 001 3d_fullres 0 -device cuda --npz","metadata":{"execution":{"iopub.status.busy":"2024-09-22T21:06:49.573667Z","iopub.execute_input":"2024-09-22T21:06:49.574107Z","iopub.status.idle":"2024-09-22T21:06:49.625645Z","shell.execute_reply.started":"2024-09-22T21:06:49.574065Z","shell.execute_reply":"2024-09-22T21:06:49.624208Z"},"trusted":true},"execution_count":null,"outputs":[]}]}